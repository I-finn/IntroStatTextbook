<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 15 Inference for a single proportion | Montana State Introductory Statistics with R</title>
<meta name="author" content="Nicole Carnegie, Stacey Hancock, Elijah Meyer, Jade Schmidt, Melinda Yager">
<meta name="description" content="TODO  Old content - revise as needed  15.1 One proportion  Notation. \(n\) = sample size (number of observational units in the data set) \(\hat{p}\) = sample proportion (number of “successes”...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 15 Inference for a single proportion | Montana State Introductory Statistics with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://mtstateintrostats.github.io/IntroStatTextbook/inference-one-prop.html">
<meta property="og:description" content="TODO  Old content - revise as needed  15.1 One proportion  Notation. \(n\) = sample size (number of observational units in the data set) \(\hat{p}\) = sample proportion (number of “successes”...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 15 Inference for a single proportion | Montana State Introductory Statistics with R">
<meta name="twitter:description" content="TODO  Old content - revise as needed  15.1 One proportion  Notation. \(n\) = sample size (number of observational units in the data set) \(\hat{p}\) = sample proportion (number of “successes”...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet">
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/plotly-binding-4.10.0/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script><script type="text/x-mathjax-config">
    const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
    for (let popover of popovers){
      const div = document.createElement('div');
      div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
      div.innerHTML = popover.getAttribute('data-content');
      
      // Will this work with TeX on its own line?
      var has_math = div.querySelector("span.math");
      if (has_math) {
        document.body.appendChild(div);
      	MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
      	MathJax.Hub.Queue(function(){
          popover.setAttribute('data-content', div.innerHTML);
      	})
      }
    }
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="css/ims-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Montana State Introductory Statistics with R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="authors.html">Authors</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="rstudio.html">Preliminaries: Getting started in RStudio</a></li>
<li class="book-part">Introduction to data</li>
<li><a class="" href="intro-to-data.html"><span class="header-section-number">1</span> Hello data</a></li>
<li><a class="" href="data-design.html"><span class="header-section-number">2</span> Study design</a></li>
<li><a class="" href="data-applications.html"><span class="header-section-number">3</span> Applications: Data</a></li>
<li class="book-part">Exploratory data analysis</li>
<li><a class="" href="categorical-data.html"><span class="header-section-number">4</span> Exploring categorical data</a></li>
<li><a class="" href="quantitative-data.html"><span class="header-section-number">5</span> Exploring quantitative data</a></li>
<li><a class="" href="cor-reg.html"><span class="header-section-number">6</span> Correlation and regression</a></li>
<li><a class="" href="mult-reg.html"><span class="header-section-number">7</span> Multivariable models</a></li>
<li><a class="" href="explore-applications.html"><span class="header-section-number">8</span> Applications: Explore</a></li>
<li class="book-part">Foundations of inference</li>
<li><a class="" href="foundations-randomization.html"><span class="header-section-number">9</span> Hypothesis testing with randomization</a></li>
<li><a class="" href="foundations-bootstrapping.html"><span class="header-section-number">10</span> Confidence intervals with bootstrapping</a></li>
<li><a class="" href="foundations-mathematical.html"><span class="header-section-number">11</span> Inference with mathematical models</a></li>
<li><a class="" href="foundations-errors.html"><span class="header-section-number">12</span> Errors, power, and practical importance</a></li>
<li><a class="" href="foundations-applications.html"><span class="header-section-number">13</span> Applications: Foundations</a></li>
<li class="book-part">Inference for categorical data</li>
<li><a class="active" href="inference-one-prop.html"><span class="header-section-number">15</span> Inference for a single proportion</a></li>
<li><a class="" href="inference-two-props.html"><span class="header-section-number">16</span> Inference for comparing two proportions</a></li>
<li><a class="" href="applications-infer-categorical.html"><span class="header-section-number">17</span> Applications: Infer categorical</a></li>
<li class="book-part">Inference for quantitative data</li>
<li><a class="" href="inference-for-a-single-mean.html"><span class="header-section-number">19</span> Inference for a single mean</a></li>
<li><a class="" href="inference-for-comparing-paired-means.html"><span class="header-section-number">20</span> Inference for comparing paired means</a></li>
<li><a class="" href="inference-for-comparing-two-independent-means.html"><span class="header-section-number">21</span> Inference for comparing two independent means</a></li>
<li><a class="" href="applications-infer-quantitative.html"><span class="header-section-number">22</span> Applications: Infer quantitative</a></li>
<li class="book-part">Inference for regression</li>
<li><a class="" href="inference-for-correlation-and-slope.html"><span class="header-section-number">24</span> Inference for correlation and slope</a></li>
<li><a class="" href="applications-infer-regression.html"><span class="header-section-number">25</span> Applications: Infer regression</a></li>
<li class="book-part">Probability</li>
<li><a class="" href="probability.html"><span class="header-section-number">26</span> Probability with tables</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/MTstateIntroStats/IntroStatTextbook">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="inference-one-prop" class="section level1" number="15">
<h1>
<span class="header-section-number">15</span> Inference for a single proportion<a class="anchor" aria-label="anchor" href="#inference-one-prop"><i class="fas fa-link"></i></a>
</h1>
<div class="chapterintro">
<p>TODO</p>
</div>
<div class="underconstruction">
<p>Old content - revise as needed</p>
</div>
<div id="single-prop" class="section level2" number="15.1">
<h2>
<span class="header-section-number">15.1</span> One proportion<a class="anchor" aria-label="anchor" href="#single-prop"><i class="fas fa-link"></i></a>
</h2>
<div class="onebox">
<p><strong>Notation</strong>.</p>
<ul>
<li>
<span class="math inline">\(n\)</span> = sample size (number of observational units in the data set)</li>
<li>
<span class="math inline">\(\hat{p}\)</span> = sample proportion (number of “successes” divided by the sample size)</li>
<li>
<span class="math inline">\(\pi\)</span> = population proportion<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;When you see &lt;span class="math inline"&gt;\(\pi\)&lt;/span&gt; in this textbook, it will always symbolize a (typically unknown) population proportion, not the value 3.14….&lt;/p&gt;'><sup>112</sup></a>
</li>
</ul>
</div>
<p>A single proportion is used to summarize data when we measured a single categorical variable on each observational unit—the single variable is measured as either a success or failure (e.g., “surgical complication” vs. “no surgical complication”)<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The terms “success” and “failure” may not actually represent outcomes we view as successful or not, but it is the typical generic way to referring to the possible outcomes of a binary variable. The “success” is whatever we count when calculating our sample proportion.&lt;/p&gt;"><sup>113</sup></a>.</p>
<div id="one-prop-null-boot" class="section level3" number="15.1.1">
<h3>
<span class="header-section-number">15.1.1</span> Simulation-based test for <span class="math inline">\(H_0: \pi = \pi_0\)</span><a class="anchor" aria-label="anchor" href="#one-prop-null-boot"><i class="fas fa-link"></i></a>
</h3>
<!-- Medical consultant case study was added to Chapter 10, so we need to change this example -->
<p> In Section <a href="foundations-randomization.html#HypothesisTesting">9.3</a>, we introduced the general steps of a hypothesis test:</p>
<div class="onebox">
<p><strong>General steps of a hypothesis test.</strong> Every hypothesis test follows these same general steps:</p>
<ol style="list-style-type: decimal">
<li>Frame the research question in terms of hypotheses.</li>
<li>Collect and summarize data using a test statistic.</li>
<li>Assume the null hypothesis is true, and simulate or mathematically model a null distribution for the test statistic.</li>
<li>Compare the observed test statistic to the null distribution to calculate a p-value.</li>
<li>Make a conclusion based on the p-value, and write a conclusion in context, in plain language, and in terms of the alternative hypothesis.</li>
</ol>
</div>
<div class="workedexample">
<p>People providing an organ for donation sometimes seek the help of a special medical consultant. These consultants assist the patient in all aspects of the surgery, with the goal of reducing the possibility of complications during the medical procedure and recovery. Patients might choose a consultant based in part on the historical complication rate of the consultant’s clients.</p>
<p>One consultant tried to attract patients by noting the average complication rate for liver donor surgeries in the US is about 10%, but her clients have had only 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!).</p>
<p>Using these data, is it possible to assess the consultant’s claim that her work meaningfully contributes to reducing complications?</p>
<hr>
<p>No. The claim is that there is a causal connection, but the data are observational, so we must be on the lookout for confounding variables. For example, maybe patients who can afford a medical consultant can afford better medical care, which can also lead to a lower complication rate.</p>
<p>While it is not possible to assess the causal claim, it is still possible to understand the consultant’s true rate of complications.</p>
</div>
<div id="steps-1-and-2-hypotheses-and-test-statistic" class="section level4 unnumbered">
<h4>Steps 1 and 2: Hypotheses and test statistic<a class="anchor" aria-label="anchor" href="#steps-1-and-2-hypotheses-and-test-statistic"><i class="fas fa-link"></i></a>
</h4>
<p>Regardless of if we use simulation-based methods or theory-based methods, the first two steps of a hypothesis test start out the same: setting up hypotheses and summarizing data with a test statistic. We will let <span class="math inline">\(\pi\)</span> represent the true complication rate for liver donors working with this consultant. This “true” complication probability is called the <strong>parameter</strong> of interest<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Parameters were first introduced in Section &lt;a href="quantitative-data.html#dotplots"&gt;5.2&lt;/a&gt;&lt;/p&gt;'><sup>114</sup></a>. The sample proportion for the complication rate is 3 complications divided by the 62 surgeries the consultant has worked on: <span class="math inline">\(\hat{p} = 3/62 = 0.048\)</span>. Since this value is estimated from sample data, it is called a <strong>statistic</strong>. The statistic <span class="math inline">\(\hat{p}\)</span> is also our point estimate, or “best guess,” for <span class="math inline">\(\pi\)</span>, and we will use is as our <strong>test statistic</strong>.</p>
<div class="onebox">
<p><strong>Parameters and statistics.</strong></p>
<p>A <strong>parameter</strong> is the “true” value of interest. We typically estimate the parameter using a <strong>statistic</strong> from a sample of data. When a statistic is used as an estimate of a parameter, it is called a <strong>point estimate</strong>.</p>
<p>For example, we estimate the probability <span class="math inline">\(\pi\)</span> of a complication for a client of the medical consultant by examining the past complications rates of her clients:</p>
<p><span class="math display">\[\hat{p} = 3 / 62 = 0.048\qquad\text{is used to estimate}\qquad \pi\]</span></p>
</div>
<div class="protip">
<p>Summary measures that summarize a sample of data, such as <span class="math inline">\(\hat{p}\)</span>, are called <strong>statistics</strong>. Numbers that summarize an entire population, such as <span class="math inline">\(\pi\)</span>, are called <strong>parameters</strong>. You can remember this distinction by looking at the first letter of each term:</p>
<blockquote>
<p><strong><em>S</em></strong>tatistics summarize <strong><em>S</em></strong>amples.<br><strong><em>P</em></strong>arameters summarize <strong><em>P</em></strong>opulations.</p>
</blockquote>
<p>We typically use Roman letters to symbolize statistics (e.g., <span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(\hat{p}\)</span>), and Greek letters to symbolize parameters (e.g., <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\pi\)</span>). Since we rarely can measure the entire population, and thus rarely know the actual parameter values, we like to say, “We don’t know Greek, and we don’t know parameters!”</p>
</div>
<div class="workedexample">
<p>Write out hypotheses in both plain and statistical language to test for the association between the consultant’s work and the true complication rate, <span class="math inline">\(\pi\)</span>, for the consultant’s clients.</p>
<hr>
<p>In words:</p>
<blockquote>
<p><span class="math inline">\(H_0\)</span>: There is no association between the consultant’s contributions and the clients’ complication rate.<br><span class="math inline">\(H_A\)</span>: Patients who work with the consultant tend to have a complication rate lower than 10%.</p>
</blockquote>
<p>In statistical language:</p>
<blockquote>
<p><span class="math inline">\(H_0: \pi=0.10\)</span><br><span class="math inline">\(H_A: \pi&lt;0.10\)</span></p>
</blockquote>
</div>
</div>
<div id="steps-3-and-4-null-distribution-and-p-value" class="section level4 unnumbered">
<h4>Steps 3 and 4: Null distribution and p-value<a class="anchor" aria-label="anchor" href="#steps-3-and-4-null-distribution-and-p-value"><i class="fas fa-link"></i></a>
</h4>
<p>To assess these hypotheses, we need to evaluate the possibility of getting a sample proportion as far below the null value, <span class="math inline">\(0.10\)</span>, as what was observed (<span class="math inline">\(0.048\)</span>), <em>if the null hypothesis were true</em>.</p>
<div class="onebox">
<p><strong>Null value of a hypothesis test.</strong></p>
<p>The <strong>null value</strong> is the reference value for the parameter in <span class="math inline">\(H_0\)</span>, and it is sometimes represented with the parameter’s label with a subscript 0 (or “null”), e.g., <span class="math inline">\(\pi_0\)</span> (just like <span class="math inline">\(H_0\)</span>).</p>
</div>
<p>The deviation of the sample statistic from the null hypothesized parameter is usually quantified with a p-value<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Now would be a good time to review the definition of a p-value in Section &lt;a href="foundations-randomization.html#HypothesisTesting"&gt;9.3&lt;/a&gt;!&lt;/p&gt;'><sup>115</sup></a>. The p-value is computed based on the null distribution, which is the distribution of the test statistic if the null hypothesis is true. Supposing the null hypothesis is true, we can compute the p-value by identifying the chance of observing a test statistic that favors the alternative hypothesis at least as strongly as the observed test statistic.</p>
<div class="onebox">
<p><strong>Null distribution.</strong></p>
<p>The <strong>null distribution</strong> of a test statistic is the sampling distribution of that statistic <em>under the assumption of the null hypothesis</em>. It describes how that statistic would vary from sample to sample, if the null hypothesis were true.</p>
<p>The null distribution can be estimated through simulation (simulation-based methods), as in this section, or can be modeled by a mathematical function (theory-based methods), as in Section <a href="inference-one-prop.html#theory-prop">15.1.3</a>.</p>
</div>
<p>We want to identify the sampling distribution of the test statistic (<span class="math inline">\(\hat{p}\)</span>) if the null hypothesis was true. In other words, we want to see how the sample proportion changes due to chance alone. Then we plan to use this information to decide whether there is enough evidence to reject the null hypothesis.</p>
<p>Under the null hypothesis, 10% of liver donors have complications during or after surgery. Suppose this rate was really no different for the consultant’s clients (for <em>all</em> the consultant’s clients, not just the 62 previously measured). If this was the case, we could <em>simulate</em> 62 clients to get a sample proportion for the complication rate from the null distribution.</p>
<p>This is a similar scenario to the one we encountered in Section <a href="foundations-randomization.html#Martian">9.1</a>, with one important difference—the null value is 0.10, not 0.50. Thus, flipping a coin to simulate whether a client had complications would not be simulating under the correct null hypothesis.</p>
<div class="guidedpractice">
<p>What physical object could you use to simulate a random sample of 62 clients who had a 10% chance of complications? How would you use this object?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;One option would be to use a spinner with 10% shaded red, and the rest shaded green. Each spin of the spinner would represent one client. Spin the spinner 62 times and count the number of times the spinner lands on red. The proportion of times the spinner lands on red represents a simulated &lt;span class="math inline"&gt;\(\hat{p}\)&lt;/span&gt; under the assumption that &lt;span class="math inline"&gt;\(\pi = 0.10\)&lt;/span&gt;. Other objects include: a bag of marbles with 10% red marbles and 90% white marbles, or 10 cards where 1 is red and 9 are white. Sampling 62 times with replacement from these collections would simulate one sample of clients.&lt;/p&gt;'><sup>116</sup></a></p>
</div>
<p>Assuming the true complication rate for the consultant’s clients is 10%, each client can be simulated using a bag of marbles with 10% red marbles and 90% white marbles. Sampling a marble from the bag (with 10% red marbles) is one way of simulating whether a patient has a complication <em>if the true complication rate is 10%</em> for the data. If we select 62 marbles and then compute the proportion of patients with complications in the simulation, <span class="math inline">\(\hat{p}_{sim}\)</span>, then the resulting sample proportion is calculated exactly from a sample from the null distribution.</p>
<p>An undergraduate student was paid $2 to complete this simulation. There were 5 simulated cases with a complication and 57 simulated cases without a complication, i.e., <span class="math inline">\(\hat{p}_{sim} = 5/62 = 0.081\)</span>.</p>
<div class="workedexample">
<p>Is this one simulation enough to determine whether or not we should reject the null hypothesis?</p>
<hr>
<p>No. To assess the hypotheses, we need to see a distribution of many <span class="math inline">\(\hat{p}_{sim}\)</span>, not just a <em>single</em> draw from this sampling distribution.</p>
</div>
<p>One simulation isn’t enough to get a sense of the null distribution; many simulation studies are needed. Roughly 10,000 seems sufficient. However, paying someone to simulate 10,000 studies by hand is a waste of time and money. Instead, simulations are typically programmed into a computer, which is much more efficient.</p>
<p>Figure <a href="inference-one-prop.html#fig:nullDistForPHatIfLiverTransplantConsultantIsNotHelpful">15.1</a> shows the results of 10,000 simulated studies. The proportions that are equal to or less than <span class="math inline">\(\hat{p}=0.048\)</span> are shaded. The shaded areas represent sample proportions under the null distribution that provide at least as much evidence as <span class="math inline">\(\hat{p}\)</span> favoring the alternative hypothesis. There were 1222 simulated sample proportions with <span class="math inline">\(\hat{p}_{sim} \leq 0.048\)</span>. We use these to construct the null distribution’s left-tail area and find the p-value: <span class="math display">\[\begin{align}
\text{left tail area }\label{estOfPValueBasedOnSimulatedNullForSingleProportion}
    &amp;= \frac{\text{Number of observed simulations with }\hat{p}_{sim}\leq\text{ 0.048}}{10000}
\end{align}\]</span> Of the 10,000 simulated <span class="math inline">\(\hat{p}_{sim}\)</span>, 1222 were equal to or smaller than <span class="math inline">\(\hat{p}\)</span>. Since the hypothesis test is one-sided, the estimated p-value is equal to this tail area: 0.1222.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:nullDistForPHatIfLiverTransplantConsultantIsNotHelpful"></span>
<img src="14-categorical-one-prop_files/figure-html/nullDistForPHatIfLiverTransplantConsultantIsNotHelpful-1.png" alt="The null distribution for $\hat{p}$, created from 10,000 simulated studies. The left tail, representing the p-value for the hypothesis test, contains 12.22% of the simulations." width="90%"><p class="caption">
Figure 15.1: The null distribution for <span class="math inline">\(\hat{p}\)</span>, created from 10,000 simulated studies. The left tail, representing the p-value for the hypothesis test, contains 12.22% of the simulations.
</p>
</div>
</div>
<div id="step-5-conclusion" class="section level4 unnumbered">
<h4>Step 5: Conclusion<a class="anchor" aria-label="anchor" href="#step-5-conclusion"><i class="fas fa-link"></i></a>
</h4>
<div class="guidedpractice">
<p>Because the estimated p-value is 0.1222, which is not small, we have little to no evidence against the null hypothesis. Explain what this means in plain language in the context of the problem.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;There isn’t sufficiently strong evidence to support the claim that fewer than 10% of the consultant’s clients experience complications. That is, there isn’t sufficiently strong evidence to support an association between the consultant’s work and fewer surgery complications.&lt;/p&gt;"><sup>117</sup></a></p>
</div>
<p></p>
<div class="guidedpractice">
<p>Does the conclusion in the previous Guided Practice imply there is no real association between the surgical consultant’s work and the risk of complications? Explain.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;No. It might be that the consultant’s work is associated with a reduction but that there isn’t enough data to convincingly show this connection.&lt;/p&gt;"><sup>118</sup></a></p>
</div>
<!--
Add this to an Appendix someday!

#### Generating the exact null distribution and p-value  {-} {#exactNullDistributionUsingBinomialModel}

The number of successes in $n$ independent cases can be described using the binomial model, which was introduced in Section \ref{binomialModel}. Recall that the probability of observing exactly $k$ successes is given by
\begin{align} \label{binomialEquationShownForFindingNullDistributionInSmallSamplePropTest}
P(k\text{ successes}) = {n\choose k} p^{k}(1-p)^{n-k} = \frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k}
\end{align}
where $p$ is the true probability of success. The expression ${n\choose k}$ is read as \emph{$n$ choose $k$}, and the exclamation points represent factorials. For instance, $3!$ is equal to $3\times 2\times 1=6$, $4!$ is equal to $4\times 3\times 2\times 1 = 24$, and so on (see Section \ref{binomialModel}).

The tail area of the null distribution is computed by adding up the probability in Equation \eqref{binomialEquationShownForFindingNullDistributionInSmallSamplePropTest} for each $k$ that provides at least as strong of evidence favoring the alternative hypothesis as the data. If the hypothesis test is one-sided, then the p-value is represented by a single tail area. If the test is two-sided, compute the single tail area and double it to get the p-value, just as we have done in the past.

\begin{example}{Compute the exact p-value to check the consultant's claim that her clients' complication rate is below 105.}
Exactly $k=3$ complications were observed in the $n=62$ cases cited by the consultant. Since we are testing against the 10% national average, our null hypothesis is $p=0.10$. We can compute the p-value by adding up the cases where there are 3 or fewer complications:
\begin{align*}
\text{p-value}
    &= \sum_{j=0}^{3} {n\choose j} p^{j}(1-p)^{n-j} \\
    &= \sum_{j=0}^{3} {62\choose j} 0.1^{j}(1-0.1)^{62-j} \\
    &= {62\choose 0} 0.1^{0}(1-0.1)^{62-0} +
        {62\choose 1} 0.1^{1}(1-0.1)^{62-1} \\
    & \qquad + {62\choose 2} 0.1^{2}(1-0.1)^{62-2} +
        {62\choose 3} 0.1^{3}(1-0.1)^{62-3} \\
    &= 0.0015 + 0.0100 + 0.0340 + 0.0755 \\
    &= 0.1210
\end{align*}
This exact p-value is very close to the p-value based on the simulations (0.1222), and we come to the same conclusion. We do not reject the null hypothesis, and there is not statistically significant evidence to support the association.

If it were plotted, the exact null distribution would look almost identical to the simulated null distribution shown in Figure \ref{nullDistForPHatIfLiverTransplantConsultantIsNotHelpful} on page \pageref{nullDistForPHatIfLiverTransplantConsultantIsNotHelpful}.
\end{example}

-->
</div>
</div>
<div id="boot-ci-prop" class="section level3" number="15.1.2">
<h3>
<span class="header-section-number">15.1.2</span> Bootstrap confidence interval for <span class="math inline">\(\pi\)</span><a class="anchor" aria-label="anchor" href="#boot-ci-prop"><i class="fas fa-link"></i></a>
</h3>
<p>A confidence interval provides a range of plausible values for the parameter <span class="math inline">\(\pi\)</span>. If the goal is to produce a range of possible values for a population value, then in an ideal world, we would sample data from the population again and recompute the sample proportion. Then we could do it again. And again. And so on until we have a good sense of the variability of our original estimate. The ideal world where sampling data is free or extremely cheap is almost never the case, and taking repeated samples from a population is usually impossible. So, instead of using a “resample from the population” approach, bootstrapping uses a “resample from the sample” approach.</p>
<p></p>
<div class="workedexample">
<p>Let’s revisit our medical consultant example from Section <a href="inference-one-prop.html#one-prop-null-boot">15.1.1</a>. This consultant tried to attract patients by noting the average complication rate for liver donor surgeries in the US is about 10%, but her clients have had only 3 complications in the 62 liver donor surgeries she has facilitated. This data, however, did not provide sufficient evidence that the consultant’s complication rate was less than 10%, since the p-value was approximately 0.122. Does this mean we can conclude that the consultant’s complication rate was equal to 10%?</p>
<hr>
<p>No! Though our decision was to fail to reject the null hypothesis, this does not mean we have evidence <em>for</em> the null hypothesis—we cannot “accept” the null. The sample proportion was <span class="math inline">\(\hat{p} = 3/62 = 0.048\)</span>, which is our point estimate—or “best guess”—of <span class="math inline">\(\pi\)</span>. It wouldn’t make sense that a sample complication rate of 4.8% gives us evidence that the true complication rate was exactly 10%. It’s plausible that the true complication rate is 10%, but there are a range of plausible values for <span class="math inline">\(\pi\)</span>. In this section, we will use a simulation-based method called <strong>bootstrapping</strong> to generate this range of plausible values for <span class="math inline">\(\pi\)</span> using the observed data.</p>
</div>
<p>In the medical consultant case study, the parameter is <span class="math inline">\(\pi\)</span>, the true probability of a complication for a client of the medical consultant. There is no reason to believe that <span class="math inline">\(\pi\)</span> is exactly <span class="math inline">\(\hat{p} = 3/62\)</span>, but there is also no reason to believe that <span class="math inline">\(\pi\)</span> is particularly far from <span class="math inline">\(\hat{p} = 3/62\)</span>. By sampling with replacement from the data set (a process called <strong>bootstrapping</strong>),<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;If you’re curious where the term “bootstrapping” comes from, it comes from the phrase “lift yourself up by your own bootstraps.” Lifting yourself up by your own bootstraps is analogous to creating more samples from the single original sample.&lt;/p&gt;"><sup>119</sup></a> the variability of the possible <span class="math inline">\(\hat{p}\)</span> values can be approximated, which will allow us to generate a range of plausible values for <span class="math inline">\(\pi\)</span>, i.e., a confidence interval.</p>
<p>Most of the inferential procedures covered in this text are grounded in quantifying how one data set would differ from another when they are both taken from the same population. It doesn’t make sense to take repeated samples from the same population because if you have the means to take more samples, a larger sample size will benefit you more than the exact same sample twice. Instead, we measure how the samples behave under an estimate of the population. Figure <a href="foundations-bootstrapping.html#fig:boot1">10.1</a> shows how an unknown original population of red and white marbles can be estimated by using multiple copies of a sample of seven marbles.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:boot1"></span>
<img src="05/figures/boot1prop1.png" alt="An unknown population of red and white marbles. The estimated population on the right is many copies of the observed sample." width="75%"><p class="caption">
Figure 10.1: An unknown population of red and white marbles. The estimated population on the right is many copies of the observed sample.
</p>
</div>
<p>By taking repeated samples from the estimated population, the variability from sample to sample can be observed. In Figure <a href="foundations-bootstrapping.html#fig:boot2">10.2</a> the repeated bootstrap samples are obviously different both from each other, from the original sample, and from the original population. Recall that the bootstrap samples were taken from the same (estimated) population, and so the differences are due entirely to natural variability in the sampling procedure.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:boot2"></span>
<img src="05/figures/boot1prop2.png" alt="Selecting $k$ random samples from the estimated population created from copies of the observed sample." width="75%"><p class="caption">
Figure 10.2: Selecting <span class="math inline">\(k\)</span> random samples from the estimated population created from copies of the observed sample.
</p>
</div>
<p>By summarizing each of the bootstrap samples (here, using the sample proportion), we see, directly, the variability of the sample proportion of red marbles, <span class="math inline">\(\hat{p}\)</span>, from sample to sample. The distribution of bootstrapped <span class="math inline">\(\hat{p}\)</span>’s for the example scenario is shown in Figure <a href="foundations-bootstrapping.html#fig:boot3">10.3</a>, and the bootstrap distribution for the medical consultant data is shown in Figure <a href="foundations-bootstrapping.html#fig:MedConsBSSim">10.6</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:boot3"></span>
<img src="05/figures/boot1prop3.png" alt="Calculate the sample proportion of red marbles in each bootstrap resample, then plot these simulated sample proportions in a dot plot. The dot plot of sample proportion provides us a sense of how sample proportions would vary from sample to sample if we could take many samples from our original population." width="50%"><img src="14-categorical-one-prop_files/figure-html/boot3-2.png" alt="Calculate the sample proportion of red marbles in each bootstrap resample, then plot these simulated sample proportions in a dot plot. The dot plot of sample proportion provides us a sense of how sample proportions would vary from sample to sample if we could take many samples from our original population." width="50%"><p class="caption">
Figure 10.3: Calculate the sample proportion of red marbles in each bootstrap resample, then plot these simulated sample proportions in a dot plot. The dot plot of sample proportion provides us a sense of how sample proportions would vary from sample to sample if we could take many samples from our original population.
</p>
</div>
<p>It turns out that in practice, it is very difficult for computers to work with an infinite population (with the same proportional breakdown as in the sample). However, there is a physical and computational model which produces an equivalent bootstrap distribution of the sample proportion in a computationally efficient manner. Consider the observed data to be a bag of marbles 3 of which are red and 4 of which are white. By drawing the marbles out of the bag <em>with replacement</em>, we depict the same sampling <strong>process</strong> as was done with the infinitely large estimated population. Note that when sampling the original observations with replacement, a particular marble may end up in the new sample one time, multiple times, or not at all.</p>
<div class="onebox">
<p><strong>Bootstrapping from one sample</strong>.</p>
<ol style="list-style-type: decimal">
<li>Take a random sample of size <span class="math inline">\(n\)</span> from the original sample, <em>with replacement</em>. This is called a <strong>bootstrapped resample</strong>.</li>
<li>Record the sample proportion (or statistic of interest) from the bootstrapped resample. This is called a <strong>bootstrapped statistic</strong>.</li>
<li>Repeat steps (1) and (2) 1000s of times to create a distribution of bootstrapped statistics.</li>
</ol>
</div>
<p>If we apply the bootstrap sampling process to the medical consultant example, we consider each client to be one of the marbles in the bag. There will be 59 white marbles (no complication) and 3 red marbles (complication). If we choose 62 marbles out of the bag (one at a time), replacing each chosen marble after its color is recorded, and compute the proportion of simulated patients with complications, <span class="math inline">\(\hat{p}_{bs}\)</span>, then this “bootstrap” proportion represents a single simulated proportion from the “resample from the sample” approach.</p>
<div class="guidedpractice">
<p>In a simulation of 62 patients conducted by sampling with replacement from the original sample, about how many would we expect to have had a complication?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Since in the original sample, 3 out of 62, or about 5% had complications, we could expect about 5% of the patients (6.2 on average) in the simulation will have a complication, though we will see a little variation from one simulation to the next.&lt;/p&gt;"><sup>120</sup></a></p>
</div>
<p>One simulated bootstrap resample isn’t enough to get a sense of the variability from one bootstrap proportion to another bootstrap proportion, so we repeated the simulation 10,000 times using a computer. Figure <a href="foundations-bootstrapping.html#fig:MedConsBSSim">10.6</a> shows the distribution from the 10,000 bootstrap simulations. The bootstrapped proportions vary from about zero to 0.15. By taking the range of the middle 95% of this distribution, we can construct a <strong>95% bootstrapped confidence interval</strong> for <span class="math inline">\(\pi\)</span>. The 2.5<sup>th</sup> percentile is 0, and the 97.5<sup>th</sup> percentile is 0.113, so the middle 95% of the distribution is the range (0, 0.113). The variability in the bootstrapped proportions leads us to believe that the true risk of complication (the parameter, <span class="math inline">\(\pi\)</span>) is somewhere between 0 and 11.3%.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:MedConsBSSim"></span>
<img src="14-categorical-one-prop_files/figure-html/MedConsBSSim-1.png" alt="The original medical consultant data is bootstrapped 10,000 times. Each simulation creates a sample from the original data where the probability of a complication is $\hat{p} = 3/62$. The bootstrap 2.5 percentile proportion is 0 and the 97.5 percentile is 0.113. The result is: we are confident that, in the population, the true probability of a complication is between 0% and 11.3%." width="90%"><p class="caption">
Figure 10.6: The original medical consultant data is bootstrapped 10,000 times. Each simulation creates a sample from the original data where the probability of a complication is <span class="math inline">\(\hat{p} = 3/62\)</span>. The bootstrap 2.5 percentile proportion is 0 and the 97.5 percentile is 0.113. The result is: we are confident that, in the population, the true probability of a complication is between 0% and 11.3%.
</p>
</div>
<div class="onebox">
<p><strong>95% Bootstrap confidence interval for a population proportion</strong> <span class="math inline">\(\pi\)</span>.</p>
<p>The 95% bootstrap confidence interval for the parameter <span class="math inline">\(\pi\)</span> can be obtained directly using the ordered values <span class="math inline">\(\hat{p}_{boot}\)</span> values — the bootstrapped sample proportions. Consider the sorted <span class="math inline">\(\hat{p}_{boot}\)</span> values, and let <span class="math inline">\(\hat{p}_{boot, 0.025}\)</span> be the 2.5<sup>th</sup> percentile value and <span class="math inline">\(\hat{p}_{boot, 0.975}\)</span> be the 97.5<sup>th</sup> percentile. The 95% confidence interval is given by:</p>
<center>
(<span class="math inline">\(\hat{p}_{boot, 0.025}\)</span>, <span class="math inline">\(\hat{p}_{boot, 0.975}\)</span>)
</center>
</div>
<p>You can find confidence intervals of difference confidence levels by changing the percent of the distribution you take, e.g., locate the middle 90% of the bootstrapped statistics for a 90% confidence interval.</p>
<div class="guidedpractice">
<p>To find the middle 90% of a distribution, which two percentiles would form its boundaries?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The the middle 95% of a distribution would range from the 5&lt;sup&gt;th&lt;/sup&gt; percentile (the value with 5% of the distribution below) to the 95&lt;sup&gt;th&lt;/sup&gt; percentile (the value with 5% of the distribution above).&lt;/p&gt;"><sup>121</sup></a></p>
</div>
<div class="workedexample">
<p>The original claim was that the consultant’s true rate of complication was under the national rate of 10%. Does the interval estimate of 0 to 11.3% for the true probability of complication indicate that the surgical consultant has a lower rate of complications than the national average? Explain.</p>
<hr>
<p>No. Because the interval overlaps 10%, it might be that the consultant’s work is associated with a lower risk of complciations, or it might be that the consulant’s work is associated with a higher risk (i.e., greater than 10%) of complications! Additionally, as previously mentioned, because this is an observational study, even if an association can be measured, there is no evidence that the consultant’s work is the cause of the complication rate (being higher or lower).</p>
</div>
<!--
%However, we currently don't have enough data to say whether the corresponding complication rate is any different than 0.10.
-->
<p></p>
</div>
<div id="theory-prop" class="section level3" number="15.1.3">
<h3>
<span class="header-section-number">15.1.3</span> Theory-based inferential methods for <span class="math inline">\(\pi\)</span><a class="anchor" aria-label="anchor" href="#theory-prop"><i class="fas fa-link"></i></a>
</h3>
<p>In Section <a href="#var-stat"><strong>??</strong></a>, we introduced the normal distribution and showed how it can be used as a mathematical model to describe the variability of a sample mean or sample proportion as a result of the Central Limit Theorem. We explored the normal distribution further in Section <a href="foundations-mathematical.html#normal">11.2</a>. Theory-based hypothesis tests and confidence intervals for proportions use the normal distribution to calculate the p-value and to determine the width of the confidence interval.</p>
<div class="onebox">
<p><strong>Central Limit Theorem for the sample proportion.</strong></p>
<p>When we collect a sufficiently large sample of <span class="math inline">\(n\)</span> independent observations of a categorical variable from a population with <span class="math inline">\(\pi\)</span> proportion of successes, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> will be nearly normal with <span class="math display">\[\begin{align*}
  &amp;\text{Mean}=\pi
  &amp;&amp;\text{Standard Deviation }(SD) = \sqrt{\frac{\pi(1-\pi)}{n}}
  \end{align*}\]</span></p>
</div>
<div id="evaluating-the-two-conditions-required-for-modeling-hatp-using-theory-based-methods" class="section level4 unnumbered">
<h4>Evaluating the two conditions required for modeling <span class="math inline">\(\hat{p}\)</span> using theory-based methods<a class="anchor" aria-label="anchor" href="#evaluating-the-two-conditions-required-for-modeling-hatp-using-theory-based-methods"><i class="fas fa-link"></i></a>
</h4>
<p>There are two conditions required to apply the Central Limit Theorem for a sample proportion <span class="math inline">\(\hat{p}\)</span>. When the sample observations are independent and the sample size is sufficiently large, the normal model will describe the variability in sample proportions quite well; when the observations violate the conditions, the normal model can be inaccurate.</p>
<div class="onebox">
<p><strong>Conditions for the sampling distribution of</strong> <span class="math inline">\(\hat{p}\)</span> to be approximately normal.</p>
<p>The sampling distribution for <span class="math inline">\(\hat{p}\)</span> based on a sample of size <span class="math inline">\(n\)</span> from a population with a true proportion <span class="math inline">\(\pi\)</span> can be modeled using a normal distribution when:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Independence.</strong> The sample observations are independent, i.e., the outcome of one observation does not influence the outcome of another. This condition is met if data come from a simple random sample of the target population.</p></li>
<li><p><strong>Success-failure condition.</strong> We expected to see at least 10 successes and 10 failures in the sample, i.e., <span class="math inline">\(n\pi\geq10\)</span> and <span class="math inline">\(n(1-\pi)\geq10\)</span>. This condition is met if we have at least 10 successes and 10 failures in the observed data.</p></li>
</ol>
<p>When these conditions are satisfied, then the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is approximately normal with mean <span class="math inline">\(\pi\)</span> and standard deviation <span class="math inline">\(\sqrt{\frac{\ \pi(1-\pi)\ }{n}}\)</span>.</p>
</div>
<p> </p>
<div class="protip">
<p>The success-failure condition listed above is only necessary for the sampling distribution of <span class="math inline">\(\hat{p}\)</span> to be approximately normal. The mean of the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is <span class="math inline">\(\pi\)</span>, and the standard deviation is <span class="math inline">\(\sqrt{\frac{\ \pi(1-\pi)\ }{n}}\)</span>, regardless of the sample size.</p>
</div>
<p>Typically we don’t know the true proportion <span class="math inline">\(\pi\)</span>, so we substitute some value to check the success-failure condition and to estimate the standard deviation of the sampling distribution of <span class="math inline">\(\hat{p}\)</span>. The independence condition is a more nuanced requirement. When it isn’t met, it is important to understand how and why it isn’t met. For example, <em>there exist no statistical methods available to truly correct the inherent biases of data from a convenience sample.</em> On the other hand, if we took a cluster random sample (see Section <a href="data-design.html#samp-methods">2.1.5</a>), the observations wouldn’t be independent, but suitable statistical methods are available for analyzing the data (but they are beyond the scope of even most second or third courses in statistics)<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;While this book is scoped to well-constrained statistical problems, do remember that this is just the first book in what is a large library of statistical methods that are suitable for a very wide range of data and contexts.&lt;/p&gt;"><sup>122</sup></a>.</p>
<div class="workedexample">
<p>In the examples based on large sample theory, we modeled <span class="math inline">\(\hat{p}\)</span> using the normal distribution. Why is this not appropriate for the study on the medical consultant?</p>
<hr>
<p>The independence assumption may be reasonable if each of the surgeries is from a different surgical team. However, the success-failure condition is not satisfied. Under the null hypothesis, we would anticipate seeing <span class="math inline">\(62\times 0.10=6.2\)</span> complications, not the 10 required for the normal approximation.</p>
</div>
<p>Since theory-based methods cannot be used on the medical consultant example, we’ll turn to another example to demonstrate these methods, where conditions for approximating the distribution of <span class="math inline">\(\hat{p}\)</span> by a normal distribution are met.</p>
</div>
<div id="payday-lenders" class="section level4" number="15.1.3.1">
<h4>
<span class="header-section-number">15.1.3.1</span> Hypothesis test for <span class="math inline">\(H_0: \pi = \pi_0\)</span><a class="anchor" aria-label="anchor" href="#payday-lenders"><i class="fas fa-link"></i></a>
</h4>
<p>One possible regulation for payday lenders is that they would be required to do a credit check and evaluate debt payments against the borrower’s finances. We would like to know: would borrowers support this form of regulation?</p>
<div class="workedexample">
<p>Set up hypotheses to evaluate whether borrowers have a majority support for this type of regulation. We take “majority” to mean greater than 50% of the population.</p>
<hr>
<p>In words,</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: there is not majority support for the regulation</li>
<li>
<span class="math inline">\(H_A\)</span>: the majority of borrowers support the regulation</li>
</ul>
<p>In statistical notation,</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: <span class="math inline">\(\pi = 0.50\)</span>
</li>
<li>
<span class="math inline">\(H_A\)</span>: <span class="math inline">\(\pi &gt; 0.50\)</span>,</li>
</ul>
<p>where <span class="math inline">\(\pi\)</span> represents the proportion of <em>all</em> payday loan borrowers that would support the regulation.</p>
</div>
<div class="protip">
<p>Note that the null hypothesis above was stated as <span class="math inline">\(H_0: \pi = 0.50\)</span>, even though saying there is “not majority support” would imply <span class="math inline">\(\pi \leq 0.50\)</span>. Indeed, some textbooks would write <span class="math inline">\(H_0: \pi \leq 0.50\)</span> in this case, and it is not an incorrect statement. However, when calculating the p-value, we need to assume a particular value for <span class="math inline">\(\pi\)</span> under the null hypothesis, so in this textbook, our null hypothesis will always be of the form:</p>
<p><span class="math display">\[
H_0: \mbox{ parameter } = \mbox{ null value}
\]</span></p>
</div>
<p>To apply the normal distribution to model the null distribution, the independence and success-failure conditions must be satisfied. In a hypothesis test, the success-failure condition is checked using the null proportion: we verify <span class="math inline">\(n\pi_0\)</span> and <span class="math inline">\(n(1-\pi_0)\)</span> are at least 10, where <span class="math inline">\(\pi_0\)</span> is the null value.</p>
<div class="guidedpractice">
<p>Do payday loan borrowers support a regulation that would require lenders to pull their credit report and evaluate their debt payments? From a random sample of 826 borrowers, 51% said they would support such a regulation. Is it reasonable use a normal distribution to model <span class="math inline">\(\hat{p}\)</span> for a hypothesis test here?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Independence holds since the poll is based on a random sample. The success-failure condition also holds, which is checked using the null value (&lt;span class="math inline"&gt;\(p_0 = 0.5\)&lt;/span&gt;) from &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;: &lt;span class="math inline"&gt;\(np_0 = 826 \times 0.5 = 413\)&lt;/span&gt;, &lt;span class="math inline"&gt;\(n(1 - p_0) = 826 \times 0.5 = 413\)&lt;/span&gt;. Recall that here, the best guess for &lt;span class="math inline"&gt;\(\pi\)&lt;/span&gt; is &lt;span class="math inline"&gt;\(p_0\)&lt;/span&gt; which comes from the null hypothesis (because we assume the null hypothesis is true when performing the testing procedure steps). &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;: there is not support for the regulation; &lt;span class="math inline"&gt;\(H_0\)&lt;/span&gt;: &lt;span class="math inline"&gt;\(\pi \leq 0.50\)&lt;/span&gt;. &lt;span class="math inline"&gt;\(H_A\)&lt;/span&gt;: the majority of borrowers support the regulation; &lt;span class="math inline"&gt;\(H_A\)&lt;/span&gt;: &lt;span class="math inline"&gt;\(\pi &amp;gt; 0.50\)&lt;/span&gt;.&lt;/p&gt;'><sup>123</sup></a></p>
</div>
<div class="workedexample">
<p>Continuing the previous Example, evaluate whether the poll on lending regulations provides convincing evidence that a majority of payday loan borrowers support a new regulation that would require lenders to pull credit reports and evaluate debt payments.</p>
<hr>
<p>With hypotheses already set up and conditions checked, we can move onto calculations. The <strong>null standard error</strong> in the context of a one proportion hypothesis test is computed using the null value, <span class="math inline">\(\pi_0\)</span>: <span class="math display">\[\begin{align*}
  SE_0(\hat{p}) = \sqrt{\frac{\pi_0 (1 - \pi_0)}{n}}
      = \sqrt{\frac{0.5 (1 - 0.5)}{826}}
      = 0.017
  \end{align*}\]</span> A picture of the normal model for the null distribution of sample proportions in this scenario is shown below in Figure <a href="inference-one-prop.html#fig:paydayCC-norm-pvalue">15.2</a>, with the p-value represented by the shaded region. Note that this null distribution is centered at 0.50, the null value, and has standard deviation 0.017.</p>
<p>Under <span class="math inline">\(H_0\)</span>, the probability of observing <span class="math inline">\(\hat{p} = 0.51\)</span> or higher is 0.278, the area above 0.51 on the null distribution.</p>
<p>With a p-value of 0.278, the poll does not provide convincing evidence that a majority of payday loan borrowers support regulations around credit checks and evaluation of debt payments.</p>
<p>You’ll note that this conclusion is somewhat unsatisfactory because there is no conclusion, as is the case with larger p-values. That is, there is no resolution one way or the other about public opinion. We cannot claim that exactly 50% of people support the regulation, but we cannot claim a majority support it either.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:paydayCC-norm-pvalue"></span>
<img src="14-categorical-one-prop_files/figure-html/paydayCC-norm-pvalue-1.png" alt="Approximate sampling distribution of $\hat{p}$ across all possible samples assuming $\pi = 0.50$. The shaded area represents the p-value corresponding to an observed sample proportion of 0.51." width="90%"><p class="caption">
Figure 15.2: Approximate sampling distribution of <span class="math inline">\(\hat{p}\)</span> across all possible samples assuming <span class="math inline">\(\pi = 0.50\)</span>. The shaded area represents the p-value corresponding to an observed sample proportion of 0.51.
</p>
</div>
<p>Often, with theory-based methods, we use a <strong>standardized statistic</strong> rather than the original statistic as our test statistic. A standardized statistic is computed by subtracting the mean of the null distribution from the original statistic, then dividing by the standard error: <span class="math display">\[
\mbox{standardized statistic} = \frac{\mbox{observed statistic} - \mbox{null value}}{\mbox{null standard error}}
\]</span> The <strong>null standard error</strong> (<span class="math inline">\(SE_0(\text{statistic})\)</span>) of the observed statistic is its estimated standard deviation assuming the null hypothesis is true. We can interpret the standardized statistic as <em>the number of standard errors our observed statistic is above (if positive) or below (if negative) the null value</em>. When we are modeling the null distribution with a normal distribution, this standardized statistic is called <span class="math inline">\(Z\)</span>, since it is the Z-score of the sample proportion.</p>
<div class="onebox">
<p><strong>Standardized sample proportion.</strong></p>
<p>The <strong>standardized statistic</strong> for theory-based methods for one proportion is <span class="math display">\[
Z = \frac{\hat{p} - \pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}} = \frac{\hat{p} - \pi_0}{SE_0(\hat{p})}
\]</span> where <span class="math inline">\(\pi_0\)</span> is the null value. The denominator, <span class="math inline">\(SE_0(\hat{p}) = \sqrt{\frac{\pi_0(1-\pi_0)}{n}}\)</span>, is called the <strong>null standard error</strong> of the sample proportion.</p>
</div>
<p>With the standardized statistic as our test statistic, we can find the p-value as the area under a standard normal distribution at or more extreme than our observed <span class="math inline">\(Z\)</span> value.</p>
<div class="workedexample">
<p>Do payday loan borrowers support a regulation that would require lenders to pull their credit report and evaluate their debt payments? From a random sample of 826 borrowers, 51% said they would support such a regulation. We set up hypotheses and checked conditions previously. Now calculate and interpret the standardized statistic, then use the standard normal distribution to calculate the approximate p-value.</p>
<hr>
<p>Our sample proportion is <span class="math inline">\(\hat{p} = 0.51\)</span>. Since our null value is <span class="math inline">\(\pi_0 = 0.50\)</span>,<br>
the null standard error is <span class="math display">\[\begin{align*}
  SE_0(\hat{p}) = \sqrt{\frac{\pi_0 (1 - \pi_0)}{n}}
      = \sqrt{\frac{0.5 (1 - 0.5)}{826}}
      = 0.017
  \end{align*}\]</span></p>
<p>The standardized statistic is <span class="math display">\[\begin{align*}
Z = \frac{0.51 - 0.50}{0.017} = 0.59
\end{align*}\]</span></p>
<p>Interpreting this value, we can say that our sample proportion of 0.51 was only 0.59 standard errors above the null value of 0.50.</p>
<p>Shown in Figure <a href="inference-one-prop.html#fig:paydayCC-stdnorm-pvalue">15.3</a>, the p-value is the area above <span class="math inline">\(Z = 0.59\)</span> on a standard normal distribution—0.278—the same p-value we would obtain by finding the area above <span class="math inline">\(\hat{p} = 0.51\)</span> on a normal distribution with mean 0.50 and standard deviation 0.017, as in Figure <a href="inference-one-prop.html#fig:paydayCC-norm-pvalue">15.2</a>.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:paydayCC-stdnorm-pvalue"></span>
<img src="14-categorical-one-prop_files/figure-html/paydayCC-stdnorm-pvalue-1.png" alt="Approximate sampling distribution of \(Z\) across all possible samples assuming \(\pi = 0.50\). The shaded area represents the p-value corresponding to an observed standardized statistic of 0.59. Compare to Figure 15.2." width="90%"><p class="caption">
Figure 15.3: Approximate sampling distribution of <span class="math inline">\(Z\)</span> across all possible samples assuming <span class="math inline">\(\pi = 0.50\)</span>. The shaded area represents the p-value corresponding to an observed standardized statistic of 0.59. Compare to Figure <a href="inference-one-prop.html#fig:paydayCC-norm-pvalue">15.2</a>.
</p>
</div>

<div class="onebox">
<p><strong>Theory-based hypothesis test for a proportion: one-sample</strong> <span class="math inline">\(Z\)</span>-test.</p>
<ol style="list-style-type: decimal">
<li>Frame the research question in terms of hypotheses.</li>
<li>Using the null value, <span class="math inline">\(\pi_0\)</span>, verify the conditions for using the normal distribution to approximate the null distribution.</li>
<li>Calculate the test statistic: <span class="math display">\[
Z = \frac{\hat{p} - \pi_0}{\sqrt{\frac{\pi_0(1-\pi_0)}{n}}} = \frac{\hat{p} - \pi_0}{SE_0(\hat{p})}
\]</span>
</li>
<li>Use the test statistic and the standard normal distribution to calculate the p-value.</li>
<li>Make a conclusion based on the p-value, and write a conclusion in context, in plain language, and in terms of the alternative hypothesis.</li>
</ol>
</div>
<!-- Move this paragraph to the right place: -->
<p>Regardless of the statistical method chosen, the p-value is always derived by analyzing the null distribution of the test statistic. The normal model poorly approximates the null distribution for <span class="math inline">\(\hat{p}\)</span> when the success-failure condition is not satisfied. As a substitute, we can generate the null distribution using simulated sample proportions and use this distribution to compute the tail area, i.e., the p-value. Neither the p-value approximated by the normal distribution nor the simulated p-value are exact, because the normal distribution and simulated null distribution themselves are not exact, only a close approximation. An exact p-value can be generated using the binomial distribution, but that method will not be covered in this text.</p>
<p></p>
</div>
<div id="confidence-interval-for-pi" class="section level4 unnumbered">
<h4>Confidence interval for <span class="math inline">\(\pi\)</span><a class="anchor" aria-label="anchor" href="#confidence-interval-for-pi"><i class="fas fa-link"></i></a>
</h4>
<p></p>
<p>A confidence interval provides a range of plausible values for the parameter <span class="math inline">\(\pi\)</span>. A point estimate is our best guess for the value of the parameter, so it makes sense to build the confidence interval around that value. The standard error, which is a measure of the uncertainty associated with the point estimate, provides a guide for how large we should make the confidence interval. When <span class="math inline">\(\hat{p}\)</span> can be modeled using a normal distribution, the 68-95-99.7 rule tells us that, in general, 95% of observations are within 2 standard errors of the mean. Here, we use the value 1.96 to be slightly more precise. The confidence interval for <span class="math inline">\(\pi\)</span> then takes the form <span class="math display">\[\begin{align*}
\hat{p} \pm z^{\star} \times SE(\hat{p}).
\end{align*}\]</span></p>
<p>We have seen <span class="math inline">\(\hat{p}\)</span> to be the sample proportion. The value <span class="math inline">\(z^{\star}\)</span> comes from a standard normal distribution and is determined by the chosen confidence level. The value of the standard error of <span class="math inline">\(\hat{p}\)</span>, <span class="math inline">\(SE(\hat{p})\)</span>, approximates how far we would expect the sample proportion to fall from <span class="math inline">\(\pi\)</span>, and depends heavily on the sample size.</p>
<div class="guidedpractice">
<p><strong>Standard error of one proportion,</strong> <span class="math inline">\(\hat{p}\)</span>.</p>
<p>When the conditions are met so that the distribution for <span class="math inline">\(\hat{p}\)</span> is nearly normal, the <strong>variability</strong> of a single proportion, <span class="math inline">\(\hat{p}\)</span> is well described by its standard deviation:</p>
<p><span class="math display">\[SD(\hat{p}) = \sqrt{\frac{\pi(1-\pi)}{n}}\]</span></p>
<p>Note that we almost never know the true value of <span class="math inline">\(\pi\)</span>, but we can substitute our best guess of <span class="math inline">\(\pi\)</span> to obtain an approximate standard deviation, called the <strong>standard error</strong> of <span class="math inline">\(\hat{p}\)</span>:</p>
<p><span class="math display">\[SD(\hat{p}) \approx \hspace{3mm} SE(\hat{p}) = \sqrt{\frac{(\mbox{best guess of }\pi)(1 - \mbox{best guess of }\pi)}{n}}\]</span></p>
<p>For hypothesis testing, we often use <span class="math inline">\(\pi_0\)</span> as the best guess of <span class="math inline">\(\pi\)</span>, as seen in Section <a href="inference-one-prop.html#theory-prop">15.1.3</a>. For confidence intervals, we typically use <span class="math inline">\(\hat{p}\)</span> as the best guess of <span class="math inline">\(\pi\)</span>.</p>
</div>
<p></p>
<!--
\newcommand{\paydayN}{826}
\newcommand{\paydayNHalf}{413}
\newcommand{\paydayRegPerc}{70\%}
\newcommand{\paydayRegProp}{0.70}
\newcommand{\paydayRegSE}{0.016}
\newcommand{\paydayRegSEPerc}{1.6\%}
\newcommand{\paydayRegLower}{0.669}
\newcommand{\paydayRegUpper}{0.731}
\newcommand{\paydayRegLowerPerc}{66.9\%}
\newcommand{\paydayRegUpperPerc}{73.1\%}
% https://www.pewtrusts.org/-/media/assets/2017/04/payday-loan-customers-want-more-protections-methodology.pdf

did search and replace for each term above.  for example 826 for 826

-->
<div class="guidedpractice">
<p>Consider taking many polls of registered voters (i.e., random samples) of size 300 and asking them if they support legalized marijuana. It is suspected that about 2/3 of all voters support legalized marijuana. To understand how the sample proportion (<span class="math inline">\(\hat{p}\)</span>) would vary across the samples, calculate the standard error of <span class="math inline">\(\hat{p}\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Because the &lt;span class="math inline"&gt;\(\pi\)&lt;/span&gt; is unknown but expected to be around 2/3, we will use 2/3 in place of &lt;span class="math inline"&gt;\(\pi\)&lt;/span&gt; in the formula for the standard deviation of &lt;span class="math inline"&gt;\(\hat{p}\)&lt;/span&gt; and calculate&lt;br&gt;&lt;span class="math inline"&gt;\(SE(\hat{p}) = \sqrt{\frac{2/3 (1 - 2/3)} {300}} = 0.027\)&lt;/span&gt;.&lt;/p&gt;'><sup>124</sup></a></p>
</div>
<div class="workedexample">
<p>A simple random sample of 826 payday loan borrowers was surveyed to better understand their interests around regulation and costs. 51% of the responses supported new regulations on payday lenders.</p>
<ol style="list-style-type: decimal">
<li><p>Is it reasonable to model the variability of <span class="math inline">\(\hat{p}\)</span> from sample to sample using a normal distribution?</p></li>
<li><p>Calculate the standard error of <span class="math inline">\(\hat{p}\)</span>.</p></li>
<li><p>Construct a 95% confidence interval for <span class="math inline">\(\pi\)</span>, the proportion of <em>all</em> payday borrowers who support increased regulation for payday lenders.</p></li>
</ol>
<hr>
<ol style="list-style-type: decimal">
<li>
<p>The data are a random sample, so the observations are independent and representative of the population of interest.</p>
<p>We also must check the success-failure condition, which we do using <span class="math inline">\(\hat{p}\)</span> in place of <span class="math inline">\(\pi\)</span> when computing a confidence interval:</p>
<p>Support: <span class="math inline">\(n \hat{p} = 826 \times 0.51 \approx 421 &gt; 10\)</span></p>
<p>Not: <span class="math inline">\(n (1 - \hat{p}) = 826 \times (1 - 0.51) \approx 405 &gt; 10\)</span></p>
<p>Since both values are at least 10, we can use the normal distribution to model the sampling distribution of <span class="math inline">\(\hat{p}\)</span>.</p>
</li>
<li>
<p>Because <span class="math inline">\(\pi\)</span> is unknown and the standard error is for a confidence interval, use <span class="math inline">\(\hat{p}\)</span> as our best guess of <span class="math inline">\(\pi\)</span> in the formula.</p>
<p><span class="math inline">\(SE(\hat{p}) = \sqrt{\frac{0.51 (1 - 0.51)} {826}} = 0.017\)</span>.</p>
</li>
<li><p>Using the point estimate <span class="math inline">\(0.51\)</span>, <span class="math inline">\(z^{\star} = 1.96\)</span> for a 95% confidence interval, and the standard error <span class="math inline">\(SE = 0.017\)</span> from the previous Guided Practice, the confidence interval is <span class="math display">\[\begin{align*}
  \text{point estimate} &amp;\pm\ z^{\star} \times SE \\
   \quad\to\quad
   0.51 \ &amp;\pm\ 1.96 \times 0.017 \\
   \quad\to\quad
   (0.477, &amp;0.543)
  \end{align*}\]</span> We are 95% confident that the true proportion of payday borrowers who supported regulation at the time of the poll was between 0.477 and 0.543.</p></li>
</ol>
</div>
<div class="onebox">
<p><strong>Constructing a confidence interval for a single proportion.</strong></p>
<p>There are four steps to constructing a confidence interval for <span class="math inline">\(p\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Check independence and the success-failure condition using <span class="math inline">\(\hat{p}\)</span>. If the conditions are met, the sampling distribution of <span class="math inline">\(\hat{p}\)</span> may be well-approximated by the normal model.</li>
<li>Construct the standard error: <span class="math display">\[
SE(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
  \]</span>
</li>
<li>Use statistical software to find the multiplier <span class="math inline">\(z^{\star}\)</span> corresponding to the confidence level.</li>
<li>Apply the general confidence interval formula <span class="math inline">\(\mbox{statistic} \pm (\mbox{multiplier}) \times SE\)</span>: <span class="math display">\[
\hat{p} \pm z^{\star}\times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
  \]</span>
</li>
</ol>
</div>
</div>
<div id="zstar-and-the-confidence-level" class="section level4 unnumbered">
<h4>
<span class="math inline">\(z^{\star}\)</span> and the confidence level<a class="anchor" aria-label="anchor" href="#zstar-and-the-confidence-level"><i class="fas fa-link"></i></a>
</h4>
<p></p>
<p>Suppose we want to consider confidence intervals where the confidence level is somewhat higher than 95%: perhaps we would like a confidence level of 99%. Think back to the analogy about trying to catch a fish: if we want to be more sure that we will catch the fish, we should use a wider net. To create a 99% confidence level, we must also widen our 95% interval. On the other hand, if we want an interval with lower confidence, such as 90%, we could make our original 95% interval slightly slimmer.</p>
<p>The 95% confidence interval structure provides guidance in how to make intervals with new confidence levels. Below is a general 95% confidence interval for a parameter whose point estimate has a nearly normal distribution: <span class="math display">\[\begin{eqnarray}
\text{point estimate}\ \pm\ 1.96\times SE
\end{eqnarray}\]</span> There are three components to this interval: the point estimate, “1.96”, and the standard error. The choice of <span class="math inline">\(1.96\times SE\)</span> was based on capturing 95% of the sampling distribution of statistics since the point estimate is within 1.96 standard errors of the true parameter about 95% of the time. The choice of 1.96 corresponds to a 95% <strong>confidence level</strong>.</p>
<div class="guidedpractice">
<p>If <span class="math inline">\(X\)</span> is a normally distributed random variable, how often will <span class="math inline">\(X\)</span> be within 2.58 standard deviations of the mean?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;This is equivalent to asking how often the &lt;span class="math inline"&gt;\(Z\)&lt;/span&gt; score will be larger than -2.58 but less than 2.58. (For a picture, see Figure &lt;a href="inference-one-prop.html#fig:choosingZForCI"&gt;15.4&lt;/a&gt;.) To determine this probability, look up -2.58 and 2.58 in the normal probability table (0.0049 and 0.9951). Thus, there is a &lt;span class="math inline"&gt;\(0.9951-0.0049 \approx 0.99\)&lt;/span&gt; probability that the unobserved random variable &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; will be within 2.58 standard deviations of the mean.&lt;/p&gt;'><sup>125</sup></a></p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:choosingZForCI"></span>
<img src="14-categorical-one-prop_files/figure-html/choosingZForCI-1.png" alt="The area between -$z^{\star}$ and $z^{\star}$ increases as $|z^{\star}|$ becomes larger. If the confidence level is 99%, we choose $z^{\star}$ such that 99% of the normal curve is between -$z^{\star}$ and $z^{\star}$, which corresponds to 0.5% in the lower tail and 0.5% in the upper tail: $z^{\star}=2.58$." width="90%"><p class="caption">
Figure 15.4: The area between -<span class="math inline">\(z^{\star}\)</span> and <span class="math inline">\(z^{\star}\)</span> increases as <span class="math inline">\(|z^{\star}|\)</span> becomes larger. If the confidence level is 99%, we choose <span class="math inline">\(z^{\star}\)</span> such that 99% of the normal curve is between -<span class="math inline">\(z^{\star}\)</span> and <span class="math inline">\(z^{\star}\)</span>, which corresponds to 0.5% in the lower tail and 0.5% in the upper tail: <span class="math inline">\(z^{\star}=2.58\)</span>.
</p>
</div>
<p></p>
<p>To create a 99% confidence interval, change 1.96 in the 95% confidence interval formula to be 2.58. The previous Guided Practice highlights that 99% of the time a normal random variable will be within 2.58 standard deviations of its mean. This approach—using the Z-scores in the normal model to compute confidence levels—is appropriate when the point estimate is associated with a normal distribution and we can properly compute the standard error. Thus, the formula for a 99% confidence interval is:</p>
<span class="math display">\[\begin{eqnarray*}
\text{point estimate}\ \pm\ 2.58\times SE
\end{eqnarray*}\]</span>
<!--
label for previous equation?
\label{99PercCIForMean}
\label{99PercCIForNormalPointEstimate}

%\Comment{I don't know where the equation number above gets referenced. Might drop the equation number.}
-->
<p>The normal approximation is crucial to the precision of the <span class="math inline">\(z^\star\)</span> confidence intervals. When the normal model is not a good fit, we will use alternative distributions that better characterize the sampling distribution or we will use bootstrapping procedures.</p>
<div class="guidedpractice">
<p>Create a 99% confidence interval for the impact of the stent on the risk of stroke using the data from Section <a href="intro-to-data.html#basic-stents-strokes">1.1</a>. The point estimate is 0.090, and the standard error is <span class="math inline">\(SE = 0.028\)</span>. It has been verified for you that the point estimate can reasonably be modeled by a normal distribution.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Since the necessary conditions for applying the normal model have already been checked for us, we can go straight to the construction of the confidence interval: &lt;span class="math inline"&gt;\(\text{point estimate}\ \pm\ 2.58 \times SE \rightarrow (0.018, 0.162)\)&lt;/span&gt;. We are 99% confident that implanting a stent in the brain of a patient who is at risk of stroke increases the risk of stroke within 30 days by a rate of 0.018 to 0.162 (assuming the patients are representative of the population).&lt;/p&gt;'><sup>126</sup></a></p>
</div>
<div class="onebox">
<p><strong>Theory-based</strong> <span class="math inline">\((1-\alpha)\times 100\)</span>% confidence interval.</p>
<p>If the statistic follows the normal model with standard error <span class="math inline">\(SE\)</span>, then a confidence interval for the population parameter is <span class="math display">\[\begin{eqnarray*}
\text{statistic}\ \pm\ z^{\star} \times SE
\end{eqnarray*}\]</span> where <span class="math inline">\(z^{\star}\)</span> corresponds to the confidence level selected: the middle <span class="math inline">\((1-\alpha)\times 100\)</span>% of a standard normal distribution lies between <span class="math inline">\(-z^{\star}\)</span> and <span class="math inline">\(z^{\star}\)</span>.</p>
</div>
</div>
<div id="using-r-to-find-zstar" class="section level4 unnumbered">
<h4>Using R to find <span class="math inline">\(z^{\star}\)</span><a class="anchor" aria-label="anchor" href="#using-r-to-find-zstar"><i class="fas fa-link"></i></a>
</h4>
<p>Figure <a href="inference-one-prop.html#fig:choosingZForCI">15.4</a> provides a picture of how to identify <span class="math inline">\(z^{\star}\)</span> based on a confidence level. We select <span class="math inline">\(z^{\star}\)</span> so that the area between -<span class="math inline">\(z^{\star}\)</span> and <span class="math inline">\(z^{\star}\)</span> in the normal model corresponds to the confidence level. In R, you can find <span class="math inline">\(z^{\star}\)</span> using the <code><a href="https://rdrr.io/r/stats/Normal.html">qnorm()</a></code> function:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># z* for 90% --&gt; alpha = 0.15 --&gt; need 5% on each side:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">.90</span> <span class="op">+</span> <span class="fl">.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.645</span></span>
<span></span>
<span><span class="co"># z* for 95% --&gt; alpha = 0.05 --&gt; need 2.5% on each side:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">.95</span> <span class="op">+</span> <span class="fl">.025</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.96</span></span>
<span></span>
<span><span class="co"># z* for 99% --&gt; alpha = 0.01 --&gt; need .5% on each side:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">.99</span> <span class="op">+</span> <span class="fl">.005</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2.576</span></span></code></pre></div>
<div class="guidedpractice">
<p>Previously, we found that implanting a stent in the brain of a patient at risk for a stroke <em>increased</em> the risk of a stroke. The study estimated a 9% increase in the number of patients who had a stroke, and the standard error of this estimate was about <span class="math inline">\(SE = 2.8%\)</span>. Compute a 90% confidence interval for the effect.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;We must find &lt;span class="math inline"&gt;\(z^{\star}\)&lt;/span&gt; such that 90% of the distribution falls between -&lt;span class="math inline"&gt;\(z^{\star}\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(z^{\star}\)&lt;/span&gt; in the standard normal model, &lt;span class="math inline"&gt;\(N(\mu=0, \sigma=1)\)&lt;/span&gt;. We can find -&lt;span class="math inline"&gt;\(z^{\star}\)&lt;/span&gt; from a standard normal distribution by looking for a lower tail of 5% (the other 5% is in the upper tail), thus &lt;span class="math inline"&gt;\(z^{\star}=1.645\)&lt;/span&gt;. The 90% confidence interval can then be computed as &lt;span class="math inline"&gt;\(\text{point estimate}\ \pm\ 1.65\times SE \to (4.4\%, 13.6\%)\)&lt;/span&gt;. (Note: The conditions for normality had earlier been confirmed for us.) That is, we are 90% confident that implanting a stent in a stroke patient’s brain increased the risk of stroke within 30 days by 4.4% to 13.6%.&lt;/p&gt;'><sup>127</sup></a></p>
</div>
</div>
<div id="violating-conditions" class="section level4 unnumbered">
<h4>Violating conditions<a class="anchor" aria-label="anchor" href="#violating-conditions"><i class="fas fa-link"></i></a>
</h4>
<p>We’ve spent a lot of time discussing conditions for when <span class="math inline">\(\hat{p}\)</span> can be reasonably modeled by a normal distribution. What happens when the success-failure condition fails? What about when the independence condition fails? In either case, the general ideas of confidence intervals and hypothesis tests remain the same, but the strategy or technique used to generate the interval or p-value change.</p>
<p>When the success-failure condition isn’t met for a hypothesis test, we can simulate the null distribution of <span class="math inline">\(\hat{p}\)</span> using the null value, <span class="math inline">\(\pi_0\)</span>, as seen in Section <a href="inference-one-prop.html#one-prop-null-boot">15.1.1</a>. Unfortunately, methods for dealing with observations which are not independent are outside the scope of this book.</p>
</div>
</div>
</div>
<div id="chp14-review" class="section level2" number="15.2">
<h2>
<span class="header-section-number">15.2</span> Chapter review<a class="anchor" aria-label="anchor" href="#chp14-review"><i class="fas fa-link"></i></a>
</h2>
<div id="summary-10" class="section level3 unnumbered">
<h3>Summary<a class="anchor" aria-label="anchor" href="#summary-10"><i class="fas fa-link"></i></a>
</h3>
<div class="underconstruction">
<p>TODO</p>
</div>
</div>
<div id="terms-10" class="section level3 unnumbered">
<h3>Terms<a class="anchor" aria-label="anchor" href="#terms-10"><i class="fas fa-link"></i></a>
</h3>
<p>We introduced the following terms in the chapter. If you’re not sure what some of these terms mean, we recommend you go back in the text and review their definitions. We are purposefully presenting them in alphabetical order, instead of in order of appearance, so they will be a little more challenging to locate. However you should be able to easily spot them as <strong>bolded text</strong>.</p>
<div class="inline-table"><table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;">
bootstrapping
</td>
<td style="text-align:left;">
null value
</td>
<td style="text-align:left;">
success-failure condition
</td>
</tr>
<tr>
<td style="text-align:left;">
confidence level
</td>
<td style="text-align:left;">
standard error of single proportion
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
null distribution
</td>
<td style="text-align:left;">
statistic
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody></table></div>
</div>
<div id="key-ideas-10" class="section level3 unnumbered">
<h3>Key ideas<a class="anchor" aria-label="anchor" href="#key-ideas-10"><i class="fas fa-link"></i></a>
</h3>
<div class="underconstruction">
<p>TODO</p>
</div>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="foundations-applications.html"><span class="header-section-number">13</span> Applications: Foundations</a></div>
<div class="next"><a href="inference-two-props.html"><span class="header-section-number">16</span> Inference for comparing two proportions</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#inference-one-prop"><span class="header-section-number">15</span> Inference for a single proportion</a></li>
<li>
<a class="nav-link" href="#single-prop"><span class="header-section-number">15.1</span> One proportion</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#one-prop-null-boot"><span class="header-section-number">15.1.1</span> Simulation-based test for \(H_0: \pi = \pi_0\)</a></li>
<li><a class="nav-link" href="#boot-ci-prop"><span class="header-section-number">15.1.2</span> Bootstrap confidence interval for \(\pi\)</a></li>
<li><a class="nav-link" href="#theory-prop"><span class="header-section-number">15.1.3</span> Theory-based inferential methods for \(\pi\)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#chp14-review"><span class="header-section-number">15.2</span> Chapter review</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#summary-10">Summary</a></li>
<li><a class="nav-link" href="#terms-10">Terms</a></li>
<li><a class="nav-link" href="#key-ideas-10">Key ideas</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/MTstateIntroStats/IntroStatTextbook/blob/master/14-categorical-one-prop.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/MTstateIntroStats/IntroStatTextbook/edit/master/14-categorical-one-prop.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Montana State Introductory Statistics with R</strong>" was written by Nicole Carnegie, Stacey Hancock, Elijah Meyer, Jade Schmidt, Melinda Yager. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
