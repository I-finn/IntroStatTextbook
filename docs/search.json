[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"website Montana State Introductory Statistics R.\ntextbook accompanies curriculum STAT 216: Introduction Statistics Montana State University. syllabus course information can found\ncourse webpage.Copyright © 2021.Version date: August 04, 2022.resource largely derivative OpenIntro project textbooks: Introduction Modern Statistics 1st Edition Çetinkaya-Rundel Hardin, OpenIntro Statistics 4th Edition Diez, Çetinkaya-Rundel, Barr, Introduction Statistics Randomization Simulation 1st Edition Diez, Barr, Çetinkaya-Rundel.\nMontana State Introductory Statistics R accompanying resources available Creative Commons Attribution-NonCommercial-ShareAlike 4.0 license unless otherwise noted.\nLicense details available Creative Commons website.Source files book may found GitHub atgithub.com/MTstateIntroStats/IntroStatTextbook.cite resource please use:Carnegie, N., Hancock, S., Meyer, E., Schmidt, J., Yager, M. (2021). Montana State Introductory Statistics R. Montana State University. https://mtstateintrostats.github.io/IntroStatTextbook/. Adapted Çetinkaya-Rundel, M. Hardin, J. (2021). Introduction Modern Statistics. OpenIntro. https://openintro-ims.netlify.app/.","code":""},{"path":"authors.html","id":"authors","chapter":"Authors","heading":"Authors","text":"","code":""},{"path":"authors.html","id":"montana-state-university-authors","chapter":"Authors","heading":"Montana State University Authors","text":"Nicole Carnegie \nFormer Associate Professor Statistics Stacey Hancock \nAssociate Professor Statistics stacey.hancock@montana.edu Elijah Meyer \nFormer PhD Statistics Graduate Student Jade Schmidt \nStudent Success Coordinator Statistics jade.schmidt2@montana.edu Melinda Yager \nAssistant Coordinator Statistics melinda.yager@montana.edu ","code":""},{"path":"authors.html","id":"openintro-authors","chapter":"Authors","heading":"OpenIntro Authors","text":"Mine Çetinkaya-Rundel mine@openintro.org \nDuke University, RStudio Johanna Hardin jo@openintro.org \nPomona College ","code":""},{"path":"preface.html","id":"preface","chapter":"Preface","heading":"Preface","text":"hope readers take away three ideas book addition forming foundation statistical thinking methods.Statistics applied field wide range practical applications.don’t math guru learn interesting, real data.Data messy, statistical tools imperfect. However, understand strengths weaknesses tools, can use learn interesting things world.","code":""},{"path":"preface.html","id":"textbook-overview","chapter":"Preface","heading":"Textbook overview","text":"Part 1: Introduction data. Data structures, variables, basic data collection techniques.Part 2: Exploratory data analysis. Data visualization summarization one variable, relationship two variables, exploring relationships among many variables.Part 3: Foundations inference. introduction ideas statistical inference randomization tests, bootstrap intervals, mathematical models.Part 4: Inference categorical data. Inference one two proportions using simulation randomization techniques well normal distribution.Part 5: Inference quantitative data. Inference one two means using simulation randomization techniques well \\(t\\)-distribution.Part 6: Inference regression. Inference regression slope correlation using simulation randomization techniques well \\(t\\)-distribution.Part 7: Probability. taste probability theory hypothetical two-way tables tree diagrams.part contains multiple chapters ends chapter demonstrating apply methods using RStudio software.chapter ends review section contains chapter summary well list key terms key ideas introduced chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully present alphabetical order, instead order appearance, little challenging locate.\nHowever, able easily spot bolded text.","code":""},{"path":"preface.html","id":"examples-and-exercises","chapter":"Preface","heading":"Examples and exercises","text":"Examples provided establish understanding apply methods.example.\nquestion asked , can answer found?answer can found , solution section example!think reader ready try determining solution , frame Guided Practice.reader may check learn answer Guided Practice problem reviewing full solution footnote.1","code":""},{"path":"preface.html","id":"datasets-and-their-sources","chapter":"Preface","heading":"Datasets and their sources","text":"large majority datasets used book can found various R packages.\ntime new dataset introduced narrative, reference package like one provided.\nMany datasets openintro R package contains datasets used OpenIntro’s open-source textbooks.2The textbooks data can found openintro R package.datasets used throughout book come real sources like opinion polls scientific articles, except handful cases use toy data highlight particular feature explain particular concept.\nReferences sources real data provided end book.","code":""},{"path":"preface.html","id":"stat-216-coursepack","chapter":"Preface","heading":"STAT 216 Coursepack","text":"week, work -class activities team mates guidance instructor. activities, well reading guides guide taking notes required readings videos, included STAT 216 Coursepack. course requires purchase printed copy STAT 216 Coursepack bring class day.coursepack available purchase MSU Bookstore. may purchase coursepack person, may purchase online coursepack shipped . coursepack available MSU Bookstore first day classes. Chapter 1 coursepack provided coursepack first day class.STAT 216 Coursepack: Chapter 1","code":""},{"path":"preface.html","id":"acknowledgements","chapter":"Preface","heading":"Acknowledgements","text":"project possible without talented authors\nOpenIntro open resource textbooks volunteer OpenIntro.\nauthors \nalso like thank Montana State University Library,\ngenerously funded project.","code":""},{"path":"rstudio.html","id":"rstudio","chapter":"Preliminaries: Getting started in RStudio","heading":"Preliminaries: Getting started in RStudio","text":"STAT 216 textbook use R RStudio statistical computing.\nR RStudio free open source. R programming language runs computations, RStudio interface engage R (called “integrated development environment”, IDE). often use “R” “RStudio” interchangeably throughout textbook.preliminaries chapter introduce RStudio environment .\nbegin learn code RStudio Chapter @(#data-applications).","code":""},{"path":"rstudio.html","id":"accessing-rstudio","chapter":"Preliminaries: Getting started in RStudio","heading":"Accessing RStudio","text":"MSU hosts web based version RStudio, can found : rstudio.math.montana.edu.\nnavigate MSU RStudio server, see following sign-screen:username 7-character NetID (form x##x###, x letter # number), password password associated NetID.logging , see RStudio working environment, displayed Figure 0.1 .\nFigure 0.1: RStudio working environment.\nregistered STAT 216 students access server starting first day classes. enrolled course, receive error “Incorrect invalid username/password” attempting log , take following steps:Ensure using 7-character NetID username. form x##x###, x letter # number. email address work log RStudio server.Ensure using correct password associated NetID account. can logging another site requires NetID (e.g., MyInfo) credentials.Reset NetID password password.montana.edu. NetID password expires 180 days day set . password expired, able log RStudio server.tried steps , continue issues logging , please email STAT 216 Faculty Course Supervisor Dr. Stacey Hancock.\nmay also refer following section options accessing RStudio.Note work save server deleted access removed semester ends. Thus, like save files, export computer prior end semester.","code":""},{"path":"rstudio.html","id":"alternative-options-for-accessing-rstudio","chapter":"Preliminaries: Getting started in RStudio","heading":"Alternative options for accessing RStudio","text":"recommend using RStudio MSU RStudio server, options accessing free software:Use RStudio MSU virtual machine. highly recommend installing VMware Horizon Client using virtual machine regularly, using web browser runs risk losing work browser disconnects system (can happen number reasons).\nlog-7-character NetID password.\nSelect “MSU” domain (“GFCMSU” “MSUNORTHERN”).\nUpon logging , select “CLS-STAT-REMOTE” virtual machine. see RStudio icon virtual desktop.\nUse RStudio MSU virtual machine. highly recommend installing VMware Horizon Client using virtual machine regularly, using web browser runs risk losing work browser disconnects system (can happen number reasons).log-7-character NetID password.Select “MSU” domain (“GFCMSU” “MSUNORTHERN”).Upon logging , select “CLS-STAT-REMOTE” virtual machine. see RStudio icon virtual desktop.Use RStudio MSU -campus computer lab.Use RStudio MSU -campus computer lab.Use RStudio RStudio Cloud. resource allows use RStudio web browser. free use, limit certain number project hours per month.Use RStudio RStudio Cloud. resource allows use RStudio web browser. free use, limit certain number project hours per month.Download R RStudio laptop. (Note: R RStudio run iPad, notebooks, Chromebooks.)\nDownload install R.\nDownload install RStudio Desktop.\nInstall catstats package.\nView tutorial video installing R RStudio \nlike additional installation instructions.\nDownload R RStudio laptop. (Note: R RStudio run iPad, notebooks, Chromebooks.)Download install R.Download install RStudio Desktop.Install catstats package.\nView tutorial video installing R RStudio \nlike additional installation instructions.","code":""},{"path":"rstudio.html","id":"packages","chapter":"Preliminaries: Getting started in RStudio","heading":"Packages","text":"Since R open source, users can contribute “packages” (“libraries”) — collections R functions. 16,000 available packages! particular, use\ntidyverse collection packages designed data science.\nSTAT 216 also R package called catstats, contains functions\nrunning simulation-based inference course.","code":""},{"path":"rstudio.html","id":"using-packages","chapter":"Preliminaries: Getting started in RStudio","heading":"Using packages","text":"packages already installed R RStudio, others (tidyverse)\nfirst need installed can used. can install package\nclicking “Packages” tab RStudio clicking “Install” icon.\ncan also install package using install.packages() command.\nusing MSU RStudio server,\nnecessary packages already installed.package installed, need “load” package RStudio session\nusing library() command. example, want load tidyverse package, use following code:Packages need installed , need loaded time start new RStudio session. Think installing package installing light bulb, loading package flipping switch (see Figure 0.23).\nFigure 0.2: Installing (install.packages()) versus loading (library()) R packages.\n","code":"\nlibrary(tidyverse)"},{"path":"rstudio.html","id":"the-catstats-package","chapter":"Preliminaries: Getting started in RStudio","heading":"The catstats package","text":"STAT 216 uses R functions R package called catstats.\npackage already installed RStudio environment MSU RStudio server. However, need “load”\npackage (library) time start new session using following command:running RStudio computer laptop, need first install R packages used course. packages can installed directly within RStudio, catstats needs installed Github (since yet CRAN).use R functions catstats package, need first install remotes package. Functions package used install catstats Github. RStudio console, run following commands:, installation, gives option update \nrecent versions packages, type 1 (choose install ),\ntype Yes asks want install.Note catstats package install packages needed run code textbook,\nneed load packages (e.g., tidyverse) load catstats R session.","code":"\nlibrary(catstats)\ninstall.packages(\"remotes\")\nremotes::install_github(\"greenwood-stat/catstats\")"},{"path":"rstudio.html","id":"projects","chapter":"Preliminaries: Getting started in RStudio","heading":"Projects","text":"RStudio workflow operates best use “Projects”. Think “Project” R session folder. create separate project activity assignment course requires use R:top right corner, see dropdown menu next “Project” currently says “(None)”. Click menu choose “New Project”.Click “File” menu top left select “New Project”.“New Project Wizard” window pop . Click “New Directory”.\n         click “New Project”.Give project directory name (e.g., Assignment1). use spaces characters name.\nClick “Browse” choose location like save project. click “Home” button, leave location “~”, shown . Alternatively, can create new folder store project. Note location server account, computer.\nLeave boxes unchecked, click “Create Project”.\nClick “Browse” choose location like save project. click “Home” button, leave location “~”, shown . Alternatively, can create new folder store project. Note location server account, computer.Leave boxes unchecked, click “Create Project”.notice project name appear folder “Files” window bottom right. click folder, see project file (.Rproj extension). Save script files, data sets, files related project folder.","code":""},{"path":"rstudio.html","id":"r-script-files","chapter":"Preliminaries: Getting started in RStudio","heading":"R script files","text":"can type directly Console > symbol run R code:However, like save code future use, write R commands R script file. script file just text file extension .R.RStudio environment, click “New File” option “File” menu, select “R Script”.window top left RStudio environment appear. script file!","code":"> 3+5\n[1] 8"},{"path":"rstudio.html","id":"try-it","chapter":"Preliminaries: Getting started in RStudio","heading":"Try it!","text":"Open new R script file.Type following commands file:Highlight two lines just typed. Click “Run” button, looks like blank page green right arrow.code output code appear Console window.save script file, click Save icon, go File -> Save. Browse location ’d like save file (folder current Project file), name file, click Save. name R script file changed name chose (e.g., MyFirstScript.R), file appear list files bottom right.","code":"\n3+5\nsqrt(10)#> [1] 8\n#> [1] 3.16"},{"path":"rstudio.html","id":"loading-data","chapter":"Preliminaries: Getting started in RStudio","heading":"Loading data","text":"RStudio can load data variety sources, including .txt, .csv, .xlsx files, can even load data website. activities assignments course, loading data set Stat 216 website. code loading data sets included provided R script file. example, following code load “Current Population Survey” data set Activity 3, save object called “CPS”.running line code, see object CPS appear “Environment” list, information data set contains 534 observations 11 variables measured observations.Clicking name CPS typing command View(CPS) opens new window displays data set.course project, data set file need import RStudio. read data set file RStudio using MSU server, first need upload data set project. data set server account files, can use “Import Dataset” button import data set location.","code":"\nCPS <- read.csv(\"https://math.montana.edu/courses/s216/data/cps.csv\")"},{"path":"rstudio.html","id":"try-it-1","chapter":"Preliminaries: Getting started in RStudio","heading":"Try it!","text":"First, download data sets shown Stat 216 webpage, save computer. website note extension file (e.g., .txt, .csv, .xlsx).RStudio, click “Upload” button “Files” tab bottom right.Click “Browse” button navigate location server like save data set.Click “Choose File”, navigate saved data set computer. Click data set file name, click “Choose Upload”, click “OK”.“Environment” tab, click “Import Dataset”.drop-menu appear, can choose type file data stored. Common formats include text files (e.g., .csv, .txt) — select “Text (readr)” — Excel spreadsheets (.xlsx) — select “Excel”.Click “Browse”, navigate location server data uploaded. RStudio show data preview — observation single row, variable single column. click “Import”.see data object appear “Environment” (name whatever filename ), RStudio open window view data set.","code":""},{"path":"rstudio.html","id":"exporting-files","chapter":"Preliminaries: Getting started in RStudio","heading":"Exporting files","text":"Since working RStudio server, local computer, like use files generated RStudio, first need export .","code":""},{"path":"rstudio.html","id":"exporting-r-script-files","chapter":"Preliminaries: Getting started in RStudio","heading":"Exporting R script files","text":"can export R script files saved server files (type file) checking box next file, clicking “”, “Export”. ask specify name file. click “Download”.","code":""},{"path":"rstudio.html","id":"try-it-2","chapter":"Preliminaries: Getting started in RStudio","heading":"Try it!","text":"Try exporting R script file created .","code":""},{"path":"rstudio.html","id":"exporting-plots","chapter":"Preliminaries: Getting started in RStudio","heading":"Exporting plots","text":"export plot, first need create plot.","code":""},{"path":"rstudio.html","id":"try-it-3","chapter":"Preliminaries: Getting started in RStudio","heading":"Try it!","text":"Copy paste following code script file; highlight code click Run. (see code Activity 3!)bar plot appear “Plots” tab.Click “Export” button, can choose export plot either image file (e.g., .png, .jpeg), pdf file, copy clipboard (e.g., pasting Word document).saving plot computer (rather copying plot), window pop various options. Choose directory computer like save file, give plot name, change dimensions desired, click Save.","code":"\nlibrary(tidyverse) \n\nmyopia <- read.csv(\"https://math.montana.edu/courses/s216/data/ChildrenLightSight.csv\") \n\nmyopia %>% \n  ggplot(aes(y = Light)) +\n  geom_bar(stat = \"count\") +\n  labs(title = \"Frequency Bar Plot of Level of Myopia\",\n       x = \"Frequency\",\n       y = \"Level of Myopia\")  +\n  coord_flip()"},{"path":"rstudio.html","id":"home","chapter":"Preliminaries: Getting started in RStudio","heading":"Home","text":"RStudio environment, next NetID top right corner “home” icon. Click icon, take dashboard., can see many sessions running “Sessions” title, see list projects “Projects” title. can click sessions projects return session/project.","code":""},{"path":"rstudio.html","id":"troubleshooting","chapter":"Preliminaries: Getting started in RStudio","heading":"Troubleshooting","text":"One frustrating things learning using R error message pops . Sometimes error message descriptive, sometimes cryptic. times, error message include line code mistake made.tips happens:missing parentheses? Check opening parentheses associated ending parenthesis.forget comma?something quotes shouldn’t ? something quotes ?type variable object name correctly? R case sensitive, case letters needs match correctly.trying run entire script file, try running line--line see error happens.trying run R function, pull help file function make sure arguments specified correctly. E.g., Type ?lm see help file lm function.Copy--paste error message, input message quotes Google. Searching phrase quotes make sure specific error shows top results.Visit instructor’s office hours Math Learning Center, share screen show error, can help troubleshoot .common error messages reasons include:“find function”. error occurs R package loaded properly due misspelling function data set name. Remember, every R session, need “load” required packages using library command, e.g., code library(catstats) load catstats package.“object found” “error eval”. error occurs particular object question exist empty.“non-numeric argument binary operator”. error may occur ’re trying run function requires numerical vector (e.g., mean), input character vector.Remember, even experienced R users still get errors! ’s part learning process.","code":""},{"path":"rstudio.html","id":"extra-references","chapter":"Preliminaries: Getting started in RStudio","heading":"Extra references","text":"many websites designed provide help use R RStudio, sometimes hard find help right level. additional recommended websites getting started R RStudio STAT 216:RStudio IDE Cheatsheet: annotated picture RStudio environment, coding keyboard shortcuts, probably want know features RStudio, refer two-page “cheatsheet”. RStudio produces many cheatsheets. Data visualization ggplot2 cheatsheet also helpful course.RStudio IDE Cheatsheet: annotated picture RStudio environment, coding keyboard shortcuts, probably want know features RStudio, refer two-page “cheatsheet”. RStudio produces many cheatsheets. Data visualization ggplot2 cheatsheet also helpful course.Using RStudio: RStudio help pages introductory statistics course Gustavus Adolphus College. Like MSU, students use RStudio server; however, use R Markdown documents, slightly involved R script files use STAT 216. pages tips get started, brief instructions creating tables, statistics, plots, theory-based tests.Using RStudio: RStudio help pages introductory statistics course Gustavus Adolphus College. Like MSU, students use RStudio server; however, use R Markdown documents, slightly involved R script files use STAT 216. pages tips get started, brief instructions creating tables, statistics, plots, theory-based tests.R Data Science: book Hadley Wickham (creator tidyverse many R packages resources), much content need, sections particularly helpful:\nRStudio tidyverse?\nrun R code?\nR scripts?\nData visualization ggplot\nR Data Science: book Hadley Wickham (creator tidyverse many R packages resources), much content need, sections particularly helpful:RStudio tidyverse?run R code?R scripts?Data visualization ggplotModernDive: Statistical Inference via Data Science — Chapter 1: Getting Started Data R: Though textbook slightly higher level STAT 216, first chapter gives great explanation exactly R RStudio , explaining differences point--click interfaces “interpreted language” like R. Chapter 2 book gives detailed overview data visualization methods using ggplot2 R package.ModernDive: Statistical Inference via Data Science — Chapter 1: Getting Started Data R: Though textbook slightly higher level STAT 216, first chapter gives great explanation exactly R RStudio , explaining differences point--click interfaces “interpreted language” like R. Chapter 2 book gives detailed overview data visualization methods using ggplot2 R package.R Data: free “course” includes videos interactive elements. Topics include: variables data structures, visualizing data using ggplot2 R package, statistical tests, data wrangling. videos visualizing data particularly helpful first activities course.R Data: free “course” includes videos interactive elements. Topics include: variables data structures, visualizing data using ggplot2 R package, statistical tests, data wrangling. videos visualizing data particularly helpful first activities course.Chester Ismay great argument use R. ’re wondering STAT 216 uses R RStudio instead statistical software, read short chapter.Chester Ismay great argument use R. ’re wondering STAT 216 uses R RStudio instead statistical software, read short chapter.","code":""},{"path":"intro-to-data.html","id":"intro-to-data","chapter":"1 Hello data","heading":"1 Hello data","text":"Scientists seek answer questions using rigorous methods careful observations.\nobservations—collected likes field notes, surveys, experiments—form backbone statistical investigation called data.\nStatistics study best collect, analyze, draw conclusions data, first chapter, focus properties data collection data.Though calculating probabilities 16th century, first US Census directed Thomas Jefferson 17904, discipline statistics know came 1800s. 21st century, statistical investigation process looked something like (adapted Tintle et al. (2016)):Ask research question.Design study collect data.Summarize visualize data.Use statistical analysis methods draw inferences data.Communicate results answer research question.Revisit look forward.rise data science, however, might start research question,\ninstead start data set5.\ncase, statistical investigation process looks like data exploration cycle found Figure 1.1 taken Wickham Grolemund (2017).\nFigure 1.1: Wickham Grolemund’s data exploration cycle (2017).\neither case, ideas, concepts, methods presented book provide tools work statistical investigation process, whether starting research question starting data.","code":""},{"path":"intro-to-data.html","id":"basic-stents-strokes","chapter":"1 Hello data","heading":"1.1 Case study: using stents to prevent strokes","text":"section, introduce classic challenge statistics: evaluating efficacy medical treatment.\nTerms section, indeed much chapter, revisited later text.\nplan now simply get sense role statistics can play practice., consider experiment studies effectiveness stents treating patients risk stroke (Chimowitz et al. 2011).\nStents small mesh tubes placed inside narrow weak arteries assist patient recovery cardiac events reduce risk additional heart attack death.Many doctors hoped similar benefits patients risk stroke. start writing principal question researchers hope answer:use stents reduce risk stroke?researchers asked question conducted experiment 451 -risk patients. volunteer patient randomly assigned one two groups:Treatment group. Patients treatment group received stent medical management.\nmedical management included medications, management risk factors, help lifestyle modification.Control group. Patients control group received medical management treatment group, receive stents.Researchers randomly assigned 224 patients treatment group 227 control group.\nstudy, control group provides reference point can measure medical impact stents treatment group.Researchers studied effect stents two time points: 30 days enrollment 365 days enrollment.\ndata collected 5 patients summarized Table 1.1.\nPatient outcomes recorded stroke event, representing whether patient stroke time period.data study can found openintro package: stent30 stent365.\nTable 1.1: Results five patients stent study.\nConsidering data 451 patients individually long, cumbersome path towards answering original research question.\nInstead, performing statistical data analysis allows us consider data .\nTable 1.2 summarizes raw data helpful way.\ntable, can quickly see happened entire study.\ninstance, identify number patients treatment group stroke within 30 days treatment, look leftmost column (30 days), intersection treatment stroke: 33.\nidentify number control patients stroke 365 days receiving treatment, look rightmost column (365 days), intersection control event: 199.\nTable 1.2: Descriptive statistics stent study.\ndata summarized table can also visualized barplot, seen Figure 1.2:\nFigure 1.2: Segmented barplot outcomes stent study group time.\n224 patients treatment group, 45 stroke end first year.\nUsing two numbers, compute proportion patients treatment group stroke end first year.\n(Note: answers Guided Practice exercises provided footnotes!)6We can compute summary statistics table give us better idea impact stent treatment differed two groups.\nsummary statistic single number summarizing large amount data.\ninstance, primary results study 1 year described two summary statistics: proportion people stroke treatment control groups.Proportion stroke treatment (stent) group: \\(45/224 = 0.20 = 20\\)%.Proportion stroke control group: \\(28/227 = 0.12 = 12\\)%.two summary statistics useful looking differences groups, surprise: additional 8% patients treatment group stroke!\nimportant two reasons.\nFirst, contrary doctors expected, stents reduce rate strokes.\nSecond, leads statistical question: data show “real” difference groups?second question subtle, basis call statistical inference.\nSuppose flip coin 100 times. chance coin lands heads given coin flip 50%, probably won’t observe exactly 50 heads.\ntype fluctuation part almost type data generating process.\npossible 8% difference stent study due natural variation.\nHowever, larger difference observe (particular sample size), less believable difference due chance.\nreally asking following: difference large reject notion due chance?don’t yet statistical tools fully address question , can comprehend conclusions published analysis: compelling evidence harm stents study stroke patients.careful.\ngeneralize results study patients stents.\nstudy looked patients specific characteristics volunteered part study may representative stroke patients.\naddition, many types stents study considered self-expanding Wingspan stent (Boston Scientific).\nHowever, study leave us important lesson: keep eyes open surprises.","code":""},{"path":"intro-to-data.html","id":"data-basics","chapter":"1 Hello data","heading":"1.2 Data basics","text":"Effective presentation description data first step analyses. section introduces one structure organizing data well terminology used throughout book.","code":""},{"path":"intro-to-data.html","id":"observations-variables-and-data-frames","chapter":"1 Hello data","heading":"1.2.1 Observations, variables, and data frames","text":", consider loans offered Lending Club, peer--peer lending company. data used explore characteristics people receiving loans platform, job titles, annual income, home ownership. Table 1.3 displays six rows data set 50 randomly sampled loans. observations referred loan50 data set.data can found openintro package: loan50.row table represents single loan.\nformal name row case observational unit. Since 50 observational units data set, sample size, denoted \\(n\\), 50 (\\(n = 50\\)).\ncolumns represent characteristics loan, column referred variable. example, first row represents loan $7,500 interest rate 7.34%, borrower based Maryland (MD) income $70,000.variable something can measured individual observational unit.\ncareful confuse summary statistics—calculated group observational units—variables.grade first loan Table 1.3?\nhome ownership status borrower first loan?\nReminder: Guided Practice questions, can check answer footnote.7In practice, especially important ask clarifying questions ensure important aspects data understood.\ninstance, always important sure know variable means units measurement.\nDescriptions variables loan50 data set given Table 1.4.\nTable 1.3: Six rows loan50 data set.\n\nTable 1.4: Variables descriptions loan50 data set.\ndata Table 1.3 represent data frame (data matrix), convenient common way organize data, especially collecting data spreadsheet.\nrow data frame corresponds unique case (observational unit), column corresponds variable.recording data, use data frame unless good reason use different structure.\nstructure allows new cases added rows new variables new columns.grades assignments, quizzes, exams course often recorded gradebook takes form data frame.\nmight organize course’s grade data using data frame?8We consider data 3,142 counties United States,\ninclude name county, state resides, population 2017, population changed 2010 2017, poverty rate, nine additional characteristics.\nmight data organized data frame?9The data described Guided Practice represent county data set, shown data frame Table 1.5.\nvariables well variables data set fit Table 1.5 described Table 1.6\nTable 1.5: Six observations six variables county data set.\n\nTable 1.6: Variables descriptions county data set.\ndata can found usdata package: county.","code":""},{"path":"intro-to-data.html","id":"variable-types","chapter":"1 Hello data","heading":"1.2.2 Types of variables","text":"Examine unemployment_rate, pop2017, state, metro, median_edu variables county data set.\nvariables inherently different others, yet share certain characteristics.First consider unemployment_rate, said quantitative numerical variable since can take wide range numerical values, sensible add, subtract, take averages values.\nhand, classify variable reporting telephone area codes quantitative since average, sum, difference area codes doesn’t clear meaning.pop2017 variable also quantitative, although seems little different unemployment_rate.\nvariable population count can take whole non-negative numbers (0, 1, 2, …).\nreason, population variable said discrete since can take numerical values jumps.\nhand, unemployment rate variable said continuous.variable state can take 51 values accounting Washington, DC: AL, AK, …, WY.\nresponses categories, state called categorical variable, possible values called variable’s levels . variable metro also categorical, two levels (yes ). categorical variable two levels called binary variable. working generic binary variable, often call two possible levels “success” “failure.”Finally, consider median_edu variable, describes median education level county residents takes values below_hs, hs_diploma, some_college, bachelors county.\nvariable seems hybrid: categorical variable levels natural ordering.\nvariable properties called ordinal variable, regular categorical variable without type special ordering called nominal variable.\nsimplify analyses, ordinal variable book treated nominal (unordered) categorical variable.\nFigure 1.3: Breakdown variables respective types.\nData collected students statistics course.\nThree variables recorded student: number siblings, student height, whether student previously taken statistics course.\nClassify variables continuous quantitative, discrete quantitative, categorical.number siblings student height represent quantitative variables.\nnumber siblings count, discrete.\nHeight varies continuously, continuous quantitative variable.\nlast variable classifies students two categories—taken statistics course—makes variable categorical.experiment evaluating effectiveness new drug treating migraines.\ngroup variable used indicate experiment group patient: treatment control.\nnum_migraines variable represents number migraines patient experienced 3-month period. Classify variable either quantitative categorical.10","code":""},{"path":"intro-to-data.html","id":"variable-relations","chapter":"1 Hello data","heading":"1.2.3 Relationships between variables","text":"Many analyses motivated researcher looking relationship two variables.\nsocial scientist may like answer following questions:higher average increase county population tend correspond counties higher lower median household incomes?homeownership lower national average one county, percent multi-unit structures county tend national average?useful predictor median education level median household income US counties?answer questions, data must collected, county data set shown Table 1.5.\nExamining summary statistics provide insights three questions counties.\nAdditionally, graphs can used visually explore data.Scatterplots one type graph used study relationship two quantitative variables.\nFigure 1.4 displays relationship variables homeownership multi_unit, percent units multi-unit structures (e.g., apartments, condos).\npoint plot represents single county (single observational unit).\ninstance, highlighted dot corresponds County 413 county data set: Chattahoochee County, Georgia, 39.4% units multi-unit structures homeownership rate 31.3%.\nscatterplot suggests relationship two variables: counties higher rate multi-units tend lower homeownership rates.\nmight brainstorm relationship exists investigate idea determine reasonable explanations.\nFigure 1.4: scatterplot homeownership versus percent units multi-unit structures US counties. highlighted dot represents Chattahoochee County, Georgia, multi-unit rate 39.4% homeownership rate 31.3%.\nmulti-unit homeownership rates said associated plot shows discernible pattern.\ntwo variables show connection one another, called associated variables.\nAssociated variables can also called dependent variables vice-versa.Examine variables loan50 data set, described Table 1.4.\nCreate two questions possible relationships variables loan50 interest .11This example examines relationship change population 2010 2017 median household income counties, visualized scatterplot Figure 1.5.\nvariables associated?larger median household income county, higher population growth observed county.\ntrend isn’t true every county, trend plot evident. Since relationship variables, associated.\nFigure 1.5: scatterplot showing pop_change median_hh_income. Owsley County Kentucky, highlighted, lost 3.63% population 2010 2017 median household income $22,736.\ndownward trend Figure 1.4—counties units multi-unit structures associated lower homeownership—variables said negatively associated.\npositive association shown relationship median_hh_income pop_change variables Figure 1.5, counties higher median household income tend higher rates population growth.two variables associated, said independent.\n, two variables independent evident relationship two.Associated independent, .\npair variables either related way (associated) (independent).\npair variables associated independent.","code":""},{"path":"intro-to-data.html","id":"explanatory-and-response-variables","chapter":"1 Hello data","heading":"1.2.4 Explanatory and response variables","text":"ask questions relationship two variables, sometimes also want determine change one variable causes change .\nConsider following rephrasing earlier question county data set:increase median household income county, drive increase population?question, asking whether one variable affects another.\nunderlying belief, median household income explanatory variable variable population change response variable variable hypothesized relationship.12Explanatory response variables.suspect one variable might causally affect another,\nlabel first variable explanatory variable\nsecond response variable.\nmain reason observational studies control confounding variables.\nrevisit idea discuss experiments next chapter.\nmany pairs variables, hypothesized relationship, labels applied either variable cases.Bear mind act labeling variables way nothing guarantee causal relationship exists.\nformal evaluation check whether one variable causes change another requires experiment.","code":""},{"path":"intro-to-data.html","id":"introducing-observational-studies-and-experiments","chapter":"1 Hello data","heading":"1.2.5 Introducing observational studies and experiments","text":"two primary types data collection: observational studies experiments. already encountered experiment case study Section 1.1, observational study Lending Club data section.Researchers perform observational study collect data way directly interfere data arise.\ninstance, researchers may collect information via surveys, review medical company records, follow cohort many similar individuals form hypotheses certain diseases might develop.\nsituations, researchers merely observe data arise.\ngeneral, observational studies can provide evidence naturally occurring association variables, show causal connection.researchers want investigate possibility causal connection, conduct experiment.\nUsually explanatory response variable.\ninstance, may suspect administering drug reduce mortality heart attack patients following year.\ncheck really causal connection explanatory variable response, researchers collect sample individuals split groups.\nindividuals group assigned treatment.\nindividuals randomly assigned group, experiment called randomized experiment.\nexample, heart attack patient drug trial randomly assigned, perhaps flipping coin, one two groups: first group receives placebo (fake treatment) second group receives drug.\nNote case study Section 1.1 use placebo.Association \\(\\neq\\) Causation.\ngeneral, association imply causation, causation can inferred randomized experiment.","code":""},{"path":"intro-to-data.html","id":"chp1-review","chapter":"1 Hello data","heading":"1.3 Chapter review","text":"","code":""},{"path":"intro-to-data.html","id":"summary","chapter":"1 Hello data","heading":"Summary","text":"chapter introduced world data.\nData can organized many ways tidy data, row represents observation column represents variable, lends easily statistical analysis.\nMany ideas chapter seen move full data analyses.\nnext chapter ’re going learn can design studies collect data need make conclusions desired scope inference.","code":""},{"path":"intro-to-data.html","id":"terms","chapter":"1 Hello data","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"intro-to-data.html","id":"key-ideas","chapter":"1 Hello data","heading":"Key ideas","text":"data set comprised measurements variables observational units.\ntype variable can quantitative categorical, variable’s role can explanatory variable response variable.data set comprised measurements variables observational units.\ntype variable can quantitative categorical, variable’s role can explanatory variable response variable.observational study, merely observe behavior individuals study; manipulate variables individuals way. randomized experiment, randomly assign values explanatory variable observational units, observe response variable. Random assignment allows us investigate causal relationships balances potential confounding variables, average. ideas discussed detail next chapter.observational study, merely observe behavior individuals study; manipulate variables individuals way. randomized experiment, randomly assign values explanatory variable observational units, observe response variable. Random assignment allows us investigate causal relationships balances potential confounding variables, average. ideas discussed detail next chapter.","code":""},{"path":"data-design.html","id":"data-design","chapter":"2 Study design","heading":"2 Study design","text":"digging details working data, stop think data come .\n, data used make broad complete conclusions, important understand data represent.\nOne important aspect data provenance sampling.\nKnowing observational units selected larger entity allow generalizations back population data randomly selected.\nAdditionally, understanding structure study, causal relationships can separated relationships associated.\ngood question ask oneself working data , “observations collected?”.\nlearn lot data understanding source.","code":""},{"path":"data-design.html","id":"sampling-principles-strategies","chapter":"2 Study design","heading":"2.1 Sampling principles and strategies","text":"\nfirst step conducting research identify topics questions investigated.\nclearly laid research question helpful identifying subjects cases studied variables important.\nalso important consider data collected reliable help achieve research goals.","code":""},{"path":"data-design.html","id":"populations-and-samples","chapter":"2 Study design","heading":"2.1.1 Populations and samples","text":"Consider following three research questions:average mercury content swordfish Atlantic Ocean?last 5 years, average time complete degree Duke undergrads?new drug reduce risk deaths patients severe heart disease?research question refers target population.\nfirst question, target population swordfish Atlantic ocean, fish represents case.\nOften times, expensive collect data every case population.\nInstead, sample taken.\nsample represents subset cases often small fraction population.\ninstance, 60 swordfish (number) population might selected, sample data may used provide estimate population average answer research question.second third questions , identify target population represents individual case.13","code":""},{"path":"data-design.html","id":"parameters-and-statistics","chapter":"2 Study design","heading":"2.1.2 Parameters and statistics","text":"statistical analysis procedures, research question hand boils understanding numerical summary.\nnumber (set numbers) may quantity already familiar (like average) may something learn text (like slope intercept least squares model, provided Section 6.2).numerical summary can calculated either sample observations entire population.\nHowever, measuring every unit population usually prohibitive (parameter rarely calculated).\n, “typical” numerical summary calculated sample.\nYet, can still conceptualize calculating average income adults Argentina.use specific terms order differentiate number calculated sample data (statistic) calculated considered calculation entire population (parameter).\nterms statistic parameter useful communicating claims models used extensively later chapters delve making inference populations.","code":""},{"path":"data-design.html","id":"anecdotal-evidence","chapter":"2 Study design","heading":"2.1.3 Anecdotal evidence","text":"Consider following possible responses three research questions:man news got mercury poisoning eating swordfish, average mercury concentration swordfish must dangerously high.met two students took 7 years graduate Duke, must take longer graduate Duke many colleges.friend’s dad heart attack died gave new heart disease drug, drug must work.conclusion based data.\nHowever, two problems.\nFirst, data represent one two cases.\nSecond, importantly, unclear whether cases actually representative population. Data collected haphazard fashion called anecdotal evidence.Anecdotal evidence.\ncareful data collected haphazard fashion.\nevidence may true verifiable, may represent extraordinary cases.\nFigure 2.1: February 2010, media pundits cited one large snow storm evidence global warming. comedian Jon Stewart pointed , “one storm, one region, one country.”\nAnecdotal evidence typically composed unusual cases recall based striking characteristics.\ninstance, likely remember two people met took 7 years graduate six others graduated four years.\nInstead looking unusual cases, examine sample many cases better represent population.","code":""},{"path":"data-design.html","id":"sampling-from-a-population","chapter":"2 Study design","heading":"2.1.4 Sampling from a population","text":"\nmight try estimate time graduation Duke undergraduates last 5 years collecting sample students.\ngraduates last 5 years represent population, graduates selected review collectively called sample.\ngeneral, always seek randomly select sample population.\nbasic type random selection equivalent raffles conducted–raffle ticket equal chance selected.\nexample, selecting graduates, write graduate’s name raffle ticket draw 100 tickets.\nselected names represent random sample 100 graduates.\npick samples randomly reduce chance introduce biases.\nFigure 2.2: graphic, five graduates randomly selected population (graduates last 5 years) included sample.\nSuppose ask student happens majoring nutrition select several graduates study.\nkind students think might collect?\nthink sample representative graduates?Perhaps pick disproportionate number graduates health-related fields. perhaps selection good representation population.\nselecting samples hand, run risk picking biased sample, even bias unintended.\nFigure 2.3: Asked pick sample graduates, nutrition major might inadvertently pick disproportionate number graduates health-related majors.\nsomeone permitted pick choose exactly graduates included sample, entirely possible sample skewed person’s interests, may entirely unintentional.\nintroduces bias sampling method.three common types sampling bias discuss:Selection bias: method sample selected tends produce samples either -represent -represent certain portions population.Non-response bias: individuals selected sample unwilling answer questions, respond, refuse participate.Response bias: individuals selected sample respond way accurately represent truth—due question wording, lack anonymity, issues.common downfall survey studies convenience sample, individuals easily accessible likely included sample.\ninstance, political survey done stopping people walking Bronx, represent New York City.\noften difficult discern sub-population convenience sample represents.convenience sample example selection bias, non-response bias,\nresponse bias?14Sampling randomly helps resolve selection bias.\nbasic random sample called simple random sample, equivalent using raffle select cases.\nmeans case population equal chance included implied connection cases sample.Even people picked random, however, caution must exercised non-response rate high, response bias present.\ninstance, 30% people randomly sampled survey actually respond, unclear whether results representative entire population.\nnon-response bias can produce results sample accurately reflect entire population.\nFigure 2.4: Due possibility non-response, survey studies may reach certain group within population. difficult, often times impossible, completely fix problem.\nAsking uninformed. Popular late night host Jimmy Kimmel segment show called “Lie Witness News,” Kimmel’s staff take streets ask pedestrians recent stories news. However, recent stories really stories —’re fake. Without fail, asked always express opinion, unflinchingly. ? People like appear don’t know ’re talking , make answers. entertaining display fascinating psychological example response bias, watch Coachella 2013 episode Lie Witness News.can easily access ratings products, sellers, companies websites. ratings based people go way provide rating. 50% online reviews product negative, think means 50% buyers dissatisfied product? ?15\n","code":""},{"path":"data-design.html","id":"samp-methods","chapter":"2 Study design","heading":"2.1.5 Four sampling methods (special topic)","text":"Almost statistical methods based notion implied randomness.\nobservational data collected random framework population, statistical methods—estimates errors associated estimates—reliable.\nconsider four random sampling techniques: simple, stratified, cluster, multistage sampling. Figures 2.5 2.6 provide graphical representations techniques.\n\nFigure 2.5: Examples simple random stratified sampling. top panel, simple random sampling used randomly select 18 cases (denoted red). bottom panel, stratified sampling used: cases grouped strata, simple random sampling employed randomly select 3 cases within stratum.\nSimple random sampling probably intuitive form random sampling.\nConsider salaries Major League Baseball (MLB) players, player member one league’s 30 teams.\ntake simple random sample 120 baseball players salaries, write names season’s several hundreds players onto slips paper, drop slips bucket, shake bucket around sure names mixed , draw slips sample 120 players.\ngeneral, sample referred “simple random” case population equal chance included final sample knowing case included sample provide useful information cases included.Stratified sampling divide--conquer sampling strategy.\npopulation divided groups called strata.\nstrata chosen similar cases grouped together, second sampling method, usually simple random sampling, employed within stratum.\nbaseball salary example, 30 teams represent strata, since teams lot money (4 times much!).\nmight randomly sample 4 players team sample 120 players.Stratified sampling especially useful cases stratum similar respect outcome interest.\ndownside analyzing data stratified sample complex task analyzing data simple random sample.\nanalysis methods introduced book need extended analyze data collected using stratified sampling.good cases within stratum similar?might get stable estimate subpopulation stratum cases similar, leading precise estimates within group.\ncombine estimates single estimate full population, population estimate tend precise since individual group estimate precise.cluster sample, break population many groups, called clusters.\nsample fixed number clusters include observations clusters sample.\nmultistage sample like cluster sample, rather keeping observations cluster, collect random sample within selected cluster.\nFigure 2.6: Examples cluster multistage sampling. top panel, cluster sampling used: data binned nine clusters, three clusters sampled, observations within three cluster included sample. bottom panel, multistage sampling used, differs cluster sampling randomly select subset cluster included sample rather measuring every case sampled cluster.\nSometimes cluster multistage sampling can economical alternative sampling techniques.\nAlso, unlike stratified sampling, approaches helpful lot case--case variability within cluster clusters don’t look different one another.\nexample, neighborhoods represented clusters, cluster multistage sampling work best neighborhoods diverse.\ndownside methods advanced techniques typically required analyze data, though methods book can extended handle data.Suppose interested estimating malaria rate densely tropical portion rural Indonesia.\nlearn 30 villages part Indonesian jungle, less similar next, distances villages substantial. goal test 150 individuals malaria.\nsampling method employed?simple random sample likely draw individuals 30 villages, make data collection extremely expensive.\nStratified sampling challenge since unclear build strata similar individuals.\nHowever, cluster sampling multistage sampling seem like good ideas.\ndecided use multistage sampling, might randomly select half villages, randomly select 10 people .\nprobably reduce data collection costs substantially comparison simple random sample, cluster sample still give us reliable information, even need analyze data slightly advanced methods discuss book.","code":""},{"path":"data-design.html","id":"observational-studies","chapter":"2 Study design","heading":"2.2 Observational studies","text":"Data treatment explicitly applied (explicitly withheld) called observational data.\ninstance, loan data county data described Section 1.2 examples observational data.Observational studies generally sufficient show associations form hypotheses can later checked experiments. Making causal conclusions based experiments often reasonable. However, making causal conclusions based observational data can treacherous recommended. Indeed, making causal conclusions based observational data arguably common mistake news headlines social media posts!Suppose observational study tracked sunscreen use skin cancer, found sunscreen someone used, likely person skin cancer. mean sunscreen causes skin cancer?16Some previous research tells us using sunscreen actually reduces skin cancer risk, maybe another variable can explain hypothetical association sunscreen usage skin cancer.\nOne important piece information absent sun exposure. someone sun day, likely use sunscreen likely get skin cancer. Exposure sun unaccounted simple investigation.Sun exposure called confounding variable17, variable associated explanatory response variables.\none method justify making causal conclusions observational studies exhaust search confounding variables, guarantee confounding variables can examined measured.confounding variable variable bothassociated explanatory variable, andassociated response variable.conditions met, observe association explanatory variable response variable data, sure association due explanatory variable confounding variable—explanatory confounding variables “confounded.”Figure 1.4 shows negative association homeownership rate percentage multi-unit structures county.\nHowever, unreasonable conclude causal relationship two variables.\nSuggest variable might explain negative relationship.18Houndstongue (noxious weed) found abundance private public lands grazed cattle. Houndstongue rarely found lands grazed mountain goats. One investigator concluded houndstongue infestations reduced importing mountain goats infested areas. wrong conclusion?19Observational studies come two forms: prospective retrospective studies.\nprospective study identifies individuals collects information events unfold.\ninstance, medical researchers may identify follow group patients many years assess possible influences behavior cancer risk.\nOne example study Nurses’ Health Study.\nStarted 1976 expanded 1989, Nurses’ Health Study collected data 275,000 nurses still enrolling participants.\nprospective study recruits registered nurses collects data using questionnaires.\nRetrospective studies collect data events taken place, e.g. researchers may review past events medical records.\ndata sets may contain prospectively- retrospectively-collected variables, medical studies gather information participants’ lives enter study subsequently collect data participants throughout study.","code":""},{"path":"data-design.html","id":"experiments","chapter":"2 Study design","heading":"2.3 Experiments","text":"Studies researchers assign treatments cases called experiments.\nassignment includes randomization, e.g., using coin flip decide treatment patient receives, called randomized experiment.\nRandomized experiments fundamentally important trying show causal connection two variables.","code":""},{"path":"data-design.html","id":"principles-of-experimental-design","chapter":"2 Study design","heading":"2.3.1 Principles of experimental design","text":"Randomized experiments generally built four principles:Controlling. Researchers assign treatments cases, best control differences groups20.\nexample, patients take drug pill form, patients take pill sip water others may entire glass water.\ncontrol effect water consumption, doctor may instruct every patient drink 12 ounce glass water pill.Controlling. Researchers assign treatments cases, best control differences groups20.\nexample, patients take drug pill form, patients take pill sip water others may entire glass water.\ncontrol effect water consumption, doctor may instruct every patient drink 12 ounce glass water pill.Randomization. Researchers randomize patients treatment groups account variables controlled.\nexample, patients may susceptible disease others due dietary habits.\nRandomizing patients treatment control group helps even differences, also prevents accidental bias entering study.Randomization. Researchers randomize patients treatment groups account variables controlled.\nexample, patients may susceptible disease others due dietary habits.\nRandomizing patients treatment control group helps even differences, also prevents accidental bias entering study.Replication. cases researchers observe, accurately can estimate effect explanatory variable response.\nsingle study, replicate collecting sufficiently large sample.\nAlternatively, group scientists may replicate entire study verify earlier finding.Replication. cases researchers observe, accurately can estimate effect explanatory variable response.\nsingle study, replicate collecting sufficiently large sample.\nAlternatively, group scientists may replicate entire study verify earlier finding.Blocking. Researchers sometimes know suspect variables, treatment, influence response.\ncircumstances, may first group individuals based variable blocks randomize cases within block treatment groups.\nstrategy often referred blocking.\ninstance, looking effect drug heart attacks, might first split patients study low-risk high-risk blocks, randomly assign half patients block control group half treatment group, shown Figure 2.7.\nstrategy ensures treatment group equal number low-risk high-risk patients.Blocking. Researchers sometimes know suspect variables, treatment, influence response.\ncircumstances, may first group individuals based variable blocks randomize cases within block treatment groups.\nstrategy often referred blocking.\ninstance, looking effect drug heart attacks, might first split patients study low-risk high-risk blocks, randomly assign half patients block control group half treatment group, shown Figure 2.7.\nstrategy ensures treatment group equal number low-risk high-risk patients.\nFigure 2.7: Blocking using variable depicting patient risk. Patients first divided low-risk high-risk blocks, block evenly separated treatment groups using randomization. strategy ensures equal representation patients treatment group low-risk high-risk categories.\nimportant incorporate first three experimental design principles study, book describes applicable methods analyzing data experiments.\nBlocking slightly advanced technique, statistical methods book may extended analyze data collected using blocking.","code":""},{"path":"data-design.html","id":"reducing-bias-human-experiments","chapter":"2 Study design","heading":"2.3.2 Reducing bias in human experiments","text":"Randomized experiments long considered gold standard data collection, ensure unbiased perspective cause effect relationship cases.\nHuman studies perfect examples bias can unintentionally arise.\nreconsider study new drug used treat heart attack patients.\nparticular, researchers wanted know drug reduced deaths patients.researchers designed randomized experiment wanted draw causal conclusions drug’s effect.\nStudy volunteers21 randomly placed two study groups.\nOne group, treatment group, received drug.\ngroup, called control group, receive drug treatment.Put place person study.\ntreatment group, given fancy new drug anticipate help .\nhand, person group doesn’t receive drug sits idly, hoping participation doesn’t increase risk death.\nperspectives suggest actually two effects study: one interest effectiveness drug, second emotional effect () taking drug, difficult quantify.Researchers aren’t usually interested emotional effect, might bias study.\ncircumvent problem, researchers want patients know group .\nresearchers keep patients uninformed treatment, study said blind.\none problem: patient doesn’t receive treatment, know ’re control group.\nsolution problem give fake treatments patients control group.\nfake treatment called placebo, effective placebo key making study truly blind.\nclassic example placebo sugar pill made look like actual treatment pill.\nOften times, placebo results slight real improvement patients.\neffect dubbed placebo effect.patients ones blinded: doctors researchers can accidentally bias study.\ndoctor knows patient given real treatment, might inadvertently give patient attention care patient know placebo.\nguard bias, found measurable effect instances, modern studies employ double-blind setup doctors researchers interact patients , just like patients, unaware receiving treatment.22Look back study Section 1.1 researchers testing whether stents effective reducing strokes -risk patients.\nexperiment? study blinded? double-blinded?23For study Section 1.1, researchers employed placebo?\n, placebo looked like?24You may many questions ethics sham surgeries create placebo.\nquestions may even arisen mind general experiment context, possibly helpful treatment withheld individuals control group; main difference sham surgery tends create additional risk, withholding treatment maintains person’s risk.always multiple viewpoints experiments placebos, rarely obvious ethically “correct”.\ninstance, ethical use sham surgery creates risk patient?\nHowever, don’t use sham surgeries, may promote use costly treatment real effect; happens, money resources diverted away treatments known helpful.\nUltimately, difficult situation perfectly protect patients volunteered study patients may benefit () treatment future.","code":""},{"path":"data-design.html","id":"scope-of-inference","chapter":"2 Study design","heading":"2.4 Scope of inference","text":"statisticians refer scope inference study,\nasking two questions:Generalizability: population can generalize results?Causation: results provide evidence causal relationship?answer first question determined sampling method—selected sample randomly, sources sampling bias, can reasonably generalize population sample taken. answer second question determined type study—study randomized experiment, can investigate whether changes explanatory variable caused changes response variable; observational study, one can investigate associations variables. summarize determine study’s scope inference Figure 2.8.\nFigure 2.8: Determining scope inference study.\n","code":""},{"path":"data-design.html","id":"chp2-review","chapter":"2 Study design","heading":"2.5 Chapter review","text":"","code":""},{"path":"data-design.html","id":"summary-1","chapter":"2 Study design","heading":"Summary","text":"strong analyst good sense types data working visualize data order gain complete understanding variables.\nEqually important however, understanding data source.\nchapter, discussed randomized experiments taking good, random, representative samples population.\ndiscuss inferential methods (starting Chapter 9), conclusions can drawn dependent data collected.\nFigure 2.9 summarizes differences random assignment treatments random samples.25\nRegularly revisiting Figure 2.9 important making conclusions given data analysis.\nFigure 2.9: see, analysis conclusions made carefully according data collected. Note datasets come top left box usually ethics require random assignment treatments can given volunteers. representative (ideally random) sampling experiments (random assignment treatments) important statistical conclusions can made populations.\n","code":""},{"path":"data-design.html","id":"terms-1","chapter":"2 Study design","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"data-design.html","id":"key-ideas-1","chapter":"2 Study design","heading":"Key ideas","text":"Statistical inference uses data sample make inferences larger, target population.Statistical inference uses data sample make inferences larger, target population.TODO: parameters statisticsTODO: parameters statisticsWe can generalize results sample target population sampling methods unbiased.\nOne unbiased sampling method simple random sample, randomly select observational units sample complete list observational units target population.can generalize results sample target population sampling methods unbiased.\nOne unbiased sampling method simple random sample, randomly select observational units sample complete list observational units target population.Various types bias can arise studies, particularly surveys individuals.\nstudy biased way conducted systematically -represent -represent certain groups responses.\nSelection bias occurs method selecting sample biased (e.g., convenience sample);\nnon-response bias occurs individuals selected study respond reached;\nresponse bias occurs responses individuals reflect truth (e.g., due confidentiality concerns, question wording, sensitive topics).Various types bias can arise studies, particularly surveys individuals.\nstudy biased way conducted systematically -represent -represent certain groups responses.\nSelection bias occurs method selecting sample biased (e.g., convenience sample);\nnon-response bias occurs individuals selected study respond reached;\nresponse bias occurs responses individuals reflect truth (e.g., due confidentiality concerns, question wording, sensitive topics).observational study, merely observe behavior individuals study; manipulate variables individuals way. randomized experiment, randomly assign values explanatory variable observational units, observe response variable. Random assignment allows us investigate causal relationships balances potential confounding variables, average.observational study, merely observe behavior individuals study; manipulate variables individuals way. randomized experiment, randomly assign values explanatory variable observational units, observe response variable. Random assignment allows us investigate causal relationships balances potential confounding variables, average.scope inference study answers two questions: (1) population can results can generalized? (2) Can assume associations data due cause--effect relationship?\ncan generalize target population sampling method unbiased (e.g., simple random sample).\ncan conclude cause--effect study design randomized experiment.scope inference study answers two questions: (1) population can results can generalized? (2) Can assume associations data due cause--effect relationship?\ncan generalize target population sampling method unbiased (e.g., simple random sample).\ncan conclude cause--effect study design randomized experiment.","code":""},{"path":"data-applications.html","id":"data-applications","chapter":"3 Applications: Data","heading":"3 Applications: Data","text":"","code":""},{"path":"data-applications.html","id":"data-in-r","chapter":"3 Applications: Data","heading":"3.1 Data in R","text":"R powerful open source software tool working data.\nThroughout text, provide guidance use R within \ncontext statistical content covered.educators, see value teaching modern software \nempower students take optimal advantage concepts learning.\nGenerally, present R techniques end\nchapter. times text concepts \ndistinguishable software, cases, provided \nR code within main body chapter.start introduction R, focused data sets structured \nR user can work data object R.","code":""},{"path":"data-applications.html","id":"dataframes-in-r","chapter":"3 Applications: Data","heading":"3.1.1 Dataframes in R","text":"Throughout text, work many different data sets. data sets\npre-loaded R, get loaded R packages, data sets\ncreated student. Data sets can viewed RStudio\nenvironment, can also investigated various R functions.Similar notation mathematical function, R function takes form:function_name(arguments function)function_name name function, mean, read.csv, lm. can access help file named function preceding question mark: ?read.csv.arguments function inputs function. can data sets, parameter values, options.R, functions take arguments round parentheses (opposed subsetting observations variables data objects happen square parentheses).R console, type ?read.csv. bring help file read.csv() function. first two arguments function?26Consider data described previously chapter.\ncan use glimpse() function see variables included data set\ndata type. , use head() function see first\nrows data set.Sometimes necessary extract column row data set.\nR, $ operator can used extract column data set.\nexample, data$variable extract variable column data dataframe.\nextracted, columns can thought vectors. vectors, desired pull specific entry, use square brackets ([ ]), index (number) entry wish extract brackets.\nexample, data$variable[2] extract second entry (row) variable column.dataframe can (roughly) thought set many different vectors, can extract rows columns dataframe using familiar matrix notation (e.g. [row, column]).\nexample data[,j] extract \\((,j)^{th}\\) entry data, data[, ] extract \\(^{th}\\) row, data[ , j] extract \\(j^{th}\\) column. Notice, extracting entire row (column), need specify columns (rows) like, second entry contain number.","code":"\ndata(email50)\nglimpse(email50)\n#> Rows: 50\n#> Columns: 21\n#> $ spam         <fct> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, …\n#> $ to_multiple  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n#> $ from         <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#> $ cc           <int> 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n#> $ sent_email   <fct> 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, …\n#> $ time         <dttm> 2012-01-04 06:19:16, 2012-02-16 13:10:06, 2012-01-04 08:…\n#> $ image        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ attach       <dbl> 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, …\n#> $ dollar       <dbl> 0, 0, 0, 0, 9, 0, 0, 0, 0, 23, 4, 0, 3, 2, 0, 0, 0, 0, 0,…\n#> $ winner       <fct> no, no, no, no, no, no, no, no, no, no, no, no, yes, no, …\n#> $ inherit      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ password     <dbl> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 8, …\n#> $ num_char     <dbl> 21.705, 7.011, 0.631, 2.454, 41.623, 0.057, 0.809, 5.229,…\n#> $ line_breaks  <int> 551, 183, 28, 61, 1088, 5, 17, 88, 242, 578, 1167, 198, 7…\n#> $ format       <fct> 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, …\n#> $ re_subj      <fct> 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, …\n#> $ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ urgent_subj  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ exclaim_mess <dbl> 8, 1, 2, 1, 43, 0, 0, 2, 22, 3, 13, 1, 2, 2, 21, 10, 0, 0…\n#> $ number       <fct> small, big, none, small, small, small, small, small, smal…\nhead(email50) \n#> # A tibble: 6 × 21\n#>   spam  to_multiple from     cc sent_e…¹ time                image attach dollar\n#>   <fct> <fct>       <fct> <int> <fct>    <dttm>              <dbl>  <dbl>  <dbl>\n#> 1 0     0           1         0 1        2012-01-04 06:19:16     0      0      0\n#> 2 0     0           1         0 0        2012-02-16 13:10:06     0      0      0\n#> 3 1     0           1         4 0        2012-01-04 08:36:23     0      2      0\n#> 4 0     0           1         0 0        2012-01-04 10:49:52     0      0      0\n#> 5 0     0           1         0 0        2012-01-27 02:34:45     0      0      9\n#> 6 0     0           1         0 0        2012-01-17 10:31:57     0      0      0\n#> # … with 12 more variables: winner <fct>, inherit <dbl>, viagra <dbl>,\n#> #   password <dbl>, num_char <dbl>, line_breaks <int>, format <fct>,\n#> #   re_subj <fct>, exclaim_subj <dbl>, urgent_subj <fct>, exclaim_mess <dbl>,\n#> #   number <fct>, and abbreviated variable name ¹​sent_email\n#> # ℹ Use `colnames()` to see all variable names\nemail50$num_char # The num_char variable column\n#>  [1] 21.705  7.011  0.631  2.454 41.623  0.057  0.809  5.229  9.277 17.170\n#> [11] 64.401 10.368 42.793  0.451 29.233  9.794  2.139  0.130  4.945 11.533\n#> [21]  5.682  6.768  0.086  3.070 26.520 26.255  5.259  2.780  5.864  9.928\n#> [31] 25.209  6.563 24.599 25.757  0.409 11.223  3.778  1.493 10.613  0.493\n#> [41]  4.415 14.156  9.491 24.837  0.684 13.502  2.789  1.169  8.937 15.829\nemail50[47,3] # The entry in the 47th row and 3rd column\n#> # A tibble: 1 × 1\n#>   from \n#>   <fct>\n#> 1 1\nemail50[47,] # The 47th row\n#> # A tibble: 1 × 21\n#>   spam  to_multiple from     cc sent_e…¹ time                image attach dollar\n#>   <fct> <fct>       <fct> <int> <fct>    <dttm>              <dbl>  <dbl>  <dbl>\n#> 1 0     1           1         0 0        2012-03-06 07:10:00     0      0      0\n#> # … with 12 more variables: winner <fct>, inherit <dbl>, viagra <dbl>,\n#> #   password <dbl>, num_char <dbl>, line_breaks <int>, format <fct>,\n#> #   re_subj <fct>, exclaim_subj <dbl>, urgent_subj <fct>, exclaim_mess <dbl>,\n#> #   number <fct>, and abbreviated variable name ¹​sent_email\n#> # ℹ Use `colnames()` to see all variable names"},{"path":"data-applications.html","id":"datastruc","chapter":"3 Applications: Data","heading":"3.1.2 Tidy structure of data","text":"plotting, analyses, model building, etc., data structured according certain principles.\nHadley Wickham provides thorough discussion advice cleaning data (Wickham2014?).Tidy data.data set rows observational units columns variables.\nkey every row case every column variable.\nexceptions.Creating tidy data often trivial! However, data sets provided course always tidy data form.","code":""},{"path":"data-applications.html","id":"using-the-pipe-to-chain","chapter":"3 Applications: Data","heading":"3.1.3 Using the pipe to chain","text":"Within R (really within type computing language, Python, SQL, Java, etc.), important understand build data using patterns language.R, syntax <- called assignment character; used store output function set operations call object. things consider:object_name <- anything way assigning anything new object_name.object_name <- function_name(data_table, arguments) way using function create new object.object_name <- data_table %>% function_name(arguments) uses chaining syntax called pipe operator (%>%) extension ideas functions.pipe syntax (%>%) takes data frame (data table) sends argument function. mapping goes first available argument function.\nexample:x %>% f(y) f(x, y)y %>% f(x, ., z) f(x,y,z)chaining, value left side %>% becomes first argument function right side. can extended multiple lines code:called extended chaining.properties pipe syntax (%>%) keep mind:%>% never front line, always connecting one idea continuation idea next line.%>% never front line, always connecting one idea continuation idea next line.spot left first %>% always data table.spot left first %>% always data table.pipe syntax read , %>%.pipe syntax read , %>%.Pipes used commonly functions dplyr package (see R examples Chapter ??) allow us sequentially build data wrangling operations.\nPipes also helpful creating data visualizations ggplot2 package.","code":"object_name <- data_table %>%\n                    function_name(arguments) %>% \n                    another_function_name(other_arguments)"},{"path":"data-applications.html","id":"a-data-wrangling-example","chapter":"3 Applications: Data","heading":"3.1.4 A data wrangling example","text":"Consider built-data set hsb2 — “High School Beyond” survey.\nTwo hundred observations randomly sampled “High School Beyond” survey, survey conducted high school seniors National Center Education Statistics.\ninterest proportion students two types school, public private.use table command tabulate many type school data set. Notice result produced $ command table chaining syntax done %>%.equivalent ","code":"\ndata(hsb2) # Load the data\ntable(hsb2$schtyp) \n#> \n#>  public private \n#>     168      32\nhsb2 %>% \n  select(schtyp) %>%\n  table()\n#> schtyp\n#>  public private \n#>     168      32"},{"path":"data-applications.html","id":"filtering","chapter":"3 Applications: Data","heading":"Filtering","text":"interested public schools?\nFirst, take note another piece R syntax: double equal sign: ==.\nlogical test “equal ”.\nwords, first determine school type equal public observations data set filter true.can read : “take hsb2 data frame pipe filter function. Filter data cases school type equal public. , assign resulting data frame new object called hsb2 underscore public.”","code":"\n# Filter for public schools\nhsb2_public <- hsb2 %>%\n  filter(schtyp == \"public\")"},{"path":"data-applications.html","id":"mutating","chapter":"3 Applications: Data","heading":"Mutating","text":"Suppose interested actual reading score students, instead whether reading score average average.\nFirst, need calculate average reading score mean() function.\ngive us mean value, 52.23.\nHowever, order able refer back value later , might want store object can refer name.instead just printing result, let’s save new object called avg_read.Next need determine whether student average. example, reading score 57 average, 68, 44 .\nObviously, going record like tedious error prone.Instead can create new variable mutate() function dplyr package (included tidyverse package).start data frame, hsb2, pipe mutate(), create new variable called read_cat (cat categorical).\nNote using new variable name order overwrite existing reading score variable.\nnew variable read_cat column existing data frame hsb2.decision criteria new variable based TRUE/FALSE question: reading score student average reading score, label “average”, otherwise, label “average”.can accomplished using ifelse() function R. Look helpfile typing ?ifelse R console window.first argument function logical test.first argument function logical test.second argument result logical test TRUE, words, student’s score average score.second argument result logical test TRUE, words, student’s score average score.last argument result FALSE.last argument result FALSE.","code":"\n# Calculate average reading score and show the value\nmean(hsb2$read)\n#> [1] 52.2\n# Calculate average reading score and store as avg_read\navg_read <- mean(hsb2$read)\nhsb2 <- hsb2 %>% mutate(read_cat = \n                          ifelse(read < avg_read, \n                                 \"below average\", \n                                 \"at or above average\"\n                                 )\n                        )"},{"path":"categorical-data.html","id":"categorical-data","chapter":"4 Exploring categorical data","heading":"4 Exploring categorical data","text":"chapter focuses exploring categorical data using summary statistics visualizations.\nsummaries graphs presented chapter created using statistical software; however, since might first exposure concepts, take time chapter detail create .\npossible, present multivariate plots; plots visualize relationship multiple variables.\nMastery content presented chapter crucial understanding methods techniques introduced rest book.chapter, introduce tables basic tools organizing analyzing categorical data used throughout book. Table 4.1 displays first six rows email data set containing information 3,921 emails sent David Diez’s Gmail account (one authors OpenIntro textbooks). section examine whether presence numbers, small large, email provides useful value classifying email spam spam.\nDescriptions five email variables given Table 4.2.email data can found openintro package.27\nTable 4.1: Six rows email data set.\n\nTable 4.2: Variables descriptions email data set.\n","code":""},{"path":"categorical-data.html","id":"contingency-tables-and-conditional-proportions","chapter":"4 Exploring categorical data","heading":"4.1 Contingency tables and conditional proportions","text":"summary table single categorical variable reports number observations (frequency) category called frequency table. Table\n4.3 frequency table number variable.\nreplaced counts percentages proportions (relative frequencies),\ntable called relative frequency table.\nTable 4.3: Frequency table Number variable.\nTable 4.4 summarizes two variables:\ntype (spam spam) number. table summarizes data two categorical variables\nway called contingency table two-way table.\nvalue table represents number times, frequency\nparticular combination variable outcomes occurred.\nexample, value 149 corresponds number emails\ndata set spam number listed email.\nRow column totals also included.\nrow totals provide total counts across row\n(e.g., \\(149 + 168 + 50 = 367\\) emails classified spam), column totals total\ncounts column.textbook, generally take convention putting categories explanatory variable columns categories response variable rows (exists explanatory-response relationship two variables).\nTable 4.4: Contingency table number (cols) type (rows) variables.\nlike examine whether presence numbers—none, small large—email provides useful value classifying email spam spam—, association variables number type?determine relationship exists whether email spam , whether email numbers, small number, big number, isn’t helpful compare number spam emails across number categories?28The proportion emails classified spam data set \\(3554/3921 = 0.906\\), 91%. Let’s compare unconditional proportion conditional proportions spam within number category: \\(400/549 \\approx 73\\%\\) emails numbers spam; \\(2659/2827 \\approx 94\\%\\) emails small numbers spam; \\(495/545 \\approx 91\\%\\) emails big numbers spam. Since three conditional proportions differ, say variables number type associated data set. Note differ overall, unconditional, proportion spam emails data set—91%.Association two categorical variables.unconditional proportion proportion measured total sample size. conditional proportion proportion measured subgroup sample.conditional proportions particular outcome (e.g., spam email) within levels categorical variable (e.g., whether number, small number, big number appears email) differ across levels, say two variables associated. can also determine two categorical variables associated checking conditional proportions outcome within categories differ overall, unconditional proportion.","code":""},{"path":"categorical-data.html","id":"row-and-column-proportions","chapter":"4 Exploring categorical data","heading":"4.1.1 Row and column proportions","text":"Conditional proportions condition row category called row proportions; conditional proportions condition column category\ncalled column proportions.Table 4.5 shows row proportions Table 4.4. row proportions computed counts divided row totals. frequnecy 149 intersection spam none replaced \\(149/367=0.406\\), .e., 149 divided row total, 367. 0.406 represent? corresponds conditional proportion non-spam emails sample numbers.\nTable 4.5: contingency table row proportions type number variables.\ncontingency table column proportions computed similar way, column proportion computed count divided corresponding column total. Table 4.6 shows table, value 0.729 indicates 72.9% emails numbers spam. rate spam much lower emails small numbers (94.1%) big numbers (90.8%). spam rates vary three levels number (none, small, big), provides evidence spam number variables associated data set.\nTable 4.6: contingency table column proportions type number variables.\n0.458 represent Table 4.5? 0.059 represent Table 4.6?29What 0.139 intersection ~spam big represent Table 4.5? 0.908 represent Table 4.6?30Data scientists use statistics filter spam incoming email messages. noting specific characteristics email, data scientist may able classify emails spam spam high accuracy.\nOne characteristics whether email contains numbers, small numbers, big numbers. Another characteristic whether email HTML content. contingency table type format variables email data set shown Table 4.7. Recall HTML email email capacity special formatting, e.g., bold text. Table~ 4.7, helpful someone hoping classify email spam regular email: row column proportions?person interested proportion spam changes within email format. corresponds column proportions: proportion spam plain text emails proportion spam HTML emails.generate column proportions, can see higher fraction plain text emails spam (\\(209/1195 = 17.5\\%\\)) compared HTML emails (\\(158/2726 = 5.8\\%\\)). information insufficient classify email spam spam, 80% plain text emails spam. Yet, carefully combine information many characteristics, variables, stand reasonable chance able classify email spam spam. \nTable 4.7: contingency table type format.\nprevious Example points row column proportions equivalent. settling one form table, important consider ensure useful table constructed.Look back Tables ?? ??. useful someone hoping identify spam emails using number variable?31","code":""},{"path":"categorical-data.html","id":"sample-proportions-and-population-proportions","chapter":"4 Exploring categorical data","heading":"4.1.2 Sample proportions and population proportions","text":"field statistics, summary measures summarize sample data called statistics. Numbers summarize entire population called parameters. can remember\ndistinction looking first letter term:Statistics summarize Samples.Parameters summarize Populations.Proportions calculated sample data denoted \\(\\hat{p}\\).\nexample, interested proportion spam emails data set, denote \\(\\hat{p} = 0.91\\). different groups want summarize proportion, can add subscripts: \\(\\hat{p}_{none} = 0.73\\), \\(\\hat{p}_{small} = 0.94\\), \\(\\hat{p}_{big} = 0.91\\). values statistic since computed sample data.3921 emails sample larger group emails—emails sent David Diez, either past future. larger group emails population. unknown value proportion emails population classified spam, denote \\(\\pi\\). Similarly, unknown values proportion emails numbers population classified spam, denoted \\(\\pi_{none}\\). unknown values called parameters.typically use Roman letters symbolize statistics (e.g., \\(\\bar{x}\\), \\(\\hat{p}\\)), Greek letters symbolize parameters (e.g., \\(\\mu\\), \\(\\pi\\)).\nSince rarely can measure entire population, thus rarely know\nactual parameter values, like say, “don’t know Greek,\ndon’t know parameters!”","code":""},{"path":"categorical-data.html","id":"bar-plots-and-mosaic-plots","chapter":"4 Exploring categorical data","heading":"4.2 Bar plots and mosaic plots","text":"bar plot common way display single categorical variable. left panel Figure 4.1 shows bar plot number variable.\nright panel, counts converted proportions (e.g., \\(549/3921=0.140\\) none).\nFigure 4.1: Two bar plots number. left panel shows counts \\(y\\)-axis, right panel shows proportions group \\(y\\)-axis.\nBar plots also used display relationship two categorical variables.\nbars stacked bar totals 100% segmented \nanother categorical variable, called segmented bar plot.segmented bar plot graphical display contingency table information. example, segmented bar plots representing Table 4.6 shown Figure 4.2, first created non-standardized segmented bar plot using number variable separated group levels type. standardized segmented bar plot using column proportions Table 4.6 helpful visualization fraction spam emails level number.segmented bar plot, explanatory variable plotted \\(x\\)-axis, response variable displayed different colors within bar, defined legend.\nFigure 4.2: () Segmented bar plot numbers found emails, counts broken type. (b) Segmented bar plot using column proportions type within number category.\nsegmented bar plots Figure 4.2, variable explanatory variable? response variable?32Examine segmented bar plots Figure 4.2. useful?Plot () contains information, plot (b) presents information clearly. Plot (b) makes clear emails number relatively high rate spam email—27%! hand, less 10% email small big numbers spam.Since proportion spam changes across groups Figure 4.2 (seen plot (b)), can conclude variables dependent, something also able discern using column proportions Table 4.6. none big groups relatively observations compared small group, association difficult see plot () Figure 4.2.cases, segmented bar plot standardized useful communicating important information. settling particular segmented bar plot, create standardized non-standardized forms decide effective communicating features data.","code":""},{"path":"categorical-data.html","id":"mosaic-plots","chapter":"4 Exploring categorical data","heading":"4.2.1 Mosaic plots","text":"mosaic plot graphical display contingency table information similar bar plot one variable segmented bar plot using two variables. Figure 4.3 plot () shows mosaic plot number variable. column represents level number, column widths correspond proportion emails number type. instance, fewer emails numbers emails small numbers, number email column slimmer. general, mosaic plots use box areas represent number observations.\nFigure 4.3: () Mosaic plot numbers found emails. (b) Mosaic plot number counts broken type.\none-variable mosaic plot divided pieces Figure 4.3 plot (b) using type variable. column split proportionally according fraction emails spam number category. example, second column, representing emails small numbers, divided emails spam (lower) spam (upper).\nanother example, bottom third column represents spam emails big numbers, upper part third column represents regular emails big numbers. can use plot see type number variables associated since columns divided different vertical locations others, technique used checking association standardized version segmented bar plot.segmented bar plot, explanatory variable plotted \\(x\\)-axis mosaic plot, .e., explanatory variable represented columns, response variable displayed different colors within column, defined legend.","code":""},{"path":"categorical-data.html","id":"why-not-pie-charts","chapter":"4 Exploring categorical data","heading":"4.3 Why not pie charts?","text":"pie charts well known, typically useful charts data analysis. pie chart shown Figure 4.4 alongside bar plot. generally difficult compare group sizes pie chart (comparing angles) bar plot (comparing heights), especially categories nearly identical counts proportions. case none big categories, difference slight may unable distinguish difference group sizes either plot!\nFigure 4.4: pie chart bar plot number email data set. pie chart see book!\nPie charts nearly useless trying compare two categorical variables, shown Figure 4.5.\nFigure 4.5: Try comparing distributions colors across pie charts , B, C—’s impossible!33\n’re still convinced shouldn’t use pie charts, read “Issue Pie Chart” “Data Viz” blog, “Worst Chart World” article Business Insider.","code":""},{"path":"categorical-data.html","id":"simpson","chapter":"4 Exploring categorical data","heading":"4.4 Simpson’s paradox","text":"1991 study Radelet Pierce examined whether race associated whether death penalty invoked homicide cases34. Table 4.8 Figure 4.6 summarize data 674 defendants indictments involving cases multiple murders Florida 1976 1987.\nTable 4.8: Contingency table homicide cases Florida 1976 1987.\n\nFigure 4.6: Segmented bar plot comparing proportion defendants received death penalty Caucasians African Americans.\nrace defendant associated sentence trial?35Overall, lower percentage African American defendants received death penalty Caucasian defendants (8% compared 11%). Given studies shown racial bias sentencing, may surprising. Let’s look data closely.Since observational data, confounding variables likely present. Recall, confounding variable one associated response variable (sentence) explanatory variable (race defendant). confounding variables present?36If subset data race victim, see different picture. Table 4.9 Figure 4.7 summarize data, separately Caucasian African American homicide victims.\nTable 4.9: Contingency table homicide cases Florida 1976 1987; sentences classified defendant’s race victim’s race.\n\nFigure 4.7: Segmented bar plots comparing proportion Caucasian African American defendants received death penalty; separate plots Caucasian victims African American victims.\ncompare Figures 4.6 4.7, see direction association race defendant sentence reversed subgroup race victim. Overall, larger proportion Caucasians sentenced death penalty African Americans. However, compare cases victim’s race, larger proportion African Americans sentenced death penalty Caucasians!happen? answer race victim confounding variable. Figure 4.8 shows two segmented barplots examining relationship race victim sentence (response variable), relationship race victim race defendant (explanatory variable). see race victim associated response explanatory variables: defendants likely involve victim race, cases African American victims less likely result death penalty.\nFigure 4.8: race victim associated sentence (death penalty death penalty) race defendant. Defendants likely involve victim race, cases African American victims less likely result death penalty.\nThus, extremely low chance homicide case resulting death penalty African Americans combined fact cases African American defendants also African American victim results overall lower rate death penalty sentences African American defendants Caucasian defendants. overall results Figure 4.6 results subgroup Figure 4.7 valid—result “bad statistics”—suggest opposite conclusions. Data , observed effect reverses examine variables within subgroups, exhibit Simpson’s Paradox.Simpson’s Paradox.association explanatory variable response variable reverses examine association within different levels confounding variable, say data exhibit Simpson’s Paradox.","code":""},{"path":"categorical-data.html","id":"chp4-review","chapter":"4 Exploring categorical data","heading":"4.5 Chapter review","text":"","code":""},{"path":"categorical-data.html","id":"summary-2","chapter":"4 Exploring categorical data","heading":"Summary","text":"Fluently working categorical variables important skill data analysts.\nchapter introduced different visualizations numerical summaries applied categorical variables.\ngraphical visualizations even descriptive two variables presented simultaneously.\npresented bar plots, mosaic plots, pie charts (downfalls), estimations conditional proportions.","code":""},{"path":"categorical-data.html","id":"terms-2","chapter":"4 Exploring categorical data","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"categorical-data.html","id":"key-ideas-2","chapter":"4 Exploring categorical data","heading":"Key ideas","text":"Proportions can either unconditional conditional. unconditional proportion proportion entire sample shares characteristic; whereas conditional proportion proportion subgroup sample shares characteristic. computing proportions using contingency table, unconditional proportions computed dividing cell total overall total sample size; conditional proportions computed dividing cell total row column total.Proportions can either unconditional conditional. unconditional proportion proportion entire sample shares characteristic; whereas conditional proportion proportion subgroup sample shares characteristic. computing proportions using contingency table, unconditional proportions computed dividing cell total overall total sample size; conditional proportions computed dividing cell total row column total.distribution single categorical variable can described examining proportions observations category.distribution single categorical variable can described examining proportions observations category.Two variables associated behavior one variable changes value variable. two categorical variables, occurs proportions category one variable change across categories variable. Recall Chapter 1, association imply causation!Two variables associated behavior one variable changes value variable. two categorical variables, occurs proportions category one variable change across categories variable. Recall Chapter 1, association imply causation!","code":""},{"path":"quantitative-data.html","id":"quantitative-data","chapter":"5 Exploring quantitative data","heading":"5 Exploring quantitative data","text":"chapter focuses exploring quantitative data using summary statistics visualizations.\nsummaries graphs presented chapter created using statistical software; however, since might first exposure concepts, take time chapter detail create .\nMastery content presented chapter crucial understanding methods techniques introduced rest book.Consider loan_amount variable loan50 data set, represents loan size 50 loans data set.\nvariable quantitative (numerical) since can sensibly discuss numerical difference size two loans.\nhand, area codes zip codes quantitative, rather categorical variables.Throughout chapter, apply methods using loan50, county, email50 data sets, introduced Section 1.2.\n’d like review variables either data set, see Tables 1.4 1.6.loan50 email50 data sets can found openintro package.\ncounty data can found usdata package.","code":""},{"path":"quantitative-data.html","id":"scatterplots","chapter":"5 Exploring quantitative data","heading":"5.1 Scatterplots for paired data","text":"scatterplot provides case--case view data two quantitative variables.\nFigure 1.4, scatterplot used examine homeownership rate fraction housing units part multi-unit properties (e.g. apartments) county data set.\nAnother scatterplot shown Figure 5.1, comparing total income borrower total_income amount borrowed loan_amount loan50 data set.\nscatterplot, point represents single case.\nSince 50 cases loan50, 50 points Figure 5.1.examining scatterplots, describe four features:Form - trace trend points,\ntrend linear nonlinear?Direction - values x-axis increase, y-values\ntend increase (positive direction) decrease (negative direction)?Strength - closely points follow trend?Unusual observations outliers- unusual observations\nseem match overall pattern scatterplot?\nFigure 5.1: scatterplot loan_amount versus total_income loan50 data set.\nLooking Figure 5.1, see many\nborrowers income $100,000 left side graph, \nhandful borrowers income $250,000. loan amounts vary \n$10,000 around $40,000. data seem linear form, though\nrelationship two variables quite weak. direction \npositive—total income increases, loan amount also tends increase—may unusual observations higher income range,\nthough since relationship weak, hard tell.\nFigure 5.2: scatterplot median household income poverty rate county data set. Data 2017. statistical model also fit data shown dashed line.\nFigure 5.2 shows plot median household income poverty rate 3,142 counties.\ncan said relationship variables?relationship evidently nonlinear, highlighted dashed line. different previous scatterplots seen, show relationships show much, , curvature trend.\nrelationship moderate strong, direction negative,\nappear unusual observations.scatterplots reveal data, useful?37Describe two variables horseshoe-shaped association scatterplot (\\(\\cap\\) \\(\\frown\\))38","code":""},{"path":"quantitative-data.html","id":"dotplots","chapter":"5 Exploring quantitative data","heading":"5.2 Dot plots and the mean","text":"Sometimes interested distribution single variable.\ncases, dot plot provides basic displays.\ndot plot one-variable scatterplot; example using interest rate 50 loans shown Figure 5.3.\nFigure 5.3: dot plot interest_rate loan50 data set. rates rounded nearest percent plot, distribution’s mean shown red triangle.\ndistribution variable description possible values\ntakes frequently value occurs. mean, often called average, common way measure center distribution data.\ncompute mean interest rate 50 loans , add interest rates divide number observations.sample mean often labeled \\(\\bar{x}\\).\nletter \\(x\\) used generic placeholder variable bar \\(x\\) communicates ’re looking average variable. example \\(x\\) represent interest rate, \\(\\bar{x}\\) = 11.57%.\nuseful think mean balancing point distribution39, ’s shown triangle Figure 5.3.Mean.sample mean can calculated sum observed values divided number observations:\\[ \\bar{x} = \\frac{x_1 + x_2 + \\cdots + x_n}{n} \\]Examine equation mean. \\(x_1\\) correspond ? \\(x_2\\) Can infer general meaning \\(x_i\\) might represent?40What \\(n\\) sample loans?41The loan50 data set represents sample larger population loans made Lending Club.\ncompute mean population way sample mean.\nHowever, population mean special label: \\(\\mu\\).\nsymbol \\(\\mu\\) Greek letter mu represents average observations population.\nSometimes subscript, \\(_x\\), used represent variable population mean refers , e.g., \\(\\mu_x\\).\nOften times expensive time consuming measure population mean precisely, often estimate \\(\\mu\\) using sample mean, \\(\\bar{x}\\).Greek letter \\(\\mu\\) pronounced mu, listen pronunciation .average interest rate across loans population can estimated using sample data. Based sample 50 loans, reasonable estimate \\(\\mu_x\\), mean interest rate loans full data set?sample mean, 11.57%, provides rough estimate \\(\\mu_x\\). perfect, statistic single best guess point estimate average interest rate loans population study, parameter. Chapter ?? beyond, develop tools characterize accuracy point estimates, like sample mean. might guessed, point estimates based larger samples tend accurate based smaller samples.mean useful making comparisons across different samples may different sample sizes allows us rescale standardize metric something easily interpretable comparable.Suppose like understand new drug effective treating asthma attacks standard drug.\ntrial 1500 adults set , 500 receive new drug, 1000 receive standard drug control group:Comparing raw counts 200 300 asthma attacks make appear new drug better, artifact imbalanced group sizes.\nInstead, look average number asthma attacks per patient group:New drug: \\(200 / 500 = 0.4\\) asthma attacks per patientStandard drug: \\(300 / 1000 = 0.3\\) asthma attacks per patientThe standard drug lower average number asthma attacks per patient average treatment group.Emilio opened food truck last year sells burritos, business stabilized last 4 months.\n4 month period, made $11,000 working 625 hours.\nEmilio’s competition, Francis, made $13,000 last 4 months working 800 hours. Francis brags Emilio business profitable. Francis’ claim warranted?Emilio’s average hourly earnings provide useful statistic evaluating much venture , least financial perspective, worth:\\[ \\frac{\\$11000}{625\\text{ hours}} = \\$17.60\\text{ per hour} \\]knowing average hourly wage,\nEmilio now put earnings standard unit easier compare many jobs might consider.comparison, Francis’ average hourly wage \\[ \\frac{\\$13000}{800\\text{ hours}} = \\$16.25\\text{ per hour} \\]Thus, Francis’ total earnings larger Emilio’s, standardizing hour, Francis shouldn’t brag.Suppose want compute average income per person US. , might first think take mean per capita incomes across 3,142 counties data set. better approach?county data set special county actually represents many individual people.\nsimply average across income variable, treating counties 5,000 5,000,000 residents equally calculations.\nInstead, compute total income county, add counties’ totals, divide number people counties.\ncompleted steps data, find per capita income US $30,861.\ncomputed simple mean per capita income across counties, result just $26,093!example used called weighted mean.\ninformation topic, check following online supplement regarding weighted means.","code":""},{"path":"quantitative-data.html","id":"histograms","chapter":"5 Exploring quantitative data","heading":"5.3 Histograms and shape","text":"Dot plots show exact value observation. useful small data sets, can become hard read larger samples. Rather showing value observation, prefer think value belonging bin. example, loan50 data set, created table counts number loans interest rates 5.0% 7.5%, number loans rates 7.5% 10.0%, . Observations fall boundary bin (e.g., 10.00%) allocated lower bin. tabulation shown Table 5.1. binned counts plotted bars Figure 5.4 called histogram, resembles heavily binned version stacked dot plot shown Figure 5.3.\nTable 5.1: Counts binned interest_rate data.\n\nFigure 5.4: histogram interest_rate. distribution strongly skewed right.\nHistograms provide view data density. Higher bars represent data relatively common, \n“dense.” instance, many loans rates 5% 10% loans rates 20% 25% data set. bars make easy see density data changes relative interest rate.Histograms especially convenient understanding shape data distribution. Figure 5.4 suggests loans rates 15%, handful loans rates 20%. data trail right way longer right tail, shape said right skewed42Data sets reverse characteristic—long, thinner tail left—said left skewed. also say distribution long left tail. Data sets show roughly equal trailing directions called symmetric.data trail one direction, distribution long tail.\ndistribution long left tail, left skewed negatively skewed.\ndistribution long right tail, right skewed positively skewed.Besides mean (since labeled), can see dot plot Figure 5.3 see histogram Figure 5.4?43In addition looking whether distribution skewed symmetric, histograms can used identify modes. mode represented prominent peak distribution. one prominent peak histogram interest_rate.definition mode sometimes taught math classes value occurrences data set. However, many real-world data sets, common observations value data set, making definition impractical data analysis.Figure 5.5 shows histograms one, two, three prominent peaks. distributions called unimodal, bimodal, multimodal, respectively. distribution two prominent peaks called multimodal. Notice one prominent peak unimodal distribution second less prominent peak counted since differs neighboring bins observations.\nFigure 5.5: Counting prominent peaks, distributions (left right) unimodal, bimodal, multimodal. Note left plot unimodal counting prominent peaks, just peak.\nFigure 5.4 reveals one prominent mode interest rate. distribution unimodal, bimodal, multimodal?44Height measurements young students adult teachers K-3 elementary school taken.\nmany modes expect height data set?45.Looking modes isn’t finding clear correct answer number modes distribution, prominent rigorously defined book. important part examination better understand data.Another type plot helpful exploring shape distribution smoothed histogram, called density plot. density plot scale \\(y\\)-axis total area density curve equal one. allows us get sense proportion data lie certain interval, rather frequency data interval. can change scale histogram plot proportions rather frequencies, overlay density curve rescaled histogram, seen Figure 5.6.\nFigure 5.6: density plot interest_rate overlayed histogram using density scale.\n","code":""},{"path":"quantitative-data.html","id":"variance-sd","chapter":"5 Exploring quantitative data","heading":"5.4 Variance and standard deviation","text":"mean introduced method describe center data set, variability data also important. , introduce two measures variability: variance standard deviation. useful data analysis, even though formulas bit tedious calculate hand. standard deviation easier two comprehend, roughly describes far away typical observation mean.call distance observation mean deviation. deviations \\(1^{st}\\), \\(2^{nd}\\), \\(3^{rd}\\), \\(50^{th}\\) observations interest_rate variable:\\[ x_1 - \\bar{x} = 10.9 - 11.57 = -0.67 \\] \\[ x_2 - \\bar{x} = 9.92 - 11.57 = -1.65 \\] \\[ x_3 - \\bar{x} = 26.3 - 11.57 = 14.73 \\] \\[ \\vdots \\] \\[ x_{50} - \\bar{x} = 6.08 - 11.57 = -5.49 \\]square deviations take average, result equal sample variance, denoted \\(s^2\\):\\[\\begin{align*}\ns^2 &= \\frac{(-0.67)^2 + (-1.65)^2 + (14.73)^2 + \\cdots + (-5.49)^2}{50 - 1} \\\\\n&= \\frac{0.45 + 2.72 + \\cdots + 30.14}{49} \\\\\n&= 25.52\n\\end{align*}\\]divide \\(n - 1\\), rather dividing \\(n\\), computing sample’s variance; ’s mathematical nuance , end result makes statistic slightly reliable useful.Notice squaring deviations two things. First, makes large values relatively much larger. Second, gets rid negative signs.standard deviation defined square root variance:\\[ s = \\sqrt{25.52} = 5.05 \\]often omitted, subscript \\(_x\\) may added variance standard deviation, .e., \\(s_x^2\\) \\(s_x\\), useful reminder variance standard deviation observations represented \\(x_1\\), \\(x_2\\), …, \\(x_n\\).Variance standard deviation.sample variance (near) average squared distance mean:\n\\[\n  s^2 = \\frac{((x_1 - \\bar{x})^2 + (x_2 - \\bar{x})^2 + \\cdots + (x_n - \\bar{x})^2)}{n-1}\n\\]\nsample standard deviation square root variance: \\(s = \\sqrt{s^2}\\).standard deviation useful considering far data distributed mean.\nstandard deviation represents typical deviation observations mean.\ndistribution bell-shaped, 70% data within one standard deviation mean 95% within two standard deviations.\nHowever, percentages necessarily hold shaped distributions!Like mean, population values variance standard deviation special symbols: \\(\\sigma^2\\) variance \\(\\sigma\\) standard deviation.Greek letter \\(\\sigma\\) pronounced sigma, listen pronunciation .\nFigure 5.7: interest_rate variable, 34 50 loans (68%) interest rates within 1 standard deviation mean, 48 50 loans (96%) rates within 2 standard deviations. Usually 70% data within 1 standard deviation mean 95% within 2 standard deviations, though far hard rule.\n\nFigure 5.8: Three different population distributions mean (0) standard deviation (1).\ngood description shape distribution include modality whether distribution symmetric skewed one side.\nUsing Figure 5.8 example, explain description important.46Describe distribution interest_rate variable using histogram Figure 5.4.\ndescription incorporate center, variability, shape distribution, also placed context.\nAlso note especially unusual cases.distribution interest rates unimodal skewed high end. Many rates fall near mean 11.57%, fall within one standard deviation (5.05%) mean.\nexceptionally large interest rates sample 20%.practice, variance standard deviation sometimes used means end, “end” able accurately estimate uncertainty associated sample statistic. example, Chapter ?? standard deviation used calculations help us understand much sample mean varies one sample next.","code":""},{"path":"quantitative-data.html","id":"box-plots-quartiles-and-the-median","chapter":"5 Exploring quantitative data","heading":"5.5 Box plots, quartiles, and the median","text":"box plot (box--whisker plot) summarizes data set using five statistics \nalso identifying unusual observations. five statistics—minimum, first quartile,\nmedian, third quartile, maximum—together called five number summary.\nFigure 5.9 provides dot plot alongside box plot interest_rate variable loan50 data set.\nFigure 5.9: Plot shows dot plot Plot B shows box plot distribution interest rates loan50 dataset.\ndark line inside box represents median, splits data half:\n50% data fall value 50% fall .\nSince loan50 dataset 50 observations (even number),\nmedian defined average two observations closest \n\\(50^{th}\\) percentile. Table 5.2 shows \ninterest rates, arranged ascending order.\ncan see \\(25^{th}\\) \\(26^{th}\\) values \n9.93, corresponds dark line \nbox plot Figure 5.9.\nTable 5.2: Interest rates loan50 dataset, arranged ascending order.\nodd number observations, exactly one\nobservation splits data two halves, case \nobservation median (average needed).Median: number middle.data ordered smallest largest, median observation\nright middle.\neven number observations, two values \nmiddle, median taken average.Mathematically, denote sample size \\(n\\), thenif \\(n\\) odd, median \\([(n+1)/2]^{th}\\) smallest value data set, andif \\(n\\) even, median average \\((n/2)^{th}\\) \\((n/2+1)^{th}\\) smallest values data set.median example percentile. Since 50% data fall \nmedian, median \\(50^{th}\\) percentile.Percentiles.\\(p^{th}\\) percentile value \\(p\\)% data fall \nvalue. example, 7.96\n\\(25^{th}\\) percentile interest rates shown Table 5.2 since 25% data fall \n7.96 (75% fall ).second step building box plot drawing rectangle represent \nmiddle 50% data.\nlength box called interquartile range, IQR short.\n, like standard deviation, measure variability data.\nvariable data, larger standard deviation IQR tend .\ntwo boundaries box called first quartile (\\(25^{th}\\) percentile) third quartile (\\(75^{th}\\) percentile) , often labeled \\(Q_1\\) \\(Q_3\\), respectively47Interquartile range (IQR).IQR interquartile range length box box plot.\ncomputed \n\\[\n  IQR = Q_3 - Q_1,\n\\]\n\\(Q_1\\) \\(Q_3\\) \\(25^{th}\\) \\(75^{th}\\) percentiles, respectively.percent data fall \\(Q_1\\) median?\npercent median \\(Q_3\\)?48Extending box, whiskers attempt capture data outside box.\nwhiskers box plot reach minimum maximum values data, unless points considered unusually high unusually low, identified potential outliers box plot.\nlabeled dot box plot.\npurpose labeling points—instead extending whiskers minimum maximum observed values—help identify observations appear unusually distant rest data.\nvariety formulas determining whether particular data point considered outlier, different statistical software use different formulas.\ncommonly used formula value beyond \\(1.5\\times IQR\\)[choice exactly 1.5 arbitrary, commonly used value box plots.] away box considered outlier.\nsense, box like body box plot whiskers like arms trying reach rest data, outliers.Figure 5.9,\nupper whisker extend last two points, 24.85% 26.3%, \n\\(Q_3 + 1.5\\times IQR\\), extends last point limit.\nlower whisker stops minimum value data set, 5.31%, since outliers lower end distribution.whiskers extend actual data points—limits outliers. ,\nvalues \\(Q_1 - 1.5\\times IQR\\) \\(Q_3 + 1.5\\times IQR\\) shown\nplot.Outliers extreme.outlier observation appears extreme relative rest data.\nExamining data outliers serves many useful purposes, includingidentifying strong skew distribution,identifying possible data collection data entry errors, andproviding insight interesting properties data.Using box plot Figure 5.9, estimate values \\(Q_1\\), \\(Q_3\\), IQR interest_rate loan50 data set.49","code":""},{"path":"quantitative-data.html","id":"describing-and-comparing-quantitative-distributions","chapter":"5 Exploring quantitative data","heading":"5.6 Describing and comparing quantitative distributions","text":"review, describing scatterplot—association \ntwo quantitative variables, look four features:FormDirectionStrengthOutliersWhen asked describe compare univariate (single variable) quantitative distributions, look four features:CenterVariabilityShapeOutliersWe can compare quantitative distributions using side--side box plots,\nstacked histograms dot plots. Recall loan50 data set represents sample larger loan data set called loans.\nlarger data set contains information 10,000 loans made Lending Club. Figure 5.10 examines relationship homeownership, loans data can take value rent, mortgage (owns mortgage), , interest_rate. Note homeownership\ncategorical variable interest_rate quantitative variable.\nFigure 5.10: Side--side box plots loan interest rates homeownership category.\nsee immediately features easier discern box plots, others histograms. Shape shown clearly histograms, center (measured median) easy compare across groups side--side box plots.Using Figure 5.10 write sentences comparing distributions loan amount\nacross different homeownership categories.median loan amount higher mortgage (around $16,000) rent (around $12,000-$13,000). However, variability loan amounts similar across homeownership categories, IQR around $15,000 loans ranging hundred dollars $40,000. see histograms distribution loan amounts skewed right three homeownership categories, means mean loan amount higher median loan amount. apparent outliers mortgage category, rent categories outliers $40,000.Besides center, variability, shape, outliers, another interesting feature distributions result rounding. Loan amounts data set often rounded nearest 100, see spikes values histogram—something evident box plots.","code":""},{"path":"quantitative-data.html","id":"robust-statistics","chapter":"5 Exploring quantitative data","heading":"5.7 Robust statistics","text":"sample statistics interest_rate data set affected observation, 26.3%?\nhappened loan instead 15%?\nhappen summary statistics observation 26.3% even larger, say 35%?\nscenarios plotted alongside original data Figure 5.11, sample statistics computed scenario Table 5.3.\nFigure 5.11: Dot plots original interest rate data two modified data sets.\n\nTable 5.3: comparison median, IQR, mean, standard deviation change value extereme observation original interest data changes.\naffected extreme observations, mean median?standard deviation IQR affected extreme observations?50The median IQR called robust statistics extreme observations little effect values—moving extreme value generally little influence statistics.\nhand, mean standard deviation heavily influenced changes extreme observations, can important situations. Additionally, mean tends get pulled direction distribution’s skewness, skewness little affect median.median IQR change three scenarios Table 5.3.\nmight case?median IQR sensitive numbers near \\(Q_1\\), median, \\(Q_3\\).\nSince values regions stable three data sets, median IQR estimates also stable.distribution loan amounts loan50 data set right skewed, large loans lingering right tail.\nwanting understand typical loan size, interested mean median?51","code":""},{"path":"quantitative-data.html","id":"transforming-data-special-topic","chapter":"5 Exploring quantitative data","heading":"5.8 Transforming data (special topic)","text":"data strongly skewed, sometimes transform easier model. transformation rescaling data using function.\nFigure 5.12: Plot : histogram populations US counties. Plot B: histogram log\\(_{10}\\)-transformed county populations. plot, x-value corresponds power 10, e.g. 4 x-axis corresponds \\(10^4 =\\) 10,000. Data 2017.\nConsider histogram county populations shown left Figure 5.12, shows extreme skew. useful plot?Nearly data fall left-bin, extreme skew obscures many potentially interesting details data.standard transformations may useful strongly right skewed data much data positive clustered near zero.\ninstance, plot logarithm (base 10) county populations results new histogram Figure 5.12.\ndata symmetric, potential outliers appear much less extreme original data set.\nreigning outliers extreme skew, transformations like often make easier build statistical models data.Transformations can also applied one variables scatterplot.\nscatterplot population change 2010 2017 population 2010 shown Figure 5.13.\nfirst scatterplot, ’s hard decipher interesting patterns population variable strongly skewed.\nHowever, apply log\\(_{10}\\) transformation population variable, shown \nFigure 5.13, positive association variables revealed.\nfact, may interested fitting trend line data explore methods around fitting regression lines Chapter 6.\nFigure 5.13: Plot : Scatterplot population change population change. Plot B: ~scatterplot data population size log-transformed.\nTransformations logarithm can useful, .\ninstance, square root (\\(\\sqrt{\\text{original observation}}\\)) inverse (\\(\\frac{1}{\\text{original observation}}\\)) commonly used data scientists.\nCommon goals transforming data see data structure differently, reduce skew, assist modeling, straighten nonlinear relationship scatterplot.","code":""},{"path":"quantitative-data.html","id":"mapping-data-special-topic","chapter":"5 Exploring quantitative data","heading":"5.9 Mapping data (special topic)","text":"county data set offers many numerical variables plot using dot plots, scatterplots, box plots, miss true nature data.\nRather, encounter geographic data, create intensity map, colors used show higher lower values variable.\nFigures 5.14 5.15 show intensity maps poverty rate percent (poverty), unemployment rate (unemployment_rate), homeownership rate percent (homeownership), median household income (median_hh_income).\ncolor key indicates colors correspond values.\nintensity maps generally helpful getting precise values given county, helpful seeing geographic trends generating interesting research questions hypotheses.interesting features evident poverty unemployment rate intensity maps?Poverty rates evidently higher locations.\nNotably, deep south shows higher poverty rates, much Arizona New Mexico.\nHigh poverty rates evident Mississippi flood plains little north New Orleans also large section Kentucky.\nunemployment rate follows similar trends, can see correspondence two\nvariables.\nfact, makes sense higher rates unemployment closely related poverty rates.\nOne observation stands comparing two maps: poverty rate much higher unemployment rate, meaning many people may working, making enough break poverty.interesting features evident median household income intensity map Figure 5.15?52\nFigure 5.14: Plot : Intensity map poverty rate (percent). Plot B: Intensity map unemployment rate (percent).\n\nFigure 5.15: Plot : Intensity map homeownership rate (percent). Plot B: Intensity map median household income ($1000s).\n","code":""},{"path":"quantitative-data.html","id":"chp5-review","chapter":"5 Exploring quantitative data","heading":"5.10 Chapter review","text":"","code":""},{"path":"quantitative-data.html","id":"summary-3","chapter":"5 Exploring quantitative data","heading":"Summary","text":"Fluently working quantitaitve variables important skill data analysts.\nchapter introduced different visualizations numerical summaries applied quantitative variables.\ngraphical visualizations even descriptive two variables presented simultaneously.\npresented scatterplots, dot plots, histograms, box plots.\nQuantitative variables can summarized using mean, median, quartiles, standard deviation, variance.","code":""},{"path":"quantitative-data.html","id":"terms-3","chapter":"5 Exploring quantitative data","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"quantitative-data.html","id":"key-ideas-3","chapter":"5 Exploring quantitative data","heading":"Key ideas","text":"Two variables associated behavior one variable depends value variable. Two quantitative variables associated trend apparent scatterplot. Recall Chapter 1, association imply causation!Two variables associated behavior one variable depends value variable. Two quantitative variables associated trend apparent scatterplot. Recall Chapter 1, association imply causation!describing distribution single quantitative variable histogram, dot plot, box plot, look (1) center, (2) variability, (3) shape, (4) outliers.describing distribution single quantitative variable histogram, dot plot, box plot, look (1) center, (2) variability, (3) shape, (4) outliers.describing relationship shown two quantitative variables scatterplot, look (1) form, (2) direction, (3) strength, (4) outliers.describing relationship shown two quantitative variables scatterplot, look (1) form, (2) direction, (3) strength, (4) outliers.","code":""},{"path":"cor-reg.html","id":"cor-reg","chapter":"6 Correlation and regression","heading":"6 Correlation and regression","text":"Linear regression powerful statistical technique.\nMany people familiarity regression just reading news, straight lines overlaid scatterplots.\nLinear models can used prediction evaluate whether linear relationship two numerical variables.","code":""},{"path":"cor-reg.html","id":"fit-line-res-cor","chapter":"6 Correlation and regression","heading":"6.1 Fitting a line, residuals, and correlation","text":"’s helpful think deeply line fitting process. section, define form linear model, explore criteria makes good fit, introduce new statistic called correlation.","code":""},{"path":"cor-reg.html","id":"fitting-a-line-to-data","chapter":"6 Correlation and regression","heading":"6.1.1 Fitting a line to data","text":"Figure 6.1 shows two variables whose relationship can modeled perfectly straight line.\nequation line \\(y = 5 + 64.96 x\\).\nConsider perfect linear relationship means: know exact value \\(y\\) just knowing value \\(x\\).\nunrealistic almost natural process.\nexample, took family income (\\(x\\)), value provide useful information much financial support college may offer prospective student (\\(y\\)).\nHowever, prediction far perfect, since factors play role financial support beyond family’s finances.\nFigure 6.1: Requests twelve separate buyers simultaneously placed trading company purchase Target Corporation stock (ticker TGT, December 28th, 2018), total cost shares reported. cost computed using linear formula, linear fit perfect.\nLinear regression statistical method fitting line data relationship two variables, \\(x\\) \\(y\\), can modeled straight line error:\\[ y = \\beta_0 + \\beta_1x + \\varepsilon\\]values \\(\\beta_0\\) \\(\\beta_1\\) represent model’s parameters (\\(\\beta\\) Greek letter beta), error represented \\(\\varepsilon\\) (Greek letter epsilon).\nparameters estimated using data, write point estimates \\(b_0\\) \\(b_1\\).\nuse \\(x\\) predict \\(y\\), usually call \\(x\\) explanatory predictor variable, call \\(y\\) response. also often drop \\(\\epsilon\\) term writing model since main focus often prediction average outcome. \\(\\epsilon\\) term dropped, put “hat” \\(y\\) (\\(\\hat{y}\\)) signal model yields prediction \\(y\\), actual value.rare data fall perfectly straight line.\nInstead, ’s common data appear cloud points,\nexamples shown Figure 6.2.\ncase, data fall around straight line, even none observations fall exactly line.\nfirst plot shows relatively strong downward linear trend, remaining variability data around line minor relative strength relationship \\(x\\) \\(y\\).\nsecond plot shows upward trend , evident, strong first. last plot shows weak downward trend data, slight can hardly notice .\nexamples, uncertainty regarding estimates model parameters, \\(\\beta_0\\) \\(\\beta_1\\).\ninstance, might wonder, move line little, tilt less?\nmove forward chapter, learn criteria line-fitting, also learn uncertainty associated estimates model parameters.\nFigure 6.2: Three data sets linear model may useful even though data fall exactly line.\nalso cases fitting straight line data, even clear relationship variables, helpful.\nOne case shown Figure 6.3 clear relationship variables even though trend linear.\ndiscuss nonlinear trends chapter next, details fitting nonlinear models saved later course.\nFigure 6.3: best fitting line data flat, useful nonlinear case. data physics experiment.\n","code":""},{"path":"cor-reg.html","id":"using-linear-regression-to-predict-possum-head-lengths","chapter":"6 Correlation and regression","heading":"6.1.2 Using linear regression to predict possum head lengths","text":"Brushtail possums marsupial lives Australia, photo\none shown Figure 6.4.\nResearchers captured 104 animals took body measurements releasing animals back wild.\nconsider two measurements: total length possum, head tail, length possum’s head.\nFigure 6.4: common brushtail possum Australia. Photo Greg Schecter, flic.kr/p/9BAFbR, CC 2.0 license.\npossum data can found openintro package.Figure 6.5 shows scatterplot head length (mm) total length (cm) possums.\npoint represents single possum data.\nhead total length variables associated: possums average total length also tend average head lengths.\nrelationship perfectly linear, helpful partially explain connection variables straight line.\nFigure 6.5: scatterplot showing head length total length 104 brushtail possums. point representing possum head length 86.7 mm total length 84 cm highlighted.\nwant describe relationship head length total length variables possum data set using line.\nexample, use total length predictor variable, \\(x\\), predict possum’s head length, \\(y\\).\nfit linear relationship using technology (criteria discussed Section 6.2), Figure 6.6.\nFigure 6.6: reasonable linear model fit represent relationship head length total length.\nequation line \\[\\hat{y} = 43+0.57x.\\]“hat” \\(y\\) used signify estimate.\ncan use line discuss properties possums.\ninstance, equation predicts possum total length 80 cm head length \\[\\hat{y} = 43 + 0.57 \\times 80 = 88.6 \\text{ mm}.\\]estimate may viewed average: equation predicts possums total length 80 cm average head length 88.6 mm.\nAbsent information 80 cm possum, prediction head length uses average reasonable estimate.may variables help us predict head length possum besides length.\nPerhaps relationship little different male possums female possums, perhaps differ possums one region Australia versus another region.\nPlot Figure 6.7 shows relationship total length head length brushtail possums, taking consideration sex.\nMale possums (represented blue triangles) seem larger terms total length head length female possums (represented red circles).\nPlot B Figure 6.7 shows relationship, taking consideration age.\n’s harder tell age changes relationship total length head length possums.\nFigure 6.7: Relationship total length head lentgh brushtail possums, taking consideration sex (Plot ) age (Plot B).\nChapter 7, ’ll learn can include one predictor model.\nget , first need better understand best build simple linear model one predictor.","code":""},{"path":"cor-reg.html","id":"residuals","chapter":"6 Correlation and regression","heading":"6.1.3 Residuals","text":"Residuals leftover variation data accounting model fit:\\[\\text{Data} = \\text{Fit} + \\text{Residual}\\]observation residual, three residuals linear model fit data shown Figure 6.8.\nobservation regression line, residual, vertical distance observation line, positive.\nObservations line negative residuals.\nOne goal picking right linear model residuals small possible.Figure 6.8 almost replica Figure 6.6, three points data highlighted.\nobservation marked red circle small, negative residual -1; observation marked green diamond large residual +7; observation marked yellow triangle moderate residual -4.\nsize residual usually discussed terms absolute value.\nexample, residual observation marked yellow triangle larger observation marked red circle \\(|-4|\\) larger \\(|-1|\\).\nFigure 6.8: reasonable linear model fit represent relationship head length total length, three points residuals highlighted.\nResidual: Difference observed expected.residual \\(^{th}\\) observation \\((x_i, y_i)\\) difference observed response (\\(y_i\\)) response predict based model fit (\\(\\hat{y}_i\\)):\\[e_i = y_i - \\hat{y}_i\\]typically identify \\(\\hat{y}_i\\) plugging \\(x_i\\) model.linear fit shown Figure 6.8 given \\(\\hat{y} = 43+0.57x\\).\nBased line, formally compute residual observation\n\\((76.0, 85.1)\\).\nobservation marked red circle Figure 6.8.\nCheck earlier visual estimate, \\(-1\\).first compute predicted value observation marked red circle based model:\\[\\hat{y} = 43+0.57x = 43+0.57\\times 76.0 = 86.3mm\\]Next, compute difference actual head length predicted head length:\\[e = y - \\hat{y} = 85.1 -  86.3 = -1.2 mm\\]model’s error \\(e = -1.2\\) mm, close \nvisual estimate \\(-1\\) mm. negative residual indicates linear model overpredicted head length particular possum.model underestimates observation, residual positive negative? overestimates observation?53Compute residuals observation marked green diamond, \\((85.0, 98.6)\\), observation marked yellow triangle, \\((95.5, 94.0)\\), figure using linear relationship \\(\\hat{y} = 43 + 0.57x\\).54Residuals helpful evaluating well linear model fits data set.\noften display residual plot one shown Figure 6.9 regression line Figure 6.8.\nresiduals plotted fitted values \\(x\\)-axis vertical coordinate residual.\ninstance, point \\((85.0, 98.6)\\) (marked green diamond) predicted value 91.45 mm residual 7.15 mm, residual plot placed \\((91.45, 7.15)\\).\nCreating residual plot sort like tipping scatterplot regression line horizontal.\nFigure 6.9: Residual plot model predicting head length total length brushtail possums.\nOne purpose residual plots identify characteristics patterns still apparent data fitting model.\nFigure 6.10 shows three scatterplots linear models first row residual plots second row. Can identify patterns remaining residuals?first data set (first column), residuals show obvious patterns.\nresiduals appear scattered randomly around dashed line represents 0.second data set shows pattern residuals.\ncurvature scatterplot, obvious residual plot.\nuse straight line model data. Instead, advanced technique used.last plot shows little upwards trend, residuals also show obvious patterns.\nreasonable try fit linear model data.\nHowever, unclear whether slope parameter statistically discernible zero.\npoint estimate slope parameter, labeled \\(b_1\\), zero, might wonder just due chance.\naddress sort scenario Chapter ??.\nFigure 6.10: Sample data best fitting lines (top row) corresponding residual plots (bottom row).\n","code":""},{"path":"cor-reg.html","id":"describing-linear-relationships-with-correlation","chapter":"6 Correlation and regression","heading":"6.1.4 Describing linear relationships with correlation","text":"’ve seen plots strong linear relationships others weak linear relationships.\nuseful quantify strength linear relationships statistic.Correlation: strength direction linear relationship.Correlation always takes values -1 1, summary statistic describes strength (magnitude) direction (sign) linear relationship two variables. denote correlation \\(R\\) \\(r\\).can compute correlation using formula, just sample mean standard deviation.\nformula rather complex55,\nlike statistics, generally perform calculations computer calculator.\nFigure 6.11 shows eight plots corresponding correlations. relationship perfectly linear correlation either -1  1.  relationship strong positive, correlation near +1.  strong negative, near -1.  apparent linear relationship variables, correlation near zero.\nFigure 6.11: Sample scatterplots correlations. first row shows variables positive relationshiop, represented trend right. second row shows variables negative trend, large value one variable associated low value .\ncorrelation intended quantify strength direction linear trend.\nNonlinear trends, even strong, sometimes produce correlations reflect strength relationship; see three examples \nFigure 6.12.\nFigure 6.12: Sample scatterplots correlations. case, strong relationship variables, However, relationship nonlinear, correlation relatively weak.\nstraight line good fit data sets represented Figure 6.12.\nTry drawing nonlinear curves plot.\ncreate curve , describe important  fit.56","code":""},{"path":"cor-reg.html","id":"least-squares-regression","chapter":"6 Correlation and regression","heading":"6.2 Least squares regression","text":"Fitting linear models eye open criticism since based individual’s preference. section, use least squares regression rigorous approach.","code":""},{"path":"cor-reg.html","id":"gift-aid-for-freshman-at-elmhurst-college","chapter":"6 Correlation and regression","heading":"6.2.1 Gift aid for freshman at Elmhurst College","text":"section considers family income gift aid data random sample fifty students freshman class Elmhurst College Illinois.\nGift aid financial aid need paid back, opposed loan.\nscatterplot data shown Figure 6.13 along two linear fits.\nlines follow negative trend data; students higher family incomes tended lower gift aid university.\nFigure 6.13: Gift aid family income random sample 50 freshman students Elmhurst College, shown least squares line (solid line) line fit minimizing sum residual magnitudes (dashed line).\ncorrelation positive negative Figure 6.13?57","code":""},{"path":"cor-reg.html","id":"an-objective-measure-for-finding-the-best-line","chapter":"6 Correlation and regression","heading":"6.2.2 An objective measure for finding the best line","text":"begin thinking mean “best”. Mathematically, want line small residuals.\nfirst option may come mind minimize sum residual magnitudes:\\[|e_1| + |e_2| + \\dots + |e_n|\\]accomplish computer program.\nresulting dashed line shown Figure 6.13 demonstrates fit can quite reasonable.\nHowever, common practice choose line minimizes sum squared residuals:\\[e_{1}^2 + e_{2}^2 + \\dots + e_{n}^2\\]line minimizes least squares criterion represented solid line Figure 6.13.\ncommonly called least squares line.\nfollowing three possible reasons choose option instead trying minimize sum residual magnitudes without squaring:commonly used method.Computing least squares line widely supported statistical software.many applications, residual twice large another residual twice bad. example, 4 usually twice bad 2. Squaring residuals accounts discrepancy.first two reasons largely tradition convenience; last reason explains least squares criterion typically helpful.58","code":""},{"path":"cor-reg.html","id":"finding-and-interpreting-the-least-squares-line","chapter":"6 Correlation and regression","heading":"6.2.3 Finding and interpreting the least squares line","text":"Elmhurst data, write equation linear regression model \n\\[aid = \\beta_0 + \\beta_{1}\\times \\textit{family_income} + \\epsilon.\\]\nmodel equation set predict gift aid based student’s family income, useful students considering Elmhurst.\ntwo unknown values \\(\\beta_0\\) \\(\\beta_1\\) parameters linear regression model.least squares regression line, computed based observed data, provides estimates parameters \\(\\beta_0\\) \\(\\beta_1\\):\n\\[\\widehat{aid} = b_0 + b_{1}\\times \\textit{family_income}.\\]\npractice, estimation done using computer way estimates, like sample mean, can estimated using computer calculator.dataset data stored called elmhurst.\nfirst 5 rows dataset given Table 6.1.\nTable 6.1: First five rows elmhurst dataset.\ncan see family income recorded variable called family_income gift aid university recorded variable called gift_aid.\nnow, won’t worry price_paid variable.\nalso note data 2011-2012 academic year, monetary amounts given $1,000s, .e., family income first student data shown Table 6.1 $92,900 received gift aid $21,700. (data source states numbers rounded nearest whole dollar.)Using data, can estimate linear regression line fitting linear model data lm() function R.model output tells us intercept approximately 24.319 slope approximately -0.043.values mean?\nInterpreting parameters regression model often one important steps analysis.intercept slope estimates Elmhurst data \\(b_0\\) = 24.319 \\(b_1\\) = -0.043.\nnumbers really mean?Interpreting slope parameter helpful almost application.\nadditional $1,000 family income, expect student receive net difference 1,000 \\(\\times\\) (-0.0431) = -$43.10 aid average, .e., $43.10 less.\nNote higher family income corresponds less aid coefficient family income negative model.\nmust cautious interpretation: real association, interpret causal connection variables data observational.\n, increasing student’s family income may cause student’s aid drop. (reasonable contact college ask relationship causal, .e., Elmhurst College’s aid decisions partially based students’ family income.) appropriate interpretation : additional $1,000 family income associated estimated decrease $43.10 aid average.estimated intercept \\(b_0\\) = 24.319 describes average aid student’s family income.\nmeaning intercept relevant application since family income students Elmhurst  $0.\napplications, intercept may little practical value observations \\(x\\) near zero.Interpreting parameters estimated least squares.slope describes estimated difference \\(y\\) variable explanatory variable \\(x\\) case happened one unit larger.intercept describes average outcome \\(y\\) \\(x=0\\) linear model valid way \\(x=0\\), many applications case.Suppose high school senior considering Elmhurst College.\nCan simply use linear equation estimated calculate financial aid university?may use estimate, though qualifiers approach important.\nFirst, data come one freshman class, way aid determined university may change year year.\nSecond, equation provide imperfect estimate.\nlinear equation good capturing trend data, individual student’s aid perfectly predicted.Statistical software usually used compute least squares line typical output generated result fitting regression models looks like one shown Table 6.2.\nnow focus first column output, lists \\({b}_0\\) \\({b}_1\\).\nChapter ?? dive deeper remaining columns give us information accurate precise values intercept slope calculated sample 50 students estimating population parameters intercept slope students.\nTable 6.2: Summary least squares fit Elmhurst data.\nlike learn using R fit linear models, see Section ?? interactive R tutorials.","code":"\nlm(gift_aid ~ family_income, data = elmhurst)\n#> \n#> Call:\n#> lm(formula = gift_aid ~ family_income, data = elmhurst)\n#> \n#> Coefficients:\n#>   (Intercept)  family_income  \n#>       24.3193        -0.0431"},{"path":"cor-reg.html","id":"calculating-the-least-squares-regression-line-using-summary-statistics-special-topic","chapter":"6 Correlation and regression","heading":"6.2.3.1 Calculating the least squares regression line using summary statistics (special topic)","text":"alternative way calculating values intercept slope least squares line manual calculations using formulas.\nmethod commonly used practicing statisticians data scientists, useful work first time ’re learning least squares line modeling general.\nCalculating values hand leverages two properties least squares line:slope least squares line can estimated \\[b_1 = \\frac{s_y}{s_x} R \\]\\(R\\) correlation two variables, \\(s_x\\) \\(s_y\\) sample standard deviations explanatory variable response, respectively.\\(\\bar{x}\\) sample mean explanatory variable \\(\\bar{y}\\) sample mean vertical variable, point \\((\\bar{x}, \\bar{y})\\) least squares line.Table 6.3 shows sample means family income gift aid $101,780 $19,940, respectively.\nplot point \\((102, 19.9)\\) Figure 6.13 verify falls least squares line (solid line).\nTable 6.3: Summary statistics family income gift aid.\nNext, formally find point estimates \\(b_0\\) \\(b_1\\) parameters \\(\\beta_0\\) \\(\\beta_1\\).Using summary statistics Table 6.3, compute slope regression line gift aid family income.Compute slope using summary statistics Table 6.3:\\[b_1 = \\frac{s_y}{s_x} r = \\frac{5.46}{63.2}(-0.499) = -0.0431\\]might recall form line math class, can use find model fit, including estimate \\(b_0\\). Given slope line point line, \\((x_0, y_0)\\), equation line can written \\[y - y_0 = slope\\times (x - x_0)\\]Identifying least squares line summary statistics.identify least squares line summary statistics:Estimate slope parameter, \\(b_1 = (s_y / s_x) R\\).Noting point \\((\\bar{x}, \\bar{y})\\) least squares line, use \\(x_0 = \\bar{x}\\) \\(y_0 = \\bar{y}\\) point-slope equation: \\(y - \\bar{y} = b_1 (x - \\bar{x})\\).Simplify equation, reveal \\(b_0 = \\bar{y} - b_1 \\bar{x}\\).Using point (102, 19.9) sample means slope estimate \\(b_1 = -0.0431\\), find least-squares line predicting aid based family income.Apply point-slope equation using \\((102, 19.9)\\) slope \\(b_1 = -0.0431\\):\\[\\begin{aligned}\ny - y_0  &= b_1 (x - x_0) \\\\\ny - 19.9 &= -0.0431(x - 102)\n\\end{aligned}\\]Expanding right side adding 19.9 side, equation simplifies:\\[\\begin{aligned}\n\\widehat{aid} = 24.3 - 0.0431 \\times \\textit{family_income}\n\\end{aligned}\\]replaced \\(y\\) \\(\\widehat{aid}\\) \\(x\\) family_income put equation context.\nfinal equation always include “hat” variable predicted, whether generic “\\(y\\)” named variable like “\\(aid\\)”.","code":""},{"path":"cor-reg.html","id":"extrapolation-is-treacherous","chapter":"6 Correlation and regression","heading":"6.2.4 Extrapolation is treacherous","text":"blizzards hit East Coast winter, proved satisfaction global warming fraud. snow freezing cold. alarming trend, temperatures spring risen. Consider : February \\(6^{th}\\) 10 degrees. Today hit almost 80. rate, August 220 degrees. clearly folks climate debate rages .59Stephen Colbert\nApril 6th, 2010Linear models can used approximate relationship two variables. However, models real limitations.\nLinear regression simply modeling framework.\ntruth almost always much complex simple line.\nexample, know data outside limited window behave.Use model \\(\\widehat{aid} = 24.3 - 0.0431 \\times \\textit{family_income}\\) estimate aid another freshman student whose family income $1 million.want calculate aid family $1 million income.\nNote model, represented 1,000 since data $1,000s.\\[24.3 - 0.0431 \\times 1000 = -18.8 \\]model predicts student -$18,800 aid (!).\nHowever, Elmhurst College offer negative aid select students pay extra top tuition attend.Applying model estimate values outside realm original data called extrapolation.\nGenerally, linear model approximation real relationship two variables.\nextrapolate, making unreliable bet approximate linear relationship valid places analyzed.","code":""},{"path":"cor-reg.html","id":"describing-the-strength-of-a-fit","chapter":"6 Correlation and regression","heading":"6.2.5 Describing the strength of a fit","text":"evaluated strength linear relationship two variables earlier using correlation, \\(R\\). However, common explain strength linear fit using \\(R^2\\), called R-squared.\nprovided linear model, might like describe closely data cluster around linear fit.\\(R^2\\) linear model describes amount variation response explained least squares line.\nexample, consider Elmhurst data, shown Figure 6.13.\nvariance response variable, aid received, \\(s_{aid}^2 \\approx 29.8\\) million.\nHowever, apply least squares line, model reduces uncertainty predicting aid using student’s family income.\nvariability residuals describes much variation remains using model: \\(s_{_{RES}}^2 \\approx 22.4\\) million.\nshort, reduction \n\\[\\frac{s_{aid}^2 - s_{_{RES}}^2}{s_{aid}^2}\n  = \\frac{29800 - 22400}{29800}\n  = \\frac{7500}{29800}\n  \\approx 0.25\\]\n25% data’s variation using information family income predicting aid using linear model.\ncorresponds exactly R-squared value:\\[R = -0.499 \\rightarrow R^2 = 0.25\\]\nsquared correlation coefficient, \\(R^2\\), also called coefficient determination.Coefficient determination: proportion variability response explained model.Since \\(R\\) always \\(-1\\) \\(1\\), \\(R^2\\) always \\(0\\) \\(1\\). statistic called coefficient determination measures proportion variation response variable, \\(y\\), can explained linear model predictor \\(x\\).Examine scatterplot head length (mm) versus total length (cm) possums Figure 6.6.\ncorrelation two variables \\(R = 0.69\\).\nFind interpret coefficient determination.find \\(R^2\\), square correlation: \\(R^2 = (0.69)^2 = 0.48\\).\ntells us 48% variation possum head length can explained total length.\nvisualized Figure 6.14.\nFigure 6.14: 104 possums, range head lengths 103 \\(-\\) 83 = 20 mm. However, among possums total length (e.g., 85 cm), range head lengths reduced 10 mm, 50% reduction, matches \\(R^2 = 0.48\\), 48%.\nlinear model strong negative relationship correlation -0.97, much variation response explained explanatory variable?60More generally, \\(R^2\\) can calculated ratio measure variability around line divided measure total variability.Sums squares measure variability \\(y\\).can measure variability \\(y\\) values far tend fall mean, \\(\\bar{y}\\). define value total sum squares,\\[\nSST = (y_1 - \\bar{y})^2 + (y_2 - \\bar{y})^2 + \\cdots + (y_n - \\bar{y})^2.\n\\]Left-variability \\(y\\) values know \\(x\\) can measured sum squared errors, sum squared residuals61,\\[\nSSE = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\cdots + (y_n - \\hat{y}_n)^2 = e_{1}^2 + e_{2}^2 + \\dots + e_{n}^2\n\\]coefficient determination can calculated \\[\nR^2 = \\frac{SST - SSE}{SST} = 1 - \\frac{SSE}{SST}\n\\]Among 104 possums, total variability head length (mm) \\(SST = 1315.2\\)62. sum squared residuals \\(SSE = 687.0\\). Find \\(R^2\\).Since know \\(SSE\\) \\(SST\\), can calculate \\(R^2\\) \\[\nR^2 = 1 - \\frac{SSE}{SST} = 1 - \\frac{687.0}{1315.2} = 0.48,\n\\]\nvalue found squared correlation: \\(R^2 = (0.69)^2 = 0.48\\).","code":""},{"path":"cor-reg.html","id":"categprical-predictor-two-levels","chapter":"6 Correlation and regression","heading":"6.2.6 Categorical predictors with two levels (special topic)","text":"Categorical variables also useful predicting outcomes.\nconsider categorical predictor two levels (recall level category).\n’ll consider Ebay auctions video game, Mario Kart Nintendo Wii, total price auction condition game recorded. want predict total price based game condition, takes values used new.mariokart data can found openintro package.plot auction data shown Figure 6.15.\nNote original dataset contains Mario Kart games sold prices $100 analysis limited focus 141 Mario Kart games sold $100.\nFigure 6.15: Total auction prices video game Mario Kart, divided used (\\(x = 0\\)) new (\\(x = 1\\)) condition games. least squares regression line also shown.\nincorporate game condition variable regression equation, must convert categories numerical form.\nusing indicator variable called condnew, takes value 1 game new 0 game used.\nUsing indicator variable, linear model may written \\[\\widehat{price} = \\beta_0 + \\beta_1 \\times condnew\\]parameter estimates given Table 6.4.\nTable 6.4: Least squares ression summary final auction price condition game.\nUsing values Table 6.4, model equation can summarized \\[\\widehat{price} = 42.871 + 10.90 \\times condnew\\]Interpret two parameters estimated model price Mario Kart eBay auctions.\nintercept estimated price condnew takes value 0, .e. game used condition.\n, average selling price used version game $42.87.slope indicates , average, new games sell $10.90 used games.Interpreting model estimates categorical predictors.estimated intercept value response variable first category (.e. category corresponding indicator value  0).\nestimated slope average change response variable two categories.’ll elaborate topic Chapter 7, examine influence many predictor variables simultaneously using multiple regression.","code":""},{"path":"cor-reg.html","id":"outliers-in-regression","chapter":"6 Correlation and regression","heading":"6.3 Outliers in linear regression","text":"section, identify criteria determining outliers important influential.\nOutliers regression observations fall far cloud points.\npoints especially important can strong influence least squares line.","code":""},{"path":"cor-reg.html","id":"types-of-outliers","chapter":"6 Correlation and regression","heading":"6.3.1 Types of outliers","text":"three plots shown Figure 6.16 along least squares line residual plots.\n scatterplot residual plot pair, identify outliers note influence least squares line.\nRecall outlier point doesn’t appear belong vast majority points.: one outlier far points, though appears slightly influence  line.: one outlier far points, though appears slightly influence  line.B: one outlier right, though quite close least squares line, suggests wasn’t influential.B: one outlier right, though quite close least squares line, suggests wasn’t influential.C: one point far away cloud, outlier appears pull least squares line right; examine line around primary cloud doesn’t appear fit  well.C: one point far away cloud, outlier appears pull least squares line right; examine line around primary cloud doesn’t appear fit  well.\nFigure 6.16: Three plots, least squares line residual plot. data sets least one outlier.\nthree plots shown Figure 6.17 along least squares line residual plots.\nprevious exercise,  scatterplot residual plot pair, identify outliers note influence least squares line.\nRecall outlier point doesn’t appear belong vast majority points.D: primary cloud small secondary cloud four outliers. secondary cloud appears influencing line somewhat strongly, making least square line fit poorly almost everywhere. might interesting explanation dual clouds, something investigated.D: primary cloud small secondary cloud four outliers. secondary cloud appears influencing line somewhat strongly, making least square line fit poorly almost everywhere. might interesting explanation dual clouds, something investigated.E: obvious trend main cloud points outlier right appears largely control slope least squares line.E: obvious trend main cloud points outlier right appears largely control slope least squares line.F: one outlier far cloud. However, falls quite close least squares line appear influential.F: one outlier far cloud. However, falls quite close least squares line appear influential.\nFigure 6.17: Three plots, least squares line residual plot. data sets least one outlier.\nExamine residual plots Figures 6.16 6.17.\nprobably find trend main clouds  Plots C, D, E.\ncases, outliers influenced slope least squares lines.\n Plot E, data clear trend assigned line large trend simply due one outlier (!).Leverage.Points fall horizontally away center cloud tend pull harder line, call points high leverage.Points fall horizontally far line points high leverage; points can strongly influence slope least squares line.\none high leverage points appear actually invoke influence slope line – Plots C, D, E Figures 6.16 6.17 – call influential point.Influential point.point influential , fitted line without , influential point unusually far least squares line.\nInfluential points tend pull slope line seen fit regression line without .tempting remove outliers. Don’t without good reason.\nModels ignore exceptional (interesting) cases often perform poorly.\ninstance, financial firm ignored largest market swings – “outliers” – soon go bankrupt making poorly thought-investments.","code":""},{"path":"cor-reg.html","id":"chp6-review","chapter":"6 Correlation and regression","heading":"6.4 Chapter review","text":"","code":""},{"path":"cor-reg.html","id":"summary-4","chapter":"6 Correlation and regression","heading":"Summary","text":"Throughout chapter, nuances simple linear regression model described.\nlearned create regression model two quantitative variables.\nresiduals linear model important metric used understand well model fits; high leverage points, influential points, types outliers can impact fit model.\nCorrelation measure strength direction linear relationship two variables, without specifying variable explanatory outcome.\nFuture chapters focus generalizing linear model sample data claims population interest.","code":""},{"path":"cor-reg.html","id":"data-visualization-summary","chapter":"6 Correlation and regression","heading":"Data visualization summary","text":"Now looked summarize visualize one two variables either type (categorical quantitative), can organize visualization methods single decision tree.\nFigure 6.18 presents decision tree deciding type plot appropriate given number types variables. next chapter, ’ll look exploratory data analysis methods two variables.\nFigure 6.18: Decision tree determining appropriate plot given number variables types.\n","code":""},{"path":"cor-reg.html","id":"summary-measures","chapter":"6 Correlation and regression","heading":"Summary measures","text":"Though summary measures covered later chapters, Table 6.5 provides comprehensive summary measures according type(s) variable(s) summarize.\nTable 6.5: Summary measures different types variables covered textbook Sections appear. binary variable categorical variable two categories.\n","code":""},{"path":"cor-reg.html","id":"notation-summary","chapter":"6 Correlation and regression","heading":"Notation summary","text":"field statistics, summary measures summarize sample data called statistics. Numbers summarize entire population called parameters. can remember\ndistinction looking first letter term:Statistics summarize Samples.Parameters summarize Populations.typically use Roman letters symbolize statistics (e.g., \\(\\bar{x}\\), \\(\\hat{p}\\)), Greek letters symbolize parameters (e.g., \\(\\mu\\), \\(\\pi\\)).","code":""},{"path":"cor-reg.html","id":"terms-4","chapter":"6 Correlation and regression","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"cor-reg.html","id":"key-ideas-4","chapter":"6 Correlation and regression","heading":"Key ideas","text":"Two variables associated behavior one variable depends value variable. two quantitative variables, occurs trend apparent scatterplot. trend linear non-zero slope, say two quantitative variables correlated. Recall Chapter 1, association imply causation!Two variables associated behavior one variable depends value variable. two quantitative variables, occurs trend apparent scatterplot. trend linear non-zero slope, say two quantitative variables correlated. Recall Chapter 1, association imply causation!least squares regression line represents predicted value response variable, \\(y\\), given \\(x\\)-value. Since actual observed values response variable denoted \\(y\\), denote predicted values \\(\\hat{y}\\).least squares regression line represents predicted value response variable, \\(y\\), given \\(x\\)-value. Since actual observed values response variable denoted \\(y\\), denote predicted values \\(\\hat{y}\\).slope regression line predicted change response variable associated one-unit increase \\(x\\).slope regression line predicted change response variable associated one-unit increase \\(x\\).\\(y\\)-intercept regression line predicted value response variable \\(x = 0\\). collected data include \\(x\\)-values near zero, prediction example extrapolation — using regression line make predictions outside range observed data.\\(y\\)-intercept regression line predicted value response variable \\(x = 0\\). collected data include \\(x\\)-values near zero, prediction example extrapolation — using regression line make predictions outside range observed data.regression line provides predicted response value, may may close value actually observe. numerical measure “prediction error” residual = (observed \\(y\\)-value) \\(-\\) (predicted \\(\\hat{y}\\)-value); , distance observed \\(y\\)-value regression line. Positive residuals indicate observed \\(y\\)-value regression line (regression model underestimated response); negative residuals indicate observed \\(y\\)-value regression line (regression model overestimated response).regression line provides predicted response value, may may close value actually observe. numerical measure “prediction error” residual = (observed \\(y\\)-value) \\(-\\) (predicted \\(\\hat{y}\\)-value); , distance observed \\(y\\)-value regression line. Positive residuals indicate observed \\(y\\)-value regression line (regression model underestimated response); negative residuals indicate observed \\(y\\)-value regression line (regression model overestimated response).correlation coefficient (just “correlation”) two quantitative variables, denoted \\(r\\) \\(R\\), number \\(-1\\) \\(1\\) measures strength (magnitude) direction (sign) linear relationship two variables. Correlation useful two quantitative variables linearly associated.correlation coefficient (just “correlation”) two quantitative variables, denoted \\(r\\) \\(R\\), number \\(-1\\) \\(1\\) measures strength (magnitude) direction (sign) linear relationship two variables. Correlation useful two quantitative variables linearly associated.coefficient determination, R-squared number \\(0\\) \\(1\\) measures proportion variation response variable can explained knowing \\(x\\)-value. can computed squaring correlation coefficient (\\(r^2\\)), using sample variances:\n\\[\nR^2 = \\frac{s^2_{y}-s^2_{RES}}{s^2_{y}},\n\\]\n\\(s^2_{y}\\) sample variance observed \\(y\\)-values, \\(s^2_{RES}\\) sample variance residuals.coefficient determination, R-squared number \\(0\\) \\(1\\) measures proportion variation response variable can explained knowing \\(x\\)-value. can computed squaring correlation coefficient (\\(r^2\\)), using sample variances:\n\\[\nR^2 = \\frac{s^2_{y}-s^2_{RES}}{s^2_{y}},\n\\]\n\\(s^2_{y}\\) sample variance observed \\(y\\)-values, \\(s^2_{RES}\\) sample variance residuals.outlier point follow general pattern data. influential point outlier tends pull slope line (correlation) seen fit regression line without . observation \\(x\\)-value far away center observed \\(x\\)-values said high leverage, potential influential point.outlier point follow general pattern data. influential point outlier tends pull slope line (correlation) seen fit regression line without . observation \\(x\\)-value far away center observed \\(x\\)-values said high leverage, potential influential point.","code":""},{"path":"mult-reg.html","id":"mult-reg","chapter":"7 Multivariable models","heading":"7 Multivariable models","text":"principles simple linear regression lay foundation sophisticated regression models used wide range challenging settings.\nchapter, explore idea “multivariable thinking” – investigating multiple variables interact response variable – examples.\nMultiple regression, introduces possibility one predictor linear model, logistic regression, technique predicting categorical outcomes two levels, presented special topics covered course.","code":""},{"path":"mult-reg.html","id":"gapminder-world","chapter":"7 Multivariable models","heading":"7.1 Gapminder world","text":"Gapminder “fact tank” uses publicly available world data produce data visualizations teaching resources global development. use excerpt data explore relationships among world health metrics across countries regions years 1952 2007.gapminder data can found gapminder package.First, let’s look relationship Gross Domestic Product (GDP) per capita (measure wealth country) Life Expectancy (years) year 2007 Figure 7.1.\nFigure 7.1: Scatterplot displaying relationship Life Expectancy GDP per capita year 2007. Note GDP per capita plotted log scale. dot represent?63\n\nFigure 7.2: Scatterplot displaying relationship Life Expectancy GDP per capita region year 2007. Note GDP per capita plotted log scale. Regression lines continent added.\nrelationship GDP per capita life expectancy differ across regions world?Yes. Looking Figure 7.2, five regression lines differing slopes, telling us estimated change life expectancy given increase GDP per capita differs across countries. Americas Oceania, life expectancy seems rise faster GDP per capita three regions. case, say GDP per capita interacts continent relationship life expectancy.Interaction two explanatory variables.relationship explanatory variable \\(x\\) response variable \\(y\\) changes different levels another variable \\(z\\), say \\(x\\) \\(z\\) interact relationship \\(y\\).\\(x\\) \\(y\\) quantitative, \\(z\\) categorical, Figure 7.2 – \\(x\\) = GDP per capita, \\(y\\) = life expectancy, \\(z\\) = continent – different regression lines level \\(z\\) parallel slopes, say \\(x\\) \\(z\\) interact. slopes parallel, interaction exists \\(x\\) \\(z\\).far, ’ve explored relationships three variables, visualize relationships five variables?64Let’s add another variable plot – population. aesthetic visual property objects plot. variable mapped aesthetic. possible aesthetics whether used quantitative categorical variables listed Table 7.1.\nTable 7.1: Examples aesthetics types variables mapped aesthetics.\nFigure 7.3, quantitative variables GDP per capita, life expectancy, population mapped aesthetics: position \\(x\\)-axis, position \\(y\\)-axis, population, respectively. categorical variable Region mapped color. Explore individual countries hovering points.\nFigure 7.3: Scatterplot displaying relationship four variables year 2007: GDP per capita (x-axis), Life Expectancy (y-axis), Population (size), Region (color).]\npattern compare happening 1952 (see Figure 7.4)?\nFigure 7.4: Scatterplot displaying relationship four variables year 1952: GDP per capita (x-axis), Life Expectancy (y-axis), Population (size), Region (color).\ncan visualize relationships among four variables plots (three quantitative variables x- y-axes size, categorical variable color). even add fifth variable using another aesthetic, like using shape represent popular religion country. visualize happens across time? Hans Rosling answer dynamic visualization. Click image watch.","code":""},{"path":"mult-reg.html","id":"simpsons-paradox-revisited","chapter":"7 Multivariable models","heading":"7.2 Simpson’s paradox, revisited","text":"Simpson’s Paradox introduced Section 4.4 example race capital punishment. example, three variables interest categorical. section, present another example paradox using three quantitative variables.1993, respected political essayist George , wrote following criticism spending public education United States.“10 states lowest per pupil spending included four – North Dakota, South Dakota, Tennessee, Utah – among 10 states top SAT scores. one 10 states highest per pupil expenditures – Wisconsin – among 10 states highest SAT scores. New Jersey highest per pupil expenditures, astonishing $10,561, teachers’ unions elsewhere try use negotiating benchmark. New Jersey’s rank regarding SAT scores? Thirty-ninth… fact quality schools… [fails correlate] education appropriations effect teacher unions’ insistence money crucial variable.”— George F. , September 12, 1993, “Meaningless Money Factor,” Washington Post, C7.George based claim state expenditures, average SAT scores, education-based variables. data data set SAT65, first six rows displayed Table 7.2. Variables data set described Table 7.3\nTable 7.2: Six rows SAT data set.\n\nTable 7.3: Variables descriptions SAT data set.\nMr. claims expenditure per pupil negative correlation average SAT scores across states. true? Indeed, correlation expend sat equal \\(r\\) = -0.381, relationship two variables shown Figure 7.5. Hover point view data particular State.\nFigure 7.5: Expenditure per pupil average daily attendance public elementary secondary schools ($1000) verses average SAT score 50 states plus District Columbia school year 1994-1995.\nmay seem surprising, remember – observational data. conclude, George , decreasing expenditures increase SAT scores. fact, one clear confounding variable data: percentage eligible students taking SAT.confounding variables may present study? determine whether variable confounding relationship school expenditures SAT scores?states time data collected, common take ACT SAT. students states, wanted go state school, need take ACT. However, wanted attend college another state, might take SAT. Thus, percent students taking SAT state, frac, confounding variable.order frac confounding, needs associated explanatory variable, expend, well response variable, sat. One look scatterplots correlation frac expend, frac sat, determine frac confounding relationship expend sat.Scatterplots expend versus frac sat versus frac displayed Figure 7.6. correlation expend frac 0.593, correlation sat frac -0.887.\nFigure 7.6: Expenditure per pupil average daily attendance public elementary secondary schools ($1000) average SAT score plotted percent students taking SAT 50 states plus District Columbia school year 1994-1995.\nNow ’ve determined frac confounding variable, let’s examine modifies relationship expend sat. Since hard visualize three quantitative variables – 3-D scatterplots difficult visualize – let’s bin variable frac three groups. States fewer 15% eligible students taking SAT classified low percentage. States 15% - 55% eligible students taking SAT classified medium states 55% eligible students taking SAT called high. Next, fit separate regression lines group. model shown Figure 7.7.\nFigure 7.7: Average SAT score plotted school expenditures per pupil, categorized Low (\\(<\\) 15%), Medium (15-55%), High (\\(>\\) 55%) percent students taking SAT.\nFigure 7.7 demonstrates overall negative correlation SAT scores expenditures disappears, even turns slightly positive, examine relationship within states similar fractions students taking SAT.data exhibit Simpson’s Paradox?66","code":""},{"path":"mult-reg.html","id":"regression-multiple-predictors","chapter":"7 Multivariable models","heading":"7.3 Multiple regression (special topic)","text":"principles simple linear regression lay foundation sophisticated regression models used wide range challenging settings.\nsection, explore multiple regression, introduces possibility one predictor linear model.Multiple regression extends simple two-variable regression case still one response many predictors (denoted \\(x_1\\), \\(x_2\\), \\(x_3\\), ...). method motivated scenarios many variables may simultaneously connected output.consider data loans peer--peer lender, Lending Club, data set first encountered Chapter 1.\nloan data includes terms loan well information borrower.\noutcome variable like better understand interest rate assigned loan.\ninstance, characteristics held constant, matter much debt someone already ? matter income verified?\nMultiple regression help us answer questions.data set includes results 10,000 loans, ’ll looking subset available variables, new saw earlier chapters.\nfirst six observations data set shown Table 7.4, descriptions variable shown Table 7.5.\nNotice past bankruptcy variable (bankruptcy) indicator variable, takes value 1 borrower past bankruptcy record 0 .\nUsing indicator variable place category name allows variables \ndirectly used regression.\nTwo variables categorical (verified_income issue_month), can take one different non-numerical values; ’ll discuss handled model Section 7.3.1.data can found openintro package: loans_full_schema. Based data dataset created new variables: credit_util calculated total credit utilized divided total credit limit bankruptcy turns number bankruptcies indicator variable (0 bankrupties 1 least 1 bankruptcies). refer modified dataset loans.\nTable 7.4: First six rows loans_full_schema data set.\n\nTable 7.5: Variables descriptions loans data set.\n","code":""},{"path":"mult-reg.html","id":"ind-and-cat-predictors","chapter":"7 Multivariable models","heading":"7.3.1 Indicator and categorical predictors","text":"Let’s start fitting linear regression model interest rate single predictor indicating whether person bankruptcy record:\\[\\widehat{\\texttt{interest_rate}} = 12.33 + 0.74 \\times bankruptcy\\]Results model shown Table 7.6.\nTable 7.6: Summary linear model predicting interest rate based whether borrower bankruptcy record. Degrees freedom model 9998.\nInterpret coefficient past bankruptcy variable model. coefficient significantly different 0?variable takes one two values: 1 borrower bankruptcy history 0 otherwise. slope 0.74 means model predicts 0.74%\nhigher interest rate borrowers bankruptcy \nrecord.\n(See Section 6.2.6 review interpretation two-level categorical predictor variables.)\nExamining regression output Table 7.6, can see p-value close zero, indicating strong evidence coefficient different zero using simple one-predictor model.Suppose fit model using 3-level categorical variable, verified_income.\noutput software shown Table 7.7.\nregression output provides multiple rows variable.\nrow represents relative difference level verified_income.\nHowever, missing one levels: Verified.\nmissing level called reference level represents default level levels measured .\nTable 7.7: Summary linear model predicting interest rate based whether borrower’s income source amount verified. predictor three levels, results 2 rows regression output.\nwrite equation regression model?equation regression model may written model two predictors:\\[\n\\begin{align*}\n\\widehat{\\texttt{interest_rate}} &= 11.10 + 1.42 \\times \\text{verified_income}_{\\text{Source Verified}}\\\\\n&\\qquad\\ + 3.25 \\times \\text{verified_income}_{\\text{Verified}}\n\\end{align*}\n\\]use notation \\(\\text{variable}_{\\text{level}}\\) represent indicator variables categorical variable takes particular value.\nexample, \\(\\text{verified_income}_{\\text{Source Verified}}\\) take value 1 \nloan, take value 0 otherwise.\nLikewise, \\(\\text{verified_income}_{\\text{Verified}}\\) take value 1 took \nvalue verified 0 took value.notation \\(\\text{variable}_{\\text{level}}\\) may feel bit confusing.\nLet’s figure use equation level verified_income variable.Using model predicting interest rate income verification type, compute average interest rate borrowers whose income source amount unverified.verified_income takes value Verified, indicator functions equation linear model set 0:\\[\\begin{align*}\n\\widehat{\\texttt{interest_rate}} &= 1.10 + 1.42 \\times 0 \\\\\n&\\qquad\\ + 3.25 \\times 0 \\\\\n&= 11.10\n\\end{align*}\\]average interest rate borrowers 11.1%.\nlevel coefficient reference value, indicators levels variable drop .Using model predicting interest rate income verification type, compute average interest rate borrowers whose income source amount unverified.verified_income takes value Source Verified, corresponding variable takes value 1 (\\(\\text{verified_income}_{\\text{Verified}}\\)) 0:\\[\\widehat{\\texttt{interest_rate}} = 11.10 + 1.42 \\times 1 + 3.25 \\times 0 = 12.52\\]average interest rate borrowers 12.52%.Compute average interest rate borrowers whose income source amount verified.67Predictors several categories.fitting regression model categorical variable \\(k\\) levels \\(k > 2\\), software provide coefficient \\(k - 1\\) levels.\nlast level receive coefficient, , coefficients listed levels considered relative reference level.Interpret coefficients model.68The higher interest rate borrowers verified income source amount surprising.\nIntuitively, ’d think loan look less risky borrower’s income verified.\nHowever, note situation may complex, may confounding variables didn’t account .\nexample, perhaps lender require borrowers poor credit verify income.\n, verifying income data set might signal concerns borrower rather reassurance borrower pay back loan.\nreason, borrower deemed higher risk, resulting higher interest rate.\n(confounding variables might explain counter-intuitive relationship suggested model?)much larger interest rate expect borrower verified income source amount vs borrower whose income source verified?69","code":""},{"path":"mult-reg.html","id":"many-predictors-in-a-model","chapter":"7 Multivariable models","heading":"7.3.2 Many predictors in a model","text":"world complex, can helpful consider many factors statistical modeling.\nexample, might like use full context borrower predict interest rate receive rather using single variable.\nstrategy used multiple regression.\nremain cautious making causal interpretations using multiple regression observational data, models common first step gaining insights providing evidence causal connection.want fit model accounts past bankruptcy whether borrower income source amount verified, simultaneously accounts variables loans data set: verified_income, debt_to_income, credit_util, bankruptcy, term, issue_month, credit_checks.\\[\\begin{align*}\n\\widehat{\\texttt{interest_rate}}\n    &= b_0 +\n        b_1\\times \\texttt{verified_income}_{\\texttt{Source Verified}} \\\\\n    &\\qquad\\  +\n        b_2\\times \\texttt{verified_income}_{\\texttt{Verified}} \\\\\n    &\\qquad\\  +\n        b_3\\times \\texttt{debt_to_income} \\\\\n    &\\qquad\\  +\n        b_4 \\times \\texttt{credit_util} \\\\\n    &\\qquad\\  +\n        b_5 \\times \\texttt{bankruptcy} \\\\\n    &\\qquad\\  +\n        b_6 \\times \\texttt{term} \\\\\n    &\\qquad\\  +\n        b_7 \\times \\texttt{issue_month}_{\\texttt{Jan-2018}} \\\\\n    &\\qquad\\ +\n        b_8 \\times \\texttt{issue_month}_{\\texttt{Mar-2018}} \\\\\n    &\\qquad\\  +\n        b_9 \\times \\texttt{credit_checks}\n\\end{align*}\\]equation represents holistic approach modeling variables simultaneously.\nNotice two coefficients verified_income also two coefficients issue_month, since 3-level categorical variables.estimate coefficients way case single predictor—select \\(b_0\\), \\(b_1\\), \\(b_2\\), \\(\\cdots\\), \\(b_9\\) minimize sum squared residuals:\\[SSE = e_1^2 + e_2^2 + \\dots + e_{10000}^2 = \\sum_{=1}^{10000} e_i^2 = \\sum_{=1}^{10000} \\left(y_i - \\hat{y}_i\\right)^2\\]\\(y_i\\) \\(\\hat{y}_i\\) represent observed interest rates estimated values according model, respectively.\n10,000 residuals calculated, one observation.\ntypically use computer minimize sum squares compute point estimates, shown sample output \nTable 7.8.\nUsing output, identify point estimates \\(b_i\\) just one-predictor case.\nTable 7.8: Output regression model, interest rate outcome variables listed predictors. Degrees freedom model 9990.\nMultiple regression model.multiple regression model linear model many predictors. general,\nwrite fitted model \\[\\hat{y} = b_0 + b_1 x_1 + b_2 x_2 + \\cdots + b_k x_k\\]\\(k\\) predictor variables. coefficient estimates, \\(b_0,\\ldots, b_k\\),\neasily found using statistical software.Write regression model using point estimates Table 7.8.\nmany predictors model?fitted model interest rate given :\\[\\begin{align*}\n\\widehat{\\texttt{interest_rate}}\n    &= 1.925 +\n        0.975 \\times \\texttt{verified_income}_{\\texttt{Source Verified}} \\\\\n    &\\qquad\\  +\n        2.537 \\times \\texttt{verified_income}_{\\texttt{Verified}} \\\\\n    &\\qquad\\  +\n        0.021 \\times \\texttt{debt_to_income} \\\\\n    &\\qquad\\  +\n        4.896 \\times \\texttt{credit_util} \\\\\n    &\\qquad\\  +\n        0.386 \\times \\texttt{bankruptcy} \\\\\n    &\\qquad\\  +\n        0.154 \\times \\texttt{term} \\\\\n    &\\qquad\\  +\n        0.028 \\times \\texttt{issue_month}_{\\texttt{Jan-2018}} \\\\\n    &\\qquad\\  -\n        0.040 \\times \\texttt{issue_month}_{\\texttt{Mar-2018}} \\\\\n    &\\qquad\\  +\n        0.228 \\times \\texttt{credit_checks}\n\\end{align*}\\]count number predictor coefficients, get effective number predictors model: \\(k = 9\\).\nNotice categorical predictor counts two, two levels shown model.\ngeneral, categorical predictor \\(p\\) different levels represented \\(p - 1\\) terms multiple regression model.\\(b_4\\), estimated coefficient variable credit_util, represent?\nvalue?70Compute residual first observation Table 7.4 page using full model.71We estimated coefficient Section 7.3.1 \\(b_4 = 0.74\\) standard error \\(SE_{b_1} = 0.15\\) using simple linear regression.\ndifference estimate estimated coefficient 0.39 multiple regression setting?examined data carefully, see predictors correlated.\ninstance, estimated connection outcome interest_rate predictor bankruptcy using simple linear regression, unable control variables like whether borrower income verified, borrower’s debt--income ratio, variables.\noriginal model constructed vacuum consider full context.\ninclude variables, underlying unintentional bias missed variables reduced eliminated.\ncourse, bias can still exist confounding variables.previous example describes common issue multiple regression: correlation among predictor variables.\nsay two predictor variables (pronounced co-linear) correlated, collinearity complicates model estimation.\nimpossible prevent collinearity arising observational data, experiments usually designed prevent predictors collinear.estimated value intercept 1.925, one might tempted make interpretation coefficient, , model’s predicted price variables take value zero: income source verified, borrower debt (debt--income credit utilization zero), .\nreasonable?\nvalue gained making interpretation?72","code":""},{"path":"mult-reg.html","id":"chp7-review","chapter":"7 Multivariable models","heading":"7.4 Chapter review","text":"","code":""},{"path":"mult-reg.html","id":"summary-5","chapter":"7 Multivariable models","heading":"Summary","text":"real data, often need describe visualize multiple variables can modeled together.\nchapter, presented one approach using multiple linear regression.\ncoefficient represents one unit increase predictor variable response variable given rest predictor variables model.\nWorking interpreting multivariable models can tricky, since relationship two variables may appear different overall look relationship within particular group.","code":""},{"path":"mult-reg.html","id":"terms-5","chapter":"7 Multivariable models","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"mult-reg.html","id":"key-ideas-5","chapter":"7 Multivariable models","heading":"Key ideas","text":"building data visualizations, map different variables different aesthetics. example, quantitative explanatory variable mapped position \\(x\\)-axis, quantitative response variable mapped position \\(y\\)-axis, categorical variable may mapped color shape plotting character.building data visualizations, map different variables different aesthetics. example, quantitative explanatory variable mapped position \\(x\\)-axis, quantitative response variable mapped position \\(y\\)-axis, categorical variable may mapped color shape plotting character.common three-variable situation one add categorical variable scatterplot, using colors /different point symbols. slope regression line differs across categories, say relationship association two quantitative variables differs across levels categorical variable. called interaction — two explanatory variables interact relationship response variable.common three-variable situation one add categorical variable scatterplot, using colors /different point symbols. slope regression line differs across categories, say relationship association two quantitative variables differs across levels categorical variable. called interaction — two explanatory variables interact relationship response variable.Simpson’s Paradox can occur three variables type (categorical quantitative). Simpson’s Paradox occurs overall association two variables interest reverses account third variable. example, overall, slope two quantitative variables \\(x\\) \\(y\\) may positive, look slope fitted subset data certain category third variable, slope negative.Simpson’s Paradox can occur three variables type (categorical quantitative). Simpson’s Paradox occurs overall association two variables interest reverses account third variable. example, overall, slope two quantitative variables \\(x\\) \\(y\\) may positive, look slope fitted subset data certain category third variable, slope negative.","code":""},{"path":"explore-applications.html","id":"explore-applications","chapter":"8 Applications: Explore","heading":"8 Applications: Explore","text":"TODO","code":""},{"path":"foundations-randomization.html","id":"foundations-randomization","chapter":"9 Hypothesis testing with randomization","heading":"9 Hypothesis testing with randomization","text":"Statistical inference primarily concerned understanding quantifying uncertainty parameter estimates—, variable sample statistic sample sample? equations details change depending setting, foundations inference throughout statistics.start two case studies designed motivate process making decisions research claims.\nformalize process introduction hypothesis testing framework, allows us formally evaluate claims population.Throughout book far, worked data variety contexts. learned summarize visualize data well visualize multiple variables time. Sometimes data set hand represents entire research question. often , data collected answer research question larger group data (hopefully) representative subset.may agree almost always variability data (one data set identical second data set even collected population using methods).\nHowever, quantifying variability data neither obvious easy , .e., answering question “different one data set another?” trivial.First, reminder notation.\ngenerally use \\(\\pi\\) denote population proportion \\(\\hat{p}\\) sample proportion.\nSimilarly, generally use \\(\\mu\\) denote population mean \\(\\bar{x}\\) denote sample mean.Suppose professor splits students class two groups: students sit left side classroom students sit right side classroom.\n\\(\\hat{p}_{L}\\) represents proportion students prefer read books screen sit left side classroom \\(\\hat{p}_{R}\\) represents proportion students prefer read books screen sit right side classroom, surprised \\(\\hat{p}_{L}\\) exactly equal \\(\\hat{p}_{R}\\)?proportions \\(\\hat{p}_{L}\\) \\(\\hat{p}_{R}\\) probably close , unusual exactly .\nprobably observe small difference due chance.think side room person sits class related whether prefer read books screen, assumption making relationship two variables?73Studying randomness form key focus statistics. Throughout chapter, follow, provide two different approaches quantifying variability inherent data: simulation-based methods theory-based methods (mathematical models). Using methods provided future chapters, able draw conclusions beyond data set hand research questions larger populations samples come .Given results seen sample, process determining can infer population based sample results called statistical inference. Statistical inferential methods enable us understand quantify uncertainty sample results. Statistical inference helps us answer two questions population:strong evidence effect?large effect?first question answered hypothesis test, second addressed confidence interval. chapter introduce foundations hypothesis testing, ideas behind confidence intervals presented next chapter.Statistical inference practice making decisions conclusions data context uncertainty. Errors occur, just like rare events, data set hand might lead us wrong conclusion. given data set may always lead us correct conclusion, statistical inference gives us tools control evaluate often errors occur.","code":""},{"path":"foundations-randomization.html","id":"Martian","chapter":"9 Hypothesis testing with randomization","heading":"9.1 Motivating example: Martian alphabet","text":"well can humans distinguish one “Martian” letter another? Figure 9.1 displays two Martian letters—one Kiki another Bumba. think Kiki think Bumba? Take moment write guess.\nFigure 9.1: Two Martian letters: Bumba Kiki. think letter Bumba left right?74\n","code":""},{"path":"foundations-randomization.html","id":"observed-data","chapter":"9 Hypothesis testing with randomization","heading":"9.1.1 Observed data","text":"image question Figure 9.1 presented introductory statistics class 38 students. class, 34 students correctly identified Bumba Martian letter left. , sample proportion \\(\\hat{p} = 34/38 = 0.90\\). Assuming can’t read Martian, result surprising?One two possibilities occurred:can’t read Martian, results just occurred chance.can read Martian, results reflect ability.decide two possibilities, calculate probability observing results randomly selected sample 38 students, assumption students just guessing. probability low, ’d reason reject first possibility favor second. can calculate probability using one two methods:Simulation-based method: simulate lots samples (classes) 38 students assumption students just guessing, calculate proportion simulated samples saw 34 students guessing correctly, orTheory-based method: develop mathematical model sample proportion scenario use model calculate probability.","code":""},{"path":"foundations-randomization.html","id":"variability-in-a-statistic","chapter":"9 Hypothesis testing with randomization","heading":"9.1.2 Variability in a statistic","text":"use coin cards simulate guesses one sample 38 students read Martian?75The observed data showed 34 students correctly identifying Bumba class 38 students, 90%. Now, suppose students truly “just guessing”, meaning student 50% chance guessing correctly. , conducted study different sample 38 students, expect half (19 students) guess correctly, half guess incorrectly. variation 19 based random fluctuation sample selection process. actually perform simulation happen randomly chose another 38 students “just guessing” flipping coin 38 times counting number times lands heads. Try —many correctly guessed Bumba simulated class 38 students? proportion guessed correctly?","code":""},{"path":"foundations-randomization.html","id":"observed-statistic-vs.-null-statistics","chapter":"9 Hypothesis testing with randomization","heading":"9.1.3 Observed statistic vs. null statistics","text":"flipping coin 38 times, computed one possible sample proportion students guessing correctly assumption “just guessing”.\nfirst simulation, physically flipped coin, much efficient perform simulation using computer.\nUsing computer repeat process 1,000 times, create dot plot simulated sample proportions shown Figure 9.2.\nFigure 9.2: dot plot 1,000 sample proportions; calculated flipping coin 38 times calculating proportion times coin landed heads. None 1,000 simulations sample proportion least 89%, proportion observed study.\nobserved statistic, \\(\\hat{p} = 0.90\\), represented Figure 9.2 \nred triangle.\nsimulated sample proportions plotted blue represent null statistics, since simulated assumption “just guessing” “nothing” “null”.\nNone simulated null statistics got even close observed statistic!\n, students just guessing, nearly impossible observe 34 students guessing correctly sample 38 students.\nGiven low probability, plausible possibility 2. can read Martian, results reflect ability. ’ve just completed first hypothesis test!Now, obviously one can read Martian, realistic possibility humans tend choose Bumba left often right—greater 50% chance choosing Bumba letter left. Even though may think ’re guessing just chance, preference Bumba left. turns explanation preference called synesthesia, tendency humans correlate sharp sounding noises (e.g., Kiki) sharp looking images.76","code":""},{"path":"foundations-randomization.html","id":"caseStudySexDiscrimination","chapter":"9 Hypothesis testing with randomization","heading":"9.2 Sex discrimination case study","text":"getting nuances hypothesis testing, let’s work another case study.\nconsider study investigating sex discrimination 1970s, set context personnel decisions within bank.\nresearch question hope answer , “individuals identify female discriminated promotion decisions made managers identify male?” (Rosen Jerdee 1974)sex_discrimination data can found openintro R package.study considered sex roles, allowed options “male” “female”.\nnote identities considered gender identities study allowed binary classification sex.","code":""},{"path":"foundations-randomization.html","id":"observed-data-1","chapter":"9 Hypothesis testing with randomization","heading":"9.2.1 Observed data","text":"participants study 48 bank supervisors identified male, attending management institute University North Carolina 1972.\nasked assume role personnel director bank given personnel file judge whether person promoted branch manager position.\nfiles given participants identical, except half indicated candidate identified male half indicated candidate identified female.\nfiles randomly assigned subjects.observational study experiment?\ntype study impact can inferred results?77For supervisor sex associated assigned file promotion decision recorded.\nUsing results study summarized Table 9.1, like evaluate individuals identify female unfairly discriminated promotion decisions.\nstudy, smaller proportion female identifying applications promoted males (0.583 versus 0.875), unclear whether difference provides convincing evidence individuals identify female unfairly discriminated .\nTable 9.1: Summary results sex discrimination study.\ndata visualized Figure 9.3 set cards.\nNote card denotes personnel file (observation data set) colors indicate decision: red promoted white promoted.\nAdditionally, observations broken groups male female identifying groups.\nFigure 9.3: sex discrimination study can thought 48 red white cards.\nStatisticians sometimes called upon evaluate strength evidence.\nlooking rates promotion study, might tempted immediately conclude individuals identifying female discriminated ?large difference promotion rates (58.3% female personnel versus 87.5% male personnel) suggest might discrimination women promotion decisions.\nHowever, yet sure observed difference represents discrimination just due random chance discrimination occurring.\nSince wouldn’t expect sample proportions exactly equal, even truth promotion decisions independent sex, can’t rule random chance possible explanation simply comparing sample proportions.previous example reminder observed outcomes sample may perfectly reflect true relationships variables underlying population.\nTable 9.1 shows 7 fewer promotions female identifying personnel male personnel, difference promotion rates 29.2% \\(\\left( \\frac{21}{24} - \\frac{14}{24} = 0.292 \\right).\\) observed difference call point estimate true difference.\npoint estimate difference promotion rate large, sample size study small, making unclear observed difference represents discrimination whether simply due chance discrimination occurring.\nChance can thought claim due natural variability; discrimination can thought claim researchers set demonstrate.\nlabel two competing claims, \\(H_0\\) \\(H_A:\\)\\(H_0:\\) Null hypothesis.\nvariables sex decision independent.\nrelationship, observed difference proportion males females promoted, 29.2%, due natural variability inherent population.\\(H_A:\\) Alternative hypothesis.\nvariables sex decision independent.\ndifference promotion rates 29.2% due natural variability, equally qualified female personnel less likely promoted male personnel.Hypothesis testing.hypotheses part called hypothesis test.\nhypothesis test statistical technique used evaluate competing claims using data.\nOften times, null hypothesis takes stance difference effect.\nhypothesis assumes differences seen due variability inherent population occurred random chance.null hypothesis data notably disagree, reject null hypothesis favor alternative hypothesis.many nuances hypothesis testing, worry aren’t master hypothesis testing end chapter.\n’ll discuss ideas details many times chapter well chapters follow.mean null hypothesis, says variables sex decision unrelated, true?\nmean banker decide whether promote candidate without regard sex indicated personnel file.\n, difference promotion percentages due natural variability files randomly allocated different bankers, randomization just happened give rise relatively large difference 29.2%.Consider alternative hypothesis: bankers influenced sex listed personnel file.\ntrue, especially influence substantial, expect see difference promotion rates male female candidates.\nsex bias female candidates, expect smaller fraction promotion recommendations female personnel relative male personnel.choose two competing claims assessing data conflict much \\(H_0\\) null hypothesis deemed reasonable.\ndata null claim seem odds one another, data seem support \\(H_A,\\) reject notion independence conclude data provide evidence discrimination.","code":""},{"path":"foundations-randomization.html","id":"variability-of-the-statistic","chapter":"9 Hypothesis testing with randomization","heading":"9.2.2 Variability of the statistic","text":"Table 9.1 shows 35 bank supervisors recommended promotion 13 .\nNow, suppose bankers’ decisions independent sex candidate.\n, conducted experiment different random assignment sex files, differences promotion rates based random fluctuation promotion decisions.\ncan actually perform randomization, simulates happened bankers’ decisions independent sex distributed file sexes differently.78In simulation, thoroughly shuffle 48 personnel files, 35 labelled promoted 13 labelled promoted, together deal files two new stacks.\nNote keeping 35 promoted 13 promoted, assuming 35 bank managers promoted individual whose content contained file independent sex indicated file.\ndeal 24 files first stack, represent 24 “female” files.\nsecond stack also 24 files, represent 24 “male” files.\nFigure 9.4 highlights shuffle reallocation sham sex groups.\nFigure 9.4: sex discrimination data shuffled reallocated new groups male female files.\n, original data, tabulate results determine fraction personnel files designated “male” “female” promoted.Since randomization files simulation independent promotion decisions, difference promotion rates due chance.\nTable 9.2 show results one simulation.\nTable 9.2: Simulation results, difference promotion rates male female purely due random chance.\ndifference promotion rates two simulated groups Table 9.2 ?\ncompare observed difference 29.2% actual study?79Figure 9.5 shows difference promotion rates much larger original data simulated groups (0.292 > 0.042).\nquantity interest throughout case study difference promotion rates.\ncall summary value observed statistic interest (often test statistic).\nencounter different data structures, type statistic likely change (e.g., might calculate average instead proportion), always want understand statistic varies sample sample.\nFigure 9.5: summarize randomized data produce one estimate difference proportions given sex discrimination. Note sort step used make easier visually calculate simulated sample proportions.\n","code":""},{"path":"foundations-randomization.html","id":"observed-statistic-vs.-null-statistics-1","chapter":"9 Hypothesis testing with randomization","heading":"9.2.3 Observed statistic vs. null statistics","text":"computed one possible difference null hypothesis Guided Practice, represents one difference due chance null hypothesis assumed true.\nfirst simulation, physically dealt files, much efficient perform simulation using computer.\nRepeating simulation computer, get another difference due chance assumption: -0.042.\nanother: 0.208.\nrepeat simulation enough times good idea shape distribution differences null hypothesis.\nFigure 9.6 shows plot differences found 100 simulations, dot represents simulated difference proportions male female files recommended promotion.\nFigure 9.6: stacked dot plot differences 100 simulations produced null hypothesis, \\(H_0,\\) simulated sex decision independent. Two 100 simulations difference least 29.2%, difference observed study, shown solid blue dots.\nNote distribution simulated differences proportions centered around 0.\nnull hypothesis simulations made distinction male female personnel files.\nThus, center 0 makes sense: expect differences chance alone fall around zero random fluctuation simulation.often observe difference least 29.2% (0.292) according Figure 9.6?\nOften, sometimes, rarely, never?appears difference least 29.2% null hypothesis happen 2% time according Figure 9.6.\nlow probability indicates observing large difference chance alone rare.difference 29.2% rare event really impact listing sex candidates’ files, provides us two possible interpretations study results:\\(H_0,\\) Null hypothesis true: Sex effect promotion decision, observed difference large happen rarely.\\(H_0,\\) Null hypothesis true: Sex effect promotion decision, observed difference large happen rarely.\\(H_A,\\) Alternative hypothesis true: Sex effect promotion decision, observed actually due equally qualified female candidates discriminated promotion decisions, explains large difference 29.2%.\\(H_A,\\) Alternative hypothesis true: Sex effect promotion decision, observed actually due equally qualified female candidates discriminated promotion decisions, explains large difference 29.2%.conduct formal studies, reject null position (idea data result chance ) data strongly conflict null position.80\nanalysis, determined \\(\\approx\\) 2% probability obtaining sample \\(\\geq\\) 29.2% male candidates female candidates get promoted null hypothesis, conclude data provide strong evidence sex discrimination female candidates male supervisors.\ncase, reject null hypothesis favor alternative.","code":""},{"path":"foundations-randomization.html","id":"HypothesisTesting","chapter":"9 Hypothesis testing with randomization","heading":"9.3 Hypothesis testing","text":"last two sections, utilized hypothesis test, formal technique evaluating two competing possibilities.\nscenario, described null hypothesis, represented either skeptical perspective perspective difference.\nalso laid alternative hypothesis, represented new perspective possibility relationship two variables treatment effect experiment.\nalternative hypothesis usually reason scientists set research first place.Null alternative hypotheses.observe effect sample, like determine observed effect represents actual effect population, whether simply due chance. label two competing claims, \\(H_0\\) \\(H_A\\), spoken “H-naught” “H_A”.null hypothesis (\\(H_0\\)) often represents either skeptical perspective claim tested.alternative hypothesis (\\(H_A\\)) represents alternative claim consideration often represented range possible values parameter interest.Martian alphabet example, two competing possibilities null hypothesis? alternative hypothesis?81The hypothesis testing framework general tool, often use without second thought. person makes somewhat unbelievable claim, initially skeptical. However, sufficient evidence supports claim, set aside skepticism. hallmarks hypothesis testing also found US court system.","code":""},{"path":"foundations-randomization.html","id":"the-us-court-system","chapter":"9 Hypothesis testing with randomization","heading":"The US court system","text":"US course system, jurors evaluate evidence see whether convincingly shows defendant guilty.\nDefendants considered innocent proven otherwise.US court considers two possible claims defendant: either innocent guilty.set claims hypothesis framework, null hypothesis alternative?jury considers whether evidence convincing (strong) reasonable doubt regarding person’s guilt.\n, skeptical perspective (null hypothesis) person innocent evidence presented convinces jury person guilty (alternative hypothesis).Jurors examine evidence see whether convincingly shows defendant guilty.\nNotice jury finds defendant guilty, necessarily mean jury confident person’s innocence.\nsimply convinced alternative, person guilty.\nalso case hypothesis testing: even fail reject null hypothesis, accept null hypothesis truth.Failing find evidence favor alternative hypothesis equivalent finding evidence null hypothesis true82.\nsee idea greater detail Section ??.","code":""},{"path":"foundations-randomization.html","id":"p-value-and-statistical-significance","chapter":"9 Hypothesis testing with randomization","heading":"p-value and statistical significance","text":"Martian alphabet example, research question—can humans read Martian?—framed context hypotheses:\\(H_0\\): chance human chooses Bumba left 50%.\\(H_0\\): chance human chooses Bumba left 50%.\\(H_A\\): Humans preference choosing Bumba left.\\(H_A\\): Humans preference choosing Bumba left.null hypothesis (\\(H_0\\)) perspective effect (ability read Martian). student data provided point estimate 89.5% (\\(34/38 \\times 100\\)%) true probability choosing Bumba left. determined observing sample proportion chance alone (assuming \\(H_0\\)) rare—happen less 1 1000 samples. results like inconsistent \\(H_0\\), reject \\(H_0\\) favor \\(H_A\\). , concluded humans preference choosing Bumba left.less 1--1000 chance call p-value, probability quantifying strength evidence null hypothesis favor alternative.p-value.p-value probability observing data least favorable alternative hypothesis current data set, null hypothesis true. typically use summary statistic data, proportion difference proportions, help compute p-value evaluate hypotheses. summary value used compute p-value often called test statistic.interpreting p-value, remember definition p-value three components. (1) probability. probability ? probability (2) observed sample statistic one extreme. Assuming ? probability observed sample statistic one extreme, (3) assuming null hypothesis true:probabilitydata83null hypothesisWhat test statistic Martian alphabet example?test statistic Martian alphabet example sample proportion, \\(\\frac{34}{38} = 0.895\\) (89.5%). also point estimate true probability humans choose Bumba left.Since p-value probability, value always 0 1. closer p-value 0, stronger evidence null hypothesis. ? small p-value means data unlikely occur, null hypothesis true. take mean null hypothesis isn’t plausible assumption, reject . process mimics scientific method—easier disprove theory prove . scientists want find evidence new drug reduces risk stroke, assume doesn’t reduce risk stroke show observed data unlikely occur plausible explanation drug works.Think p-values continuum strength evidence null, 0 (extremely strong evidence) 1 (evidence). Beyond around 10%, data provide evidence null hypothesis. careful equate evidence null hypothesis, incorrect.\nFigure 9.7: Strength evidence null continuum p-values. p-value beyond around 0.10, data provide evidence null hypothesis.\np-value small, .e., less previously set threshold, say results statistically significant.\nmeans data provide strong evidence \\(H_0\\) reject null hypothesis favor alternative hypothesis.\nthreshold called significance level often represented \\(\\alpha\\) (Greek letter alpha).\nvalue \\(\\alpha\\) represents rare event needs order null hypothesis rejected.\nHistorically, many fields set \\(\\alpha = 0.05,\\) meaning results need occur less 5% time, null hypothesis rejected.\nvalue \\(\\alpha\\) can vary depending field application.Although everyday language “significant” indicate difference large meaningful, necessarily case .\nterm “statistically significant” indicates p-value study fell chosen significance level.\nexample, sex discrimination study, p-value found approximately 0.02.\nUsing significance level \\(\\alpha = 0.05,\\) say data provided statistically significant evidence null hypothesis.\nHowever, conclusion gives us information regarding size difference promotion rates!Statistical significance.say data provide statistically significant evidence null hypothesis p-value less predetermined threshold (e.g., 0.01, 0.05, 0.1).’s special 0.05?often use threshold 0.05 determine whether result statistically significant. 0.05? Maybe use bigger number, maybe smaller number. ’re little puzzled, probably means ’re reading critical eye—good job! OpenIntro authors video help clarify 0.05: Sometimes ’s also good idea deviate standard. ’ll discuss choose threshold different 0.05 Section ??.Statistical significance hot topic news, related “reproducibility crisis” scientific fields. encourage read debate use p-values statistical significance. good place start Nature article, “Scientists rise statistical significance,” March 20, 2019.","code":""},{"path":"foundations-randomization.html","id":"chp9-review","chapter":"9 Hypothesis testing with randomization","heading":"9.4 Chapter review","text":"","code":""},{"path":"foundations-randomization.html","id":"summary-6","chapter":"9 Hypothesis testing with randomization","heading":"Summary","text":"Regardless data structure analysis method, hypothesis testing framework always follows steps—details model randomness data change.General steps hypothesis test. Every hypothesis test follows general steps:Frame research question terms hypotheses.Collect summarize data using test statistic.Assume null hypothesis true, simulate mathematically model null distribution test statistic.Compare observed test statistic null distribution calculate p-value.Make conclusion based p-value, write conclusion context, plain language, terms alternative hypothesis.Add summary","code":""},{"path":"foundations-randomization.html","id":"terms-6","chapter":"9 Hypothesis testing with randomization","heading":"Terms","text":"introduced following terms chapter. ’re sure terms mean, recommend go back text review definitions. purposefully presenting alphabetical order, instead order appearance, little challenging locate. However able easily spot bolded text.","code":""},{"path":"foundations-randomization.html","id":"key-ideas-6","chapter":"9 Hypothesis testing with randomization","heading":"Key ideas","text":"Need update list distribute across chaptersIn chapter, introduced statistical inference methods — simulation-based theory-based — scenarios involving one two categorical variables.statistical inference revolves around idea sampling variability: take different samples population, value sample statistic vary. chapter, explored sampling variability single proportion difference two proportions. see sort effect sample, just due chance? indicative actual effect population? Statistical inference answer question.statistical inference revolves around idea sampling variability: take different samples population, value sample statistic vary. chapter, explored sampling variability single proportion difference two proportions. see sort effect sample, just due chance? indicative actual effect population? Statistical inference answer question.hypothesis test answers question “strong evidence effect?” confidence interval answers question “large effect?”hypothesis test answers question “strong evidence effect?” confidence interval answers question “large effect?”general steps hypothesis test :\nFrame research question terms hypotheses.\nCollect summarize data using test statistic.\nAssume null hypothesis true, simulate mathematically model null distribution test statistic.\nCompare observed test statistic null distribution calculate p-value.\nMake conclusion based p-value, write conclusion context, plain language, terms alternative hypothesis.\ngeneral steps hypothesis test :Frame research question terms hypotheses.Collect summarize data using test statistic.Assume null hypothesis true, simulate mathematically model null distribution test statistic.Compare observed test statistic null distribution calculate p-value.Make conclusion based p-value, write conclusion context, plain language, terms alternative hypothesis.p-value probability observing data like , data extreme effect, assumption null hypothesis. define “extreme” depends direction alternative hypothesis. p-value answer question “null hypothesis true, chances observing data like mine?”\nsmall p-value indicates observed data unusual null hypothesis true, thus evidence null hypothesis.\np-value small indicates observed data plausible assumption null hypothesis, thus evidence null hypothesis.\np-value probability observing data like , data extreme effect, assumption null hypothesis. define “extreme” depends direction alternative hypothesis. p-value answer question “null hypothesis true, chances observing data like mine?”small p-value indicates observed data unusual null hypothesis true, thus evidence null hypothesis.p-value small indicates observed data plausible assumption null hypothesis, thus evidence null hypothesis.Since decisions hypothesis testing based probabilities (.e., p-values), ’s possible make wrong decision. Type 1 error occurs reject true null hypothesis. fail reject false null hypothesis, committed Type 2 error.Since decisions hypothesis testing based probabilities (.e., p-values), ’s possible make wrong decision. Type 1 error occurs reject true null hypothesis. fail reject false null hypothesis, committed Type 2 error.power hypothesis test probability rejecting null hypothesis, varies depending true value parameter. Power typically increases sample size increases. Thus, small samples may show effect sample practically important — may matter real life — test high enough power reject null hypothesis, statistically significant. hand, large samples may show effect sample isn’t meaningful, practically important, statistically significant due high power.power hypothesis test probability rejecting null hypothesis, varies depending true value parameter. Power typically increases sample size increases. Thus, small samples may show effect sample practically important — may matter real life — test high enough power reject null hypothesis, statistically significant. hand, large samples may show effect sample isn’t meaningful, practically important, statistically significant due high power.simulation-based confidence interval takes percentiles bootstrap distribution sample statistics endpoints. example, 95% confidence interval interval 2.5th percentile 97.5th percentile — percentiles capture middle 95% bootstrap distribution.simulation-based confidence interval takes percentiles bootstrap distribution sample statistics endpoints. example, 95% confidence interval interval 2.5th percentile 97.5th percentile — percentiles capture middle 95% bootstrap distribution.theory-based confidence interval always form: statistic \\(\\pi\\) (multiplier) \\(\\times\\) (standard error statistic). amount add subtract statistic ((multiplier) \\(\\times\\) (standard error statistic)) called margin error. mathematical model sampling variability sample proportion difference sample proportions normal distribution, due Central Limit Theorem.theory-based confidence interval always form: statistic \\(\\pi\\) (multiplier) \\(\\times\\) (standard error statistic). amount add subtract statistic ((multiplier) \\(\\times\\) (standard error statistic)) called margin error. mathematical model sampling variability sample proportion difference sample proportions normal distribution, due Central Limit Theorem.statistical inference methods require certain validity conditions met; otherwise, methods valid. methods textbook require observations data set independent. Additionally, theory-based methods require large enough sample size Central Limit Theorem can apply. proportions, condition known success-failure condition.statistical inference methods require certain validity conditions met; otherwise, methods valid. methods textbook require observations data set independent. Additionally, theory-based methods require large enough sample size Central Limit Theorem can apply. proportions, condition known success-failure condition.","code":""},{"path":"probability.html","id":"probability","chapter":"10 Probability with tables","heading":"10 Probability with tables","text":"TODO","code":""},{"path":"probability.html","id":"defining-probability","chapter":"10 Probability with tables","heading":"10.1 Defining probability","text":"random process one outcome unpredictable. encounter random processes every day: rain today? many minutes pass receiving next text message? Seahawks win Super Bowl? Though outcome one particular random process unpredictable, observe process many many times, pattern outcomes, probability distribution, can often modeled mathematically. Though several philosophical definitions probability, use “frequentist” definition probability—long-run relative frequency.Probability.probability event long-run proportion times event occur random process repeated indefinitely (identical conditions).Consider simple example flipping fair coin . probability coin lands heads. physical properties, assume probability heads 0.5, let’s use simulation examine probability. Figure 10.1 shows long-run proportion times simulated coin flip lands heads y-axis, number tosses x-axis. Notice long-run proportion starts converging 0.5 number tosses increases.\nFigure 10.1: One simulation flipping fair coin, tracking long-run proportion times coin lands heads.\n","code":""},{"path":"probability.html","id":"finding-probabilities-with-tables","chapter":"10 Probability with tables","heading":"10.2 Finding probabilities with tables","text":"can solve many real-life probability problems without using equations creating hypothetical two-way table scenario. tool best demonstrated example.student Montana State University, suppose first class Mondays Wilson Hall 8:00am commute school. Bobcat parking permit. past experience, know 20% chance finding open parking spot Lot 6 Animal Bioscience. Otherwise, park Lot 18 graduate housing. find spot Lot 6, 5% chance late class. However, park Lot 18, 15% chance late class. probability late class Monday?two random variables scenario: whether park Lot 6 Lot 18, whether late class. Since know probability long-run relative frequency, let’s imagine 1000 hypothetical Mondays, fill contingency table frequencies ’d expect cell.Now can find probability late class reading table: 130/1000 = 0.13.create table last Example? Let’s work step--step.Identify unconditional probabilities given problem: 20% chance parking Lot 6, means 80% chance parking Lot 18. Take 20% 80% 1000 fill row totals:Identify conditional probabilities given problem: park Lot 6, probability late class 5%; park Log 18, probability late class 15%. Fill corresponding cells table taking 5% times parked Lot 6, 15% times parked Lot 18:Use subtraction fill remaining cells column “late class.” Use addition find column totals.Using hypothetical two-way table given last Example, find following probabilities:probability late class?probability park Lot 6 late class?Given late class, probability parked Lot 18?84Carefully read probabilities described Guided Practice—note subtle difference “probability late class, given parked Lot 18” (\\(120/800 = 0.15\\)) “probability parking Lot 18, given late class” (\\(120/130 = 0.923\\)). given extra information, called conditional probability, denominator probability calculation row total (e.g., 800) column total (e.g., 130) rather overall total hypothetical two-way table.previous Guided Practice, probabilities conditional probabilities? unconditional?85","code":""},{"path":"probability.html","id":"probability-notation","chapter":"10 Probability with tables","heading":"10.3 Probability notation","text":"ease translating probability problems calculations, let’s define notation. denote “events” (e.g., late class) upper case letters near beginning alphabet, e.g., \\(\\), \\(B\\), \\(C\\). probability event \\(\\) denoted \\(P()\\), \\(P()\\) number 0 1. event \\(\\) happen called complement \\(\\) denoted \\(P(^C)\\). Sometimes additional information like condition , denote conditional probability \\(\\) given \\(B\\) \\(P(| B)\\)—probability \\(\\) happens given \\(B\\) already happened.coin flip example, let \\(\\) event coin lands heads. can denote probability coin lands heads \\(P() = 0.5\\). flip coin twice let \\(H_1\\) event first flip lands heads, \\(H_2\\) event second flip lands heads. Since coin remember last flip, first flip lands heads, second flip still 50% chance landing heads. , \\(P(H_2 | H_1) = 0.5\\).","code":""},{"path":"probability.html","id":"diagnostic-testing","chapter":"10 Probability with tables","heading":"10.4 Diagnostic testing","text":"Medical diagnostic tests diseases spend years development. clinical trials, developers diagnostic test able determine two important properties test:sensitivity diagnostic test probability test yields positive result, given individual disease. words, proportion diseased population test positive?specificity diagnostic test probability test yields negative result, given individual disease. , proportion non-diseased population test negative?good diagnostic test high (near 100%) sensitivity specificity. However, even near-perfect test, probability disease given test positive still quite low. investigate counter-intuitive result, need another definition:call proportion population disease—probability contracting disease—prevalence (incidence) disease.Let \\(D\\) event individual disease \\(T\\) event individual tests positive. express following quantities using probability notation?sensitivityspecificityprevalence86Note sensitivity specificity conditional probabilities, prevalence unconditional probability. probabilities useful information, test positive diagnostic test, none quantities probability really want know: conditional probability disease, given tested positive, \\(P(D | T)\\).","code":""},{"path":"probability.html","id":"the-case-of-baby-jeff","chapter":"10 Probability with tables","heading":"10.4.1 The case of Baby Jeff","text":"following case study presented Slawson Shaughnessy (2002). poster hospital’s newborn nursery announced male newborns screened muscular dystrophy using heel stick blood test creatinine phosphokinase (CPK). test characteristics screening tests nearly perfect: sensitivity 100% specificity 99.98%. prevalence muscular dystrophy male newborns ranges 1 3,500 1 15,000. Baby Jeff abnormal CPK test. parents baby wanted know, “chance son muscular dystrophy?” Doctors informed parents though 100% likely, highly probable. First, take minute predict probability – think? 80% chance? 99% chance? Let’s investigate using two-way table hypothetical population 100,000 male newborns.calculations, let’s use prevalence 1 10,000. 100,000 hypothetical male newborns, expect 1 10,000 muscular dystrophy, 10: \\((1/10000)\\times 100000 = 10\\). sensitivity test perfect, 10 male newborns muscular dystrophy test positive. \\(100000-10 = 99,990\\) male newborns muscular dystrophy, 99.98% test negative: \\((0.9998)\\times 99990 = 99,970\\) infants. leaves \\(99990 - 99970 = 20\\) male newborns test positive even though muscular dystrophy. allows us fill counts hypothetical two-way table:Now can read desired probability table: 30 male newborns ’d expect test positive, 10 actually muscular dystrophy. means chance Baby Jeff muscular dystrophy 33%!probability change prevalence 1/3500? 1/15000? Try .87Why counter-intuitive result occur? high sensitivity specificity, test perform poorly? answer prevalence disease. rare disease, small proportion test positive large group people without disease overwhelm large proportion test positive small group people disease. number false positives can much higher number true positives.","code":""},{"path":"probability.html","id":"chp23-review","chapter":"10 Probability with tables","heading":"10.5 Chapter review","text":"","code":""},{"path":"probability.html","id":"summary-7","chapter":"10 Probability with tables","heading":"Summary","text":"TODO","code":""},{"path":"probability.html","id":"terms-7","chapter":"10 Probability with tables","heading":"Terms","text":"introduced following terms chapter.\n’re sure terms mean, recommend go back text review definitions.\npurposefully presenting alphabetical order, instead order appearance, little challenging locate.\nHowever able easily spot bolded text.","code":""},{"path":"probability.html","id":"key-ideas-7","chapter":"10 Probability with tables","heading":"Key ideas","text":"Probabilities can either unconditional conditional. unconditional probability proportion proportion measured entire population; whereas conditional probability proportion proportion measured subgroup population. computing probabilities using contingency table, unconditional probabilities computed dividing cell total overall total; conditional probabilities computed dividing cell total row column total.Probabilities can either unconditional conditional. unconditional probability proportion proportion measured entire population; whereas conditional probability proportion proportion measured subgroup population. computing probabilities using contingency table, unconditional probabilities computed dividing cell total overall total; conditional probabilities computed dividing cell total row column total.Recall Chapter @ref(#categorical-data) two variables associated behavior one variable depends value variable. two categorical variables, occurs conditional probabilities category one variable change across probabilities variable.Recall Chapter @ref(#categorical-data) two variables associated behavior one variable depends value variable. two categorical variables, occurs conditional probabilities category one variable change across probabilities variable.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
