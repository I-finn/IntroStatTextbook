<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Hypothesis testing with randomization | Montana State Introductory Statistics with R</title>
<meta name="author" content="Stacey Hancock, Nicole Carnegie, Elijah Meyer, Jade Schmidt, Melinda Yager">
<meta name="description" content="Statistical inference is primarily concerned with understanding and quantifying the uncertainty of parameter estimates—that is, how variable is a sample statistic from sample to sample? While the...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 9 Hypothesis testing with randomization | Montana State Introductory Statistics with R">
<meta property="og:type" content="book">
<meta property="og:url" content="https://mtstateintrostats.github.io/IntroStatTextbook/foundations-randomization.html">
<meta property="og:description" content="Statistical inference is primarily concerned with understanding and quantifying the uncertainty of parameter estimates—that is, how variable is a sample statistic from sample to sample? While the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 9 Hypothesis testing with randomization | Montana State Introductory Statistics with R">
<meta name="twitter:description" content="Statistical inference is primarily concerned with understanding and quantifying the uncertainty of parameter estimates—that is, how variable is a sample statistic from sample to sample? While the...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet">
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/plotly-binding-4.10.0/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script><script type="text/x-mathjax-config">
    const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
    for (let popover of popovers){
      const div = document.createElement('div');
      div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
      div.innerHTML = popover.getAttribute('data-content');
      
      // Will this work with TeX on its own line?
      var has_math = div.querySelector("span.math");
      if (has_math) {
        document.body.appendChild(div);
      	MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
      	MathJax.Hub.Queue(function(){
          popover.setAttribute('data-content', div.innerHTML);
      	})
      }
    }
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="css/ims-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Montana State Introductory Statistics with R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="authors.html">Authors</a></li>
<li><a class="" href="preface.html">Preface</a></li>
<li><a class="" href="rstudio.html">Preliminaries: Getting started in RStudio</a></li>
<li class="book-part">Introduction to data</li>
<li><a class="" href="data-hello.html"><span class="header-section-number">1</span> Hello data</a></li>
<li><a class="" href="data-design.html"><span class="header-section-number">2</span> Study design</a></li>
<li><a class="" href="data-applications.html"><span class="header-section-number">3</span> Applications: Data</a></li>
<li class="book-part">Exploratory data analysis</li>
<li><a class="" href="explore-categorical.html"><span class="header-section-number">4</span> Exploring categorical data</a></li>
<li><a class="" href="explore-numerical.html"><span class="header-section-number">5</span> Exploring quantitative data</a></li>
<li><a class="" href="explore-regression.html"><span class="header-section-number">6</span> Correlation and regression</a></li>
<li><a class="" href="explore-mult-reg.html"><span class="header-section-number">7</span> Multivariable models</a></li>
<li><a class="" href="explore-applications.html"><span class="header-section-number">8</span> Applications: Explore</a></li>
<li class="book-part">Foundations of inference</li>
<li><a class="active" href="foundations-randomization.html"><span class="header-section-number">9</span> Hypothesis testing with randomization</a></li>
<li><a class="" href="foundations-bootstrapping.html"><span class="header-section-number">10</span> Confidence intervals with bootstrapping</a></li>
<li><a class="" href="foundations-mathematical.html"><span class="header-section-number">11</span> Inference with mathematical models</a></li>
<li><a class="" href="foundations-errors.html"><span class="header-section-number">12</span> Errors, power, and practical importance</a></li>
<li><a class="" href="foundations-applications.html"><span class="header-section-number">13</span> Applications: Foundations</a></li>
<li class="book-part">Inference for categorical data</li>
<li><a class="" href="inference-one-prop.html"><span class="header-section-number">14</span> Inference for a single proportion</a></li>
<li><a class="" href="inference-two-props.html"><span class="header-section-number">15</span> Inference for comparing two proportions</a></li>
<li><a class="" href="inference-categ-applications.html"><span class="header-section-number">16</span> Applications: Infer categorical</a></li>
<li class="book-part">Inference for quantitative data</li>
<li><a class="" href="inference-one-mean.html"><span class="header-section-number">17</span> Inference for a single mean</a></li>
<li><a class="" href="inference-paired-means.html"><span class="header-section-number">18</span> Inference for comparing paired means</a></li>
<li><a class="" href="inference-two-means.html"><span class="header-section-number">19</span> Inference for comparing two independent means</a></li>
<li><a class="" href="inference-num-applications.html"><span class="header-section-number">20</span> Applications: Infer quantitative</a></li>
<li class="book-part">Inference for regression</li>
<li><a class="" href="inference-reg.html"><span class="header-section-number">21</span> Inference for correlation and slope</a></li>
<li><a class="" href="inference-reg-applications.html"><span class="header-section-number">22</span> Applications: Infer regression</a></li>
<li class="book-part">Probability</li>
<li><a class="" href="probability.html"><span class="header-section-number">23</span> Probability with tables</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/MTstateIntroStats/IntroStatTextbook">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="foundations-randomization" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Hypothesis testing with randomization<a class="anchor" aria-label="anchor" href="#foundations-randomization"><i class="fas fa-link"></i></a>
</h1>
<div class="chapterintro">
<p>Statistical inference is primarily concerned with understanding and quantifying the <em>uncertainty</em> of parameter estimates—that is, how variable is a sample statistic from sample to sample? While the equations and details change depending on the setting, the foundations for inference are the same throughout all of statistics.</p>
<p>We start with two case studies designed to motivate the process of making decisions about research claims.
We formalize the process through the introduction of the <strong>hypothesis testing framework</strong>, which allows us to formally evaluate claims about the population.</p>
</div>
<!-- # Inference for categorical data {#inference-cat} -->
<p>Throughout the book so far, you have worked with data in a variety of contexts. You have learned how to summarize and visualize the data as well as how to visualize multiple variables at the same time. Sometimes the data set at hand represents the entire research question. But more often than not, the data have been collected to answer a research question about a larger group of which the data are a (hopefully) representative subset.</p>
<p>You may agree that there is almost always variability in data (one data set will not be identical to a second data set even if they are both collected from the same population using the same methods).
However, quantifying the variability in the data is neither obvious nor easy to do, i.e., answering the question “<em>how</em> different is one data set from another?” is not trivial.</p>
<p>First, a reminder on notation.
We generally use <span class="math inline">\(\pi\)</span> to denote a population proportion and <span class="math inline">\(\hat{p}\)</span> to a sample proportion.
Similarly, we generally use <span class="math inline">\(\mu\)</span> to denote a population mean and <span class="math inline">\(\bar{x}\)</span> to denote a sample mean.</p>
<div class="workedexample">
<p>Suppose your professor splits the students in your class into two groups: students who sit on the left side of the classroom and students who sit on the right side of the classroom.
If <span class="math inline">\(\hat{p}_{L}\)</span> represents the proportion of students who prefer to read books on screen who sit on the left side of the classroom and <span class="math inline">\(\hat{p}_{R}\)</span> represents the proportion of students who prefer to read books on screen who sit on the right side of the classroom, would you be surprised if <span class="math inline">\(\hat{p}_{L}\)</span> did not <em>exactly</em> equal <span class="math inline">\(\hat{p}_{R}\)</span>?</p>
<hr>
<p>While the proportions <span class="math inline">\(\hat{p}_{L}\)</span> and <span class="math inline">\(\hat{p}_{R}\)</span> would probably be close to each other, it would be unusual for them to be exactly the same.
We would probably observe a small difference due to <em>chance</em>.</p>
</div>
<div class="guidedpractice">
<p>If we do not think the side of the room a person sits on in class is related to whether they prefer to read books on screen, what assumption are we making about the relationship between these two variables?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;We would be assuming that these two variables are &lt;strong&gt;independent&lt;/strong&gt;.&lt;/p&gt;"><sup>74</sup></a></p>
</div>
<p>Studying randomness of this form is a key focus of statistics. Throughout this chapter, and those that follow, we provide two different approaches for quantifying the variability inherent in data: simulation-based methods and theory-based methods (mathematical models). Using the methods provided in this and future chapters, we will be able to draw conclusions beyond the data set at hand to research questions about larger populations that the samples come from.</p>
<!-- ## Foundations of inference {#inf-foundations} -->
<p>Given results seen in a sample, the process of determining what we can <em>infer</em> to the population based on sample results is called <strong>statistical inference</strong>. Statistical inferential methods enable us to understand and quantify the <em>uncertainty</em> of our sample results. Statistical inference helps us answer two questions about the population:</p>
<ol style="list-style-type: decimal">
<li>How strong is the <em>evidence</em> of an effect?</li>
<li>How <em>large</em> is the effect?</li>
</ol>
<p>The first question is answered through a <strong>hypothesis test</strong>, while the second is addressed with a <strong>confidence interval</strong>. This chapter will introduce you to the foundations of hypothesis testing, while the ideas behind confidence intervals will be presented in the next chapter.</p>
<p>Statistical inference is the practice of making decisions and conclusions from data in the context of uncertainty. Errors do occur, just like rare events, and the data set at hand might lead us to the wrong conclusion. While a given data set may not always lead us to a correct conclusion, statistical inference gives us tools to control and evaluate how often these errors occur.</p>
<div id="Martian" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Motivating example: Martian alphabet<a class="anchor" aria-label="anchor" href="#Martian"><i class="fas fa-link"></i></a>
</h2>
<p>How well can humans distinguish one “Martian” letter from another? The Figure <a href="foundations-randomization.html#fig:kiki-bumba">9.1</a> displays two Martian letters—one is Kiki and the another is Bumba. Which do you think is Kiki and which do you think is Bumba? Take a moment to write down your guess.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:kiki-bumba"></span>
<img src="05/images/bumBa-KiKi.png" alt="Two Martian letters: Bumba and Kiki. Do you think the letter Bumba is on the left or the right?^[Bumba is the Martian letter on the left!]" width="75%"><p class="caption">
Figure 9.1: Two Martian letters: Bumba and Kiki. Do you think the letter Bumba is on the left or the right?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Bumba is the Martian letter on the left!&lt;/p&gt;"><sup>75</sup></a>
</p>
</div>
<div id="observed-data" class="section level3" number="9.1.1">
<h3>
<span class="header-section-number">9.1.1</span> Observed data<a class="anchor" aria-label="anchor" href="#observed-data"><i class="fas fa-link"></i></a>
</h3>
<p>This same image and question from Figure <a href="foundations-randomization.html#fig:kiki-bumba">9.1</a> were presented to an introductory statistics class of 38 students. In that class, 34 students correctly identified Bumba as the Martian letter on the left. That is, a sample proportion of <span class="math inline">\(\hat{p} = 34/38 = 0.90\)</span>. Assuming we can’t read Martian, is this result surprising?</p>
<p>One of two possibilities occurred:</p>
<ol style="list-style-type: decimal">
<li><em>We can’t read Martian, and these results just occurred by chance.</em></li>
<li><em>We can read Martian, and these results reflect this ability.</em></li>
</ol>
<p>To decide between these two possibilities, we could calculate the probability of observing such results in a randomly selected sample of 38 students, under the assumption that students were just guessing. If this probability is <em>very low</em>, we’d have reason to reject the first possibility in favor of the second. We can calculate this probability using one of two methods:</p>
<ul>
<li>
<strong>Simulation-based method</strong>: simulate lots of samples (classes) of 38 students under the assumption that students are just guessing, then calculate the proportion of these simulated samples where we saw 34 or more students guessing correctly, or</li>
<li>
<strong>Theory-based method</strong>: develop a mathematical model for the sample proportion in this scenario and use the model to calculate the probability.</li>
</ul>
</div>
<div id="variability-in-a-statistic" class="section level3" number="9.1.2">
<h3>
<span class="header-section-number">9.1.2</span> Variability in a statistic<a class="anchor" aria-label="anchor" href="#variability-in-a-statistic"><i class="fas fa-link"></i></a>
</h3>
<div class="guidedpractice">
<p>How could you use a coin or cards to simulate the guesses of one sample of 38 students who cannot read Martian?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;A fair coin has a 50% chance of landing on heads, which is the chance a student would guess Bumba correctly if they were just guessing. Thus, toss a coin 38 times with heads representing “guess correctly”; then calculate the proportion of tosses that landed on heads. Another option would be to 10 black cards and 10 red cards, letting red represent “guess correctly”. Shuffle the cards and draw one card, record if it is red or black, then replace the card and shuffle again. Do this 38 times and calculate the proportion of red cards observed.&lt;/p&gt;"><sup>76</sup></a></p>
</div>
<p>The observed data showed 34 students correctly identifying Bumba in a class of 38 students, or 90%. Now, suppose students were truly “just guessing”, meaning each student had a 50% chance of guessing correctly. Then, if we conducted the study again with a different sample of 38 students, we would expect about half (or 19 students) to guess correctly, and the other half to guess incorrectly. Any variation from 19 would be based only on random fluctuation in our sample selection process. We could actually perform this <strong>simulation</strong> of what would happen if we randomly chose another 38 students that were “just guessing” by flipping a coin 38 times and counting the number of times it lands on heads. Try it out—how many correctly guessed Bumba in your simulated class of 38 students? What proportion guessed correctly?</p>
</div>
<div id="observed-statistic-vs.-null-statistics" class="section level3" number="9.1.3">
<h3>
<span class="header-section-number">9.1.3</span> Observed statistic vs. null statistics<a class="anchor" aria-label="anchor" href="#observed-statistic-vs.-null-statistics"><i class="fas fa-link"></i></a>
</h3>
<p>By flipping a coin 38 times, we computed one possible sample proportion of students guessing correctly under the assumption that they were “just guessing”.
While in this first simulation, we physically flipped a coin, it is much more efficient to perform this simulation using a computer.
Using a computer to repeat this process 1,000 times, we create the dot plot of simulated sample proportions shown in Figure <a href="foundations-randomization.html#fig:MartianDotPlot">9.2</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:MartianDotPlot"></span>
<img src="09-foundations-hyp-testing_files/figure-html/MartianDotPlot-1.png" alt="A dot plot of 1,000 sample proportions; each calculated by flipping a coin 38 times and calculating the proportion of times the coin landed on heads. None of the 1,000 simulations had sample proportion of at least 89%, which was the proportion observed in the study." width="90%"><p class="caption">
Figure 9.2: A dot plot of 1,000 sample proportions; each calculated by flipping a coin 38 times and calculating the proportion of times the coin landed on heads. None of the 1,000 simulations had sample proportion of at least 89%, which was the proportion observed in the study.
</p>
</div>
<p>Our <strong>observed statistic</strong>, <span class="math inline">\(\hat{p} = 0.90\)</span>, is represented in Figure <a href="foundations-randomization.html#fig:MartianDotPlot">9.2</a> by the
red triangle.
The simulated sample proportions plotted in blue represent <strong>null statistics</strong>, since they were simulated under the assumption of “just guessing” or “nothing” or “null”.
None of the simulated null statistics got even close to our observed statistic!
That is, if students were just guessing, it is nearly impossible to observe 34 or more students guessing correctly in a sample of 38 students.
Given this low probability, the more plausible possibility is 2. <em>We can read Martian, and these results reflect this ability.</em> We’ve just completed our first hypothesis test!</p>
<p>Now, obviously no one can read Martian, so a more realistic possibility is that humans tend to choose Bumba on the left more often than the right—there is a greater than 50% chance of choosing Bumba as the letter on the left. Even though we may think we’re guessing just by chance, we have a preference for Bumba on the left. It turns out that the explanation for this preference is called <em>synesthesia</em>, a tendency for humans to correlate sharp sounding noises (e.g., Kiki) with sharp looking images.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;To explore this further, watch this &lt;a href="https://www.ted.com/talks/vs_ramachandran_3_clues_to_understanding_your_brain"&gt;TED Talk&lt;/a&gt; by neurologist Vilayanur Ramachandran (The synesthesia part begins at roughly 17:40 minutes).&lt;/p&gt;'><sup>77</sup></a></p>
</div>
</div>
<div id="caseStudySexDiscrimination" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Case study: Sex discrimination<a class="anchor" aria-label="anchor" href="#caseStudySexDiscrimination"><i class="fas fa-link"></i></a>
</h2>
<p>Before getting into the nuances of hypothesis testing, let’s work through another case study.
We consider a study investigating sex discrimination in the 1970s, which is set in the context of personnel decisions within a bank.
The research question we hope to answer is, “Are individuals who identify as female discriminated against in promotion decisions made by their managers who identify as male?” <span class="citation">(<a href="references.html#ref-Rosen:1974" role="doc-biblioref">Rosen and Jerdee 1974</a>)</span></p>
<div class="data">
<p>The <a href="http://openintrostat.github.io/openintro/reference/sex_discrimination.html"><code>sex_discrimination</code></a> data can be found in the <a href="http://openintrostat.github.io/openintro"><strong>openintro</strong></a> R package.</p>
</div>
<p>This study considered sex roles, and only allowed for options of “male” and “female”.
We should note that the identities being considered are not gender identities and that the study allowed only for a binary classification of sex.</p>
<div id="observed-data-1" class="section level3" number="9.2.1">
<h3>
<span class="header-section-number">9.2.1</span> Observed data<a class="anchor" aria-label="anchor" href="#observed-data-1"><i class="fas fa-link"></i></a>
</h3>
<p>The participants in this study were 48 bank supervisors who identified as male, attending a management institute at the University of North Carolina in 1972.
They were asked to assume the role of the personnel director of a bank and were given a personnel file to judge whether the person should be promoted to a branch manager position.
The files given to the participants were identical, except that half of them indicated the candidate identified as male and the other half indicated the candidate identified as female.
These files were randomly assigned to the subjects.</p>
<div class="guidedpractice">
<p>Is this an observational study or an experiment?
How does the type of study impact what can be inferred from the results?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The study is an experiment, as subjects were randomly assigned a “male” file or a “female” file (remember, all the files were actually identical in content).
Since this is an experiment, the results can be used to evaluate a causal relationship between the sex of a candidate and the promotion decision.&lt;/p&gt;"><sup>78</sup></a></p>
</div>
<p>For each supervisor both the sex associated with the assigned file and the promotion decision were recorded.
Using the results of the study summarized in Table <a href="foundations-randomization.html#tab:sex-discrimination-obs">9.1</a>, we would like to evaluate if individuals who identify as female are unfairly discriminated against in promotion decisions.
In this study, a smaller proportion of female identifying applications were promoted than males (0.583 versus 0.875), but it is unclear whether the difference provides <em>convincing evidence</em> that individuals who identify as female are unfairly discriminated against.</p>
<div class="inline-table"><table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:sex-discrimination-obs">Table 9.1: </span>Summary results for the sex discrimination study.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
decision
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:left;">
sex
</th>
<th style="text-align:right;">
promoted
</th>
<th style="text-align:right;">
not promoted
</th>
<th style="text-align:right;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 7em; ">
male
</td>
<td style="text-align:right;width: 7em; ">
21
</td>
<td style="text-align:right;width: 7em; ">
3
</td>
<td style="text-align:right;width: 7em; ">
24
</td>
</tr>
<tr>
<td style="text-align:left;width: 7em; ">
female
</td>
<td style="text-align:right;width: 7em; ">
14
</td>
<td style="text-align:right;width: 7em; ">
10
</td>
<td style="text-align:right;width: 7em; ">
24
</td>
</tr>
<tr>
<td style="text-align:left;width: 7em; ">
Total
</td>
<td style="text-align:right;width: 7em; ">
35
</td>
<td style="text-align:right;width: 7em; ">
13
</td>
<td style="text-align:right;width: 7em; ">
48
</td>
</tr>
</tbody>
</table></div>
<p>The data are visualized in Figure <a href="foundations-randomization.html#fig:sex-rand-obs">9.3</a> as a set of cards.
Note that each card denotes a personnel file (an observation from our data set) and the colors indicate the decision: red for promoted and white for not promoted.
Additionally, the observations are broken up into groups of male and female identifying groups.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sex-rand-obs"></span>
<img src="images/sex-rand-01-obs.png" alt="48 cards are laid out; 24 indicating male files, 24 indicated female files.  Of the 24 male files 3 of the cards are colored white, and 21 of the cards are colored red. Of the female files, 10 of the cards are colored white, and 14 of the cards are colored red." width="40%"><p class="caption">
Figure 9.3: The sex discrimination study can be thought of as 48 red and white cards.
</p>
</div>
<div class="workedexample">
<p>Statisticians are sometimes called upon to evaluate the strength of evidence.
When looking at the rates of promotion in this study, why might we be tempted to immediately conclude that individuals identifying as female are being discriminated against?</p>
<hr>
<p>The large difference in promotion rates (58.3% for female personnel versus 87.5% for male personnel) suggest there might be discrimination against women in promotion decisions.
However, we cannot yet be sure if the observed difference represents discrimination or is just due to random chance when there is no discrimination occurring.
Since we wouldn’t expect the sample proportions to be <em>exactly</em> equal, even if the truth was that the promotion decisions were independent of sex, we can’t rule out random chance as a possible explanation when simply comparing the sample proportions.</p>
</div>
<p>The previous example is a reminder that the observed outcomes in the sample may not perfectly reflect the true relationships between variables in the underlying population.
Table <a href="foundations-randomization.html#tab:sex-discrimination-obs">9.1</a> shows there were 7 fewer promotions for female identifying personnel than for the male personnel, a difference in promotion rates of 29.2% <span class="math inline">\(\left( \frac{21}{24} - \frac{14}{24} = 0.292 \right).\)</span> This observed difference is what we call a <strong>point estimate</strong> of the true difference.
The point estimate of the difference in promotion rate is large, but the sample size for the study is small, making it unclear if this observed difference represents discrimination or whether it is simply due to chance when there is no discrimination occurring.
Chance can be thought of as the claim due to natural variability; discrimination can be thought of as the claim the researchers set out to demonstrate.
We label these two competing claims, <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A:\)</span></p>
<ul>
<li>
<span class="math inline">\(H_0:\)</span> <strong>Null hypothesis</strong>.
The variables <code>sex</code> and <code>decision</code> are independent.
They have no relationship, and the observed difference between the proportion of males and females who were promoted, 29.2%, was due to the natural variability inherent in the population.</li>
<li>
<span class="math inline">\(H_A:\)</span> <strong>Alternative hypothesis</strong>.
The variables <code>sex</code> and <code>decision</code> are <em>not</em> independent.
The difference in promotion rates of 29.2% was not due to natural variability, and equally qualified female personnel are less likely to be promoted than male personnel.</li>
</ul>
<div class="onebox">
<p><strong>Hypothesis testing.</strong></p>
<p>These hypotheses are part of what is called a <strong>hypothesis test</strong>.
A hypothesis test is a statistical technique used to evaluate competing claims using data.
Often times, the null hypothesis takes a stance of <em>no difference</em> or <em>no effect</em>.
This hypothesis assumes that any differences seen are due to the variability inherent in the population and could have occurred by random chance.</p>
<p>If the null hypothesis and the data notably disagree, then we will reject the null hypothesis in favor of the alternative hypothesis.</p>
<p>There are many nuances to hypothesis testing, so do not worry if you aren’t a master of hypothesis testing at the end of this chapter.
We’ll discuss these ideas and details many times in this chapter as well as in the chapters that follow.</p>
</div>
<p>What would it mean if the null hypothesis, which says the variables <code>sex</code> and <code>decision</code> are unrelated, was true?
It would mean each banker would decide whether to promote the candidate without regard to the sex indicated on the personnel file.
That is, the difference in the promotion percentages would be due to the natural variability in how the files were randomly allocated to different bankers, and this randomization just happened to give rise to a relatively large difference of 29.2%.</p>
<p>Consider the alternative hypothesis: bankers were influenced by which sex was listed on the personnel file.
If this was true, and especially if this influence was substantial, we would expect to see some difference in the promotion rates of male and female candidates.
If this sex bias was against female candidates, we would expect a smaller fraction of promotion recommendations for female personnel relative to the male personnel.</p>
<p>We will choose between the two competing claims by assessing if the data conflict so much with <span class="math inline">\(H_0\)</span> that the null hypothesis cannot be deemed reasonable.
If data and the null claim seem to be at odds with one another, and the data seem to support <span class="math inline">\(H_A,\)</span> then we will reject the notion of independence and conclude that the data provide evidence of discrimination.</p>
</div>
<div id="variability-of-the-statistic" class="section level3" number="9.2.2">
<h3>
<span class="header-section-number">9.2.2</span> Variability of the statistic<a class="anchor" aria-label="anchor" href="#variability-of-the-statistic"><i class="fas fa-link"></i></a>
</h3>
<p>Table <a href="foundations-randomization.html#tab:sex-discrimination-obs">9.1</a> shows that 35 bank supervisors recommended promotion and 13 did not.
Now, suppose the bankers’ decisions were independent of the sex of the candidate.
Then, if we conducted the experiment again with a different random assignment of sex to the files, differences in promotion rates would be based only on random fluctuation in promotion decisions.
We can actually perform this <strong>randomization</strong>, which simulates what would have happened if the bankers’ decisions had been independent of <code>sex</code> but we had distributed the file sexes differently.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The test procedure we employ in this section is sometimes referred to as a &lt;strong&gt;randomization test&lt;/strong&gt;. If the explanatory variable had not been randomly assigned, as in an observational study, the procedure would be referred to as a &lt;strong&gt;permutation test&lt;/strong&gt;..&lt;/p&gt;"><sup>79</sup></a></p>
<p>In the <strong>simulation</strong>, we thoroughly shuffle the 48 personnel files, 35 labelled <code>promoted</code> and 13 labelled <code>not promoted</code>, together and we deal files into two new stacks.
Note that by keeping 35 promoted and 13 not promoted, we are assuming that 35 of the bank managers would have promoted the individual whose content is contained in the file <strong>independent</strong> of the sex indicated on their file.
We will deal 24 files into the first stack, which will represent the 24 “female” files.
The second stack will also have 24 files, and it will represent the 24 “male” files.
Figure <a href="foundations-randomization.html#fig:sex-rand-shuffle-1">9.4</a> highlights both the shuffle and the reallocation to the sham sex groups.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sex-rand-shuffle-1"></span>
<img src="images/sex-rand-02-shuffle-1.png" alt="The 48 red and white cards which denote the original data are shuffled and reassigned, 24 to each group indicating 24 male files and 24 female files." width="80%"><p class="caption">
Figure 9.4: The sex discrimination data is shuffled and reallocated to new groups of male and female files.
</p>
</div>
<p>Then, as we did with the original data, we tabulate the results and determine the fraction of personnel files designated as “male” and “female” who were promoted.</p>
<p>Since the randomization of files in this simulation is independent of the promotion decisions, any difference in promotion rates is due to chance.
Table <a href="foundations-randomization.html#tab:sex-discrimination-rand-1">9.2</a> show the results of one such simulation.</p>
<div class="inline-table"><table class="table table-striped table-condensed" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:sex-discrimination-rand-1">Table 9.2: </span>Simulation results, where the difference in promotion rates between male and female is purely due to random chance.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
decision
</div>
</th>
<th style="empty-cells: hide;border-bottom:hidden;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:left;">
sex
</th>
<th style="text-align:right;">
promoted
</th>
<th style="text-align:right;">
not promoted
</th>
<th style="text-align:right;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 7em; ">
male
</td>
<td style="text-align:right;width: 7em; ">
18
</td>
<td style="text-align:right;width: 7em; ">
6
</td>
<td style="text-align:right;width: 7em; ">
24
</td>
</tr>
<tr>
<td style="text-align:left;width: 7em; ">
female
</td>
<td style="text-align:right;width: 7em; ">
17
</td>
<td style="text-align:right;width: 7em; ">
7
</td>
<td style="text-align:right;width: 7em; ">
24
</td>
</tr>
<tr>
<td style="text-align:left;width: 7em; ">
Total
</td>
<td style="text-align:right;width: 7em; ">
35
</td>
<td style="text-align:right;width: 7em; ">
13
</td>
<td style="text-align:right;width: 7em; ">
48
</td>
</tr>
</tbody>
</table></div>
<div class="guidedpractice">
<p>What is the difference in promotion rates between the two simulated groups in Table <a href="foundations-randomization.html#tab:sex-discrimination-rand-1">9.2</a> ?
How does this compare to the observed difference 29.2% from the actual study?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(18/24 - 17/24=0.042\)&lt;/span&gt; or about 4.2% in favor of the male personnel.
This difference due to chance is much smaller than the difference observed in the actual groups.&lt;/p&gt;'><sup>80</sup></a></p>
</div>
<p>Figure <a href="foundations-randomization.html#fig:sex-rand-shuffle-1-sort">9.5</a> shows that the difference in promotion rates is much larger in the original data than it is in the simulated groups (0.292 &gt; 0.042).
The quantity of interest throughout this case study has been the difference in promotion rates.
We call the summary value the <strong>observed statistic</strong> of interest (or often the <strong>test statistic</strong>).
When we encounter different data structures, the type of statistic is likely to change (e.g., we might calculate an average instead of a proportion), but we will always want to understand how the statistic varies from sample to sample.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sex-rand-shuffle-1-sort"></span>
<img src="images/sex-rand-03-shuffle-1-sort.png" alt="The 48 red and white cards are show in three panels.  The first panel represents the original data and original allocation of the male and female files (in the original data there are 3 white cards in the male group and 10 white cards in the female group).  The second panel represents the shuffled red and white cards that are randomly assigned as male and female files.  The third panel has the cards sorted according to the random assignment of female or male.  In the third panel there are 6 white cards in the male group and 7 white cards in the female group." width="100%"><p class="caption">
Figure 9.5: We summarize the randomized data to produce one estimate of the difference in proportions given no sex discrimination. Note that the sort step is only used to make it easier to visually calculate the simulated sample proportions.
</p>
</div>
</div>
<div id="observed-statistic-vs.-null-statistics-1" class="section level3" number="9.2.3">
<h3>
<span class="header-section-number">9.2.3</span> Observed statistic vs. null statistics<a class="anchor" aria-label="anchor" href="#observed-statistic-vs.-null-statistics-1"><i class="fas fa-link"></i></a>
</h3>
<p>We computed one possible difference under the null hypothesis in Guided Practice, which represents one difference due to chance when the null hypothesis is assumed to be true.
While in this first simulation, we physically dealt out files, it is much more efficient to perform this simulation using a computer.
Repeating the simulation on a computer, we get another difference due to chance under the same assumption: -0.042.
And another: 0.208.
And so on until we repeat the simulation enough times that we have a good idea of the shape of the <em>distribution of differences</em> under the null hypothesis.
Figure <a href="foundations-randomization.html#fig:sex-rand-dot-plot">9.6</a> shows a plot of the differences found from 100 simulations, where each dot represents a simulated difference between the proportions of male and female files recommended for promotion.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sex-rand-dot-plot"></span>
<img src="09-foundations-hyp-testing_files/figure-html/sex-rand-dot-plot-1.png" alt="A stacked dot plot of differences from 100 simulations produced under the null hypothesis, \(H_0,\) where the simulated sex and decision are independent. Two of the 100 simulations had a difference of at least 29.2%, the difference observed in the study, and are shown as solid blue dots." width="100%"><p class="caption">
Figure 9.6: A stacked dot plot of differences from 100 simulations produced under the null hypothesis, <span class="math inline">\(H_0,\)</span> where the simulated sex and decision are independent. Two of the 100 simulations had a difference of at least 29.2%, the difference observed in the study, and are shown as solid blue dots.
</p>
</div>

<p>Note that the distribution of these simulated differences in proportions is centered around 0.
Under the null hypothesis our simulations made no distinction between male and female personnel files.
Thus, a center of 0 makes sense: we should expect differences from chance alone to fall around zero with some random fluctuation for each simulation.</p>
<div class="workedexample">
<p>How often would you observe a difference of at least 29.2% (0.292) according to Figure <a href="foundations-randomization.html#fig:sex-rand-dot-plot">9.6</a>?
Often, sometimes, rarely, or never?</p>
<hr>
<p>It appears that a difference of at least 29.2% under the null hypothesis would only happen about 2% of the time according to Figure <a href="foundations-randomization.html#fig:sex-rand-dot-plot">9.6</a>.
Such a low probability indicates that observing such a large difference from chance alone is rare.</p>
</div>
<p>The difference of 29.2% is a rare event if there really is no impact from listing sex in the candidates’ files, which provides us with two possible interpretations of the study results:</p>
<ul>
<li><p>If <span class="math inline">\(H_0,\)</span> the <strong>Null hypothesis</strong> is true: Sex has no effect on promotion decision, and we observed a difference that is so large that it would only happen rarely.</p></li>
<li><p>If <span class="math inline">\(H_A,\)</span> the <strong>Alternative hypothesis</strong> is true: Sex has an effect on promotion decision, and what we observed was actually due to equally qualified female candidates being discriminated against in promotion decisions, which explains the large difference of 29.2%.</p></li>
</ul>
<p>When we conduct formal studies, we reject a null position (the idea that the data are a result of chance only) if the data strongly conflict with that null position.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This reasoning does not generally extend to anecdotal observations.
Each of us observes incredibly rare events every day, events we could not possibly hope to predict.
However, in the non-rigorous setting of anecdotal evidence, almost anything may appear to be a rare event, so the idea of looking for rare events in day-to-day activities is treacherous.
For example, we might look at the lottery: there was only a 1 in 176 million chance that the Mega Millions numbers for the largest jackpot in history (October 23, 2018) would be (5, 28, 62, 65, 70) with a Mega ball of (5), but nonetheless those numbers came up!
However, no matter what numbers had turned up, they would have had the same incredibly rare odds.
That is, &lt;em&gt;any set of numbers we could have observed would ultimately be incredibly rare&lt;/em&gt;.
This type of situation is typical of our daily lives: each possible event in itself seems incredibly rare, but if we consider every alternative, those outcomes are also incredibly rare.
We should be cautious not to misinterpret such anecdotal evidence.&lt;/p&gt;"><sup>81</sup></a>
In our analysis, we determined that there was only a <span class="math inline">\(\approx\)</span> 2% probability of obtaining a sample where <span class="math inline">\(\geq\)</span> 29.2% more male candidates than female candidates get promoted under the null hypothesis, so we conclude that the data provide strong evidence of sex discrimination against female candidates by the male supervisors.
In this case, we reject the null hypothesis in favor of the alternative.</p>
</div>
</div>
<div id="HypothesisTesting" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Hypothesis testing<a class="anchor" aria-label="anchor" href="#HypothesisTesting"><i class="fas fa-link"></i></a>
</h2>
<p>In the last two sections, we utilized a <strong>hypothesis test</strong>, which is a formal technique for evaluating two competing possibilities.
In each scenario, we described a <strong>null hypothesis</strong>, which represented either a skeptical perspective or a perspective of no difference.
We also laid out an <strong>alternative hypothesis</strong>, which represented a new perspective such as the possibility of a relationship between two variables or a treatment effect in an experiment.
The alternative hypothesis is usually the reason the scientists set out to do the research in the first place.</p>
<div class="onebox">
<p><strong>Null and alternative hypotheses.</strong></p>
<p>When we observe an effect in a sample, we would like to determine if this observed effect represents an actual effect in the population, or whether it was simply due to chance. We label these two competing claims, <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_A\)</span>, which are spoken as “H-naught” and “H_A”.</p>
<p>The <strong>null hypothesis</strong> (<span class="math inline">\(H_0\)</span>) often represents either a skeptical perspective or a claim to be tested.</p>
<p>The <strong>alternative hypothesis</strong> (<span class="math inline">\(H_A\)</span>) represents an alternative claim under consideration and is often represented by a range of possible values for the parameter of interest.</p>
</div>
<div class="guidedpractice">
<p>In the Martian alphabet example, which of the two competing possibilities was the null hypothesis? the alternative hypothesis?<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;The first possibility (&lt;em&gt;We can’t read Martian, and these results just occurred by chance.&lt;/em&gt;) was the null hypothesis; the second possibility (&lt;em&gt;We can read Martian, and these results reflect this ability.&lt;/em&gt;) was the alternative hypothesis.&lt;/p&gt;"><sup>82</sup></a></p>
</div>
<p>The hypothesis testing framework is a very general tool, and we often use it without a second thought. If a person makes a somewhat unbelievable claim, we are initially skeptical. However, if there is sufficient evidence that supports the claim, we set aside our skepticism. The hallmarks of hypothesis testing are also found in the US court system.</p>
<div id="the-us-court-system" class="section level3" number="9.3.1">
<h3>
<span class="header-section-number">9.3.1</span> The US court system<a class="anchor" aria-label="anchor" href="#the-us-court-system"><i class="fas fa-link"></i></a>
</h3>
<p>In the US course system, jurors evaluate the evidence to see whether it convincingly shows a defendant is guilty.
Defendants are considered to be innocent until proven otherwise.</p>
<div class="workedexample">
<p>The US court considers two possible claims about a defendant: they are either innocent or guilty.</p>
<p>If we set these claims up in a hypothesis framework, which would be the null hypothesis and which the alternative?</p>
<hr>
<p>The jury considers whether the evidence is so convincing (strong) that there is no reasonable doubt regarding the person’s guilt.
That is, the skeptical perspective (null hypothesis) is that the person is innocent until evidence is presented that convinces the jury that the person is guilty (alternative hypothesis).</p>
</div>
<p>Jurors examine the evidence to see whether it convincingly shows a defendant is guilty.
Notice that if a jury finds a defendant <em>not guilty</em>, this does not necessarily mean the jury is confident in the person’s innocence.
They are simply not convinced of the alternative, that the person is guilty.
This is also the case with hypothesis testing: <em>even if we fail to reject the null hypothesis, we do not accept the null hypothesis as truth</em>.</p>
<p>Failing to find evidence in favor of the alternative hypothesis is not equivalent to finding evidence that the null hypothesis is true<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;This idea is succinctly expressed by the saying, “the absence of evidence is not evidence of absence.”&lt;/p&gt;"><sup>83</sup></a>.
We will see this idea in greater detail in Section <a href="foundations-bootstrapping.html#ConfidenceIntervals">10.2</a>.</p>
</div>
<div id="p-value-stat-signif" class="section level3" number="9.3.2">
<h3>
<span class="header-section-number">9.3.2</span> p-value and statistical significance<a class="anchor" aria-label="anchor" href="#p-value-stat-signif"><i class="fas fa-link"></i></a>
</h3>
<p>In the <a href="foundations-randomization.html#Martian">Martian alphabet example</a>, the research question—can humans read Martian?—was framed in the context of hypotheses:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: The chance a human chooses Bumba on the left is 50%.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Humans have a preference for choosing Bumba on the left.</p></li>
</ul>
<p>The null hypothesis (<span class="math inline">\(H_0\)</span>) was a perspective of no effect (no ability to read Martian). The student data provided a point estimate of 89.5% (<span class="math inline">\(34/38 \times 100\)</span>%) for the true probability of choosing Bumba on the left. We determined that observing such a sample proportion from chance alone (assuming <span class="math inline">\(H_0\)</span>) would be rare—it would only happen in less than 1 out of 1000 samples. When results like these are inconsistent with <span class="math inline">\(H_0\)</span>, we reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_A\)</span>. Here, we concluded that humans have a preference for choosing Bumba on the left.</p>
<p>The less than 1-in-1000 chance is what we call a <strong>p-value</strong>, which is a probability quantifying the strength of the evidence against the null hypothesis and in favor of the alternative.</p>
<div class="onebox">
<p><strong>p-value.</strong></p>
<p>The <strong>p-value</strong> is the probability of observing data at least as favorable to the alternative hypothesis as our current data set, if the null hypothesis were true. We typically use a summary statistic of the data, such as a proportion or difference in proportions, to help compute the p-value and evaluate the hypotheses. This summary value that is used to compute the p-value is often called the <strong>test statistic</strong>.</p>
</div>
<div class="protip">
<p>When interpreting a p-value, remember that the definition of a p-value has three components. It is a (1) probability. What it is the probability of? It is the probability of (2) our observed sample statistic or one more extreme. Assuming what? It is the probability of our observed sample statistic or one more extreme, (3) assuming the null hypothesis is true:</p>
<ol style="list-style-type: decimal">
<li>probability</li>
<li>data<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Technically, the observed sample statistic or one more extreme in the direction of our alternative. But it is helpful to just remember this as “the data”.&lt;/p&gt;"><sup>84</sup></a>
</li>
<li>null hypothesis</li>
</ol>
</div>
<div class="workedexample">
<p>What was the test statistic in the <a href="foundations-randomization.html#Martian">Martian alphabet example</a>?</p>
<hr>
<p>The test statistic in the the Martian alphabet example was the sample proportion, <span class="math inline">\(\frac{34}{38} = 0.895\)</span> (or 89.5%). This is also the <strong>point estimate</strong> of the true probability that humans would choose Bumba on the left.</p>
</div>
<p>Since the p-value is a probability, its value will always be between 0 and 1. The closer the p-value is to 0, the stronger the evidence we have <em>against the null hypothesis</em>. Why? A small p-value means that our data are <em>unlikely</em> to occur, <em>if</em> the null hypothesis is true. We take that to mean that the null hypothesis isn’t a plausible assumption, and we reject it. This process mimics the scientific method—it is easier to disprove a theory than prove it. If scientists want to find evidence that a new drug reduces the risk of stroke, then they assume it <em>doesn’t</em> reduce the risk of stroke and then show that the observed data are so unlikely to occur that the more plausible explanation is that the drug works.</p>
<p>Think of p-values as a continuum of strength of evidence against the null, from 0 (extremely strong evidence) to 1 (no evidence). Beyond around 10%, the data provide no evidence against the null hypothesis. Be careful not to equate this with evidence for the null hypothesis, which is incorrect.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:pval-continuum"></span>
<img src="images/soe_gradient_gray.png" alt="Strength of evidence against the null for a continuum of p-values. Once the p-value is beyond around 0.10, the data provide no evidence against the null hypothesis." width="100%"><p class="caption">
Figure 9.7: Strength of evidence against the null for a continuum of p-values. Once the p-value is beyond around 0.10, the data provide no evidence against the null hypothesis.
</p>
</div>
<!-- You may use Table <a href="#tab:pvalue-continuum"><strong>??</strong></a> as a general guide, but remember that there are no hard and fast cutoffs on this scale---the strength of evidence against the null with a p-value of 0.049 is the same as with a p-value of 0.051.  -->
<!-- ```{r pvalue-continuum} -->
<!-- pval_table <- tribble( -->
<!--   ~variable,    ~col1,  -->
<!-- "p-value < 0.01",  "very strong", -->
<!-- "0.01 < p-value < 0.05", "strong", -->
<!-- "0.05 < p-value < 0.10", "moderate", -->
<!-- "p-value > 0.10", "little to no evidence", -->
<!-- ) -->
<!-- pval_table %>% -->
<!--  kable(caption = "The p-value as a continuum of strength of evidence against the null--a general guide.",  -->
<!--     col.names = c("p-value range", "Strength of evidence against $H_0$")) %>% -->
<!--  kable_styling() -->
<!-- ``` -->
<p>When the p-value is small, i.e., less than a previously set threshold, we say the results are <strong>statistically significant</strong>.
This means the data provide such strong evidence against <span class="math inline">\(H_0\)</span> that we reject the null hypothesis in favor of the alternative hypothesis.
The threshold is called the <strong>significance level</strong> and often represented by <span class="math inline">\(\alpha\)</span> (the Greek letter <em>alpha</em>).
The value of <span class="math inline">\(\alpha\)</span> represents how rare an event needs to be in order for the null hypothesis to be rejected.
Historically, many fields have set <span class="math inline">\(\alpha = 0.05,\)</span> meaning that the results need to occur less than 5% of the time, if the null hypothesis is to be rejected.
The value of <span class="math inline">\(\alpha\)</span> can vary depending on the the field or the application.</p>
<p>Although in everyday language “significant” would indicate that a difference is large or meaningful, that is not necessarily the case here.
The term “statistically significant” only indicates that the p-value from a study fell below the chosen significance level.
For example, in the sex discrimination study, the p-value was found to be approximately 0.02.
Using a significance level of <span class="math inline">\(\alpha = 0.05,\)</span> we would say that the data provided statistically significant evidence against the null hypothesis.
However, this conclusion gives us no information regarding the size of the difference in promotion rates!</p>
<div class="onebox">
<p><strong>Statistical significance.</strong></p>
<p>We say that the data provide <strong>statistically significant</strong> evidence against the null hypothesis if the p-value is less than some predetermined threshold (e.g., 0.01, 0.05, 0.1).</p>
</div>
<div class="onebox">
<p><strong>What’s so special about 0.05?</strong></p>
<p>We often use a threshold of 0.05 to determine whether a result is statistically significant. But why 0.05? Maybe we should use a bigger number, or maybe a smaller number. If you’re a little puzzled, that probably means you’re reading with a critical eye—good job! The <em>OpenIntro</em> authors have a video to help clarify <em>why 0.05</em>:</p>
<center>
<a href="https://www.openintro.org/book/stat/why05/" class="uri">https://www.openintro.org/book/stat/why05/</a>
</center>
<p><br> Sometimes it’s also a good idea to deviate from the standard. We’ll discuss when to choose a threshold different than 0.05 in Section <a href="foundations-errors.html#foundations-errors">12</a>.</p>
</div>
<p>Statistical significance has been a hot topic in the news, related to the “reproducibility crisis” in some scientific fields. We encourage you to read more about the debate on the use of p-values and statistical significance. A good place to start would be the <em>Nature</em> article, “<a href="https://www.nature.com/articles/d41586-019-00857-9">Scientists rise up against statistical significance</a>,” from March 20, 2019.</p>
</div>
</div>
<div id="chp9-review" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Chapter review<a class="anchor" aria-label="anchor" href="#chp9-review"><i class="fas fa-link"></i></a>
</h2>
<div id="summary-6" class="section level3 unnumbered">
<h3>Summary<a class="anchor" aria-label="anchor" href="#summary-6"><i class="fas fa-link"></i></a>
</h3>
<p>Regardless of the data structure or analysis method, the hypothesis testing framework always follows the same steps—only the details for how we model randomness in the data change.</p>
<div class="onebox">
<p><strong>General steps of a hypothesis test.</strong> Every hypothesis test follows these same general steps:</p>
<ol style="list-style-type: decimal">
<li>Frame the research question in terms of hypotheses.</li>
<li>Collect and summarize data using a test statistic.</li>
<li>Assume the null hypothesis is true, and simulate or mathematically model a null distribution for the test statistic.</li>
<li>Compare the observed test statistic to the null distribution to calculate a p-value.</li>
<li>Make a conclusion based on the p-value, and write a conclusion in context, in plain language, and in terms of the alternative hypothesis.</li>
</ol>
</div>
<!-- ::: {.underconstruction} -->
<!-- Add more to this summary -->
<!-- ::: -->
</div>
<div id="terms-7" class="section level3 unnumbered">
<h3>Terms<a class="anchor" aria-label="anchor" href="#terms-7"><i class="fas fa-link"></i></a>
</h3>
<p>We introduced the following terms in the chapter. If you’re not sure what some of these terms mean, we recommend you go back in the text and review their definitions. We are purposefully presenting them in alphabetical order, instead of in order of appearance, so they will be a little more challenging to locate. However you should be able to easily spot them as <strong>bolded text</strong>.</p>
<div class="inline-table"><table class="table table-striped table-condensed" style="margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;">
alternative hypothesis
</td>
<td style="text-align:left;">
permutation test
</td>
<td style="text-align:left;">
simulation-based method
</td>
</tr>
<tr>
<td style="text-align:left;">
null hypothesis
</td>
<td style="text-align:left;">
point estimate
</td>
<td style="text-align:left;">
statistically significant
</td>
</tr>
<tr>
<td style="text-align:left;">
null statistic
</td>
<td style="text-align:left;">
randomization test
</td>
<td style="text-align:left;">
test statistic
</td>
</tr>
<tr>
<td style="text-align:left;">
observed statistic
</td>
<td style="text-align:left;">
significance level
</td>
<td style="text-align:left;">
theory-based method
</td>
</tr>
<tr>
<td style="text-align:left;">
p-value
</td>
<td style="text-align:left;">
simulation
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody></table></div>
</div>
<div id="key-ideas-6" class="section level3 unnumbered">
<h3>Key ideas<a class="anchor" aria-label="anchor" href="#key-ideas-6"><i class="fas fa-link"></i></a>
</h3>
<!-- ::: {.underconstruction} -->
<!-- Need to update this list and distribute across chapters -->
<!-- ::: -->
<p>In this chapter, we introduced statistical inference methods — both simulation-based and theory-based — for scenarios involving one or two categorical variables.</p>
<ul>
<li><p>All of statistical inference revolves around the idea of <strong>sampling variability</strong>: as we take different samples from the population, the value of the sample statistic will vary. In this chapter, we explored sampling variability of a single proportion and a difference in two proportions. If we see some sort of effect in our sample, was it just due to chance? or was it indicative of an actual effect in the population? <strong>Statistical inference</strong> is how we answer this question.</p></li>
<li><p>A <strong>hypothesis test</strong> answers the question “how strong is the <em>evidence</em> of an effect?” A <strong>confidence interval</strong> answers the question “how <em>large</em> is the effect?”</p></li>
<li>
<p>The general steps of a <strong>hypothesis test</strong> are:</p>
<ol style="list-style-type: decimal">
<li>Frame the research question in terms of hypotheses.</li>
<li>Collect and summarize data using a test statistic.</li>
<li>Assume the null hypothesis is true, and simulate or mathematically model a null distribution for the test statistic.</li>
<li>Compare the observed test statistic to the null distribution to calculate a p-value.</li>
<li>Make a conclusion based on the p-value, and write a conclusion in context, in plain language, and in terms of the alternative hypothesis.</li>
</ol>
</li>
<li>
<p>A <strong>p-value</strong> is the probability of observing data like ours, or data with a more extreme effect, under the assumption of the null hypothesis. How we define “more extreme” depends on the direction of the alternative hypothesis. The p-value is the answer to the question “<em>if the null hypothesis were true</em>, what are the chances of observing data like mine?”</p>
<ul>
<li>A small p-value indicates that the observed data would have been unusual if the null hypothesis were true, and thus we have evidence against the null hypothesis.</li>
<li>A p-value that is not small indicates that the observed data are plausible under the assumption of the null hypothesis, and thus we do not have evidence against the null hypothesis.</li>
</ul>
</li>
<li><p>Since decisions in hypothesis testing are based on probabilities (i.e., p-values), it’s possible to make the wrong decision. A <strong>Type 1 error</strong> occurs when we reject a true null hypothesis. If we fail to reject a false null hypothesis, we have committed a <strong>Type 2 error</strong>.</p></li>
<li><p>The <strong>power</strong> of a hypothesis test is the probability of rejecting the null hypothesis, which varies depending on the true value of the parameter. Power typically increases as the sample size increases. Thus, small samples may show an effect in the sample that is <strong>practically important</strong> — may matter in real life — but the test did not have high enough power to reject the null hypothesis, so was not statistically significant. On the other hand, large samples may show an effect in the sample that isn’t very meaningful, or not practically important, but is <strong>statistically significant</strong> due to high power.</p></li>
<li><p>A <strong>simulation-based confidence interval</strong> takes percentiles of a bootstrap distribution of sample statistics as its endpoints. For example, a 95% confidence interval is the interval from the 2.5<sup>th</sup> percentile to the 97.5<sup>th</sup> percentile — those percentiles that capture the middle 95% of the bootstrap distribution.</p></li>
<li><p>A <strong>theory-based confidence interval</strong> is always of the form: statistic <span class="math inline">\(\pi\)</span> (multiplier) <span class="math inline">\(\times\)</span> (standard error of the statistic). The amount we add and subtract to the statistic ((multiplier) <span class="math inline">\(\times\)</span> (standard error of the statistic)) is called the <strong>margin of error</strong>. The mathematical model for the sampling variability of a sample proportion or difference in sample proportions is the <strong>normal distribution</strong>, which is due to the <strong>Central Limit Theorem</strong>.</p></li>
<li><p>All statistical inference methods require that certain <strong>validity conditions</strong> are met; otherwise, the methods are not valid. All methods in this textbook require that the observations in our data set are <strong>independent</strong>. Additionally, theory-based methods require that we have a large enough sample size so that the Central Limit Theorem can apply. For proportions, this condition is known as the <strong>success-failure condition</strong>.</p></li>
</ul>
</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="explore-applications.html"><span class="header-section-number">8</span> Applications: Explore</a></div>
<div class="next"><a href="foundations-bootstrapping.html"><span class="header-section-number">10</span> Confidence intervals with bootstrapping</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#foundations-randomization"><span class="header-section-number">9</span> Hypothesis testing with randomization</a></li>
<li>
<a class="nav-link" href="#Martian"><span class="header-section-number">9.1</span> Motivating example: Martian alphabet</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#observed-data"><span class="header-section-number">9.1.1</span> Observed data</a></li>
<li><a class="nav-link" href="#variability-in-a-statistic"><span class="header-section-number">9.1.2</span> Variability in a statistic</a></li>
<li><a class="nav-link" href="#observed-statistic-vs.-null-statistics"><span class="header-section-number">9.1.3</span> Observed statistic vs. null statistics</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#caseStudySexDiscrimination"><span class="header-section-number">9.2</span> Case study: Sex discrimination</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#observed-data-1"><span class="header-section-number">9.2.1</span> Observed data</a></li>
<li><a class="nav-link" href="#variability-of-the-statistic"><span class="header-section-number">9.2.2</span> Variability of the statistic</a></li>
<li><a class="nav-link" href="#observed-statistic-vs.-null-statistics-1"><span class="header-section-number">9.2.3</span> Observed statistic vs. null statistics</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#HypothesisTesting"><span class="header-section-number">9.3</span> Hypothesis testing</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#the-us-court-system"><span class="header-section-number">9.3.1</span> The US court system</a></li>
<li><a class="nav-link" href="#p-value-stat-signif"><span class="header-section-number">9.3.2</span> p-value and statistical significance</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#chp9-review"><span class="header-section-number">9.4</span> Chapter review</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#summary-6">Summary</a></li>
<li><a class="nav-link" href="#terms-7">Terms</a></li>
<li><a class="nav-link" href="#key-ideas-6">Key ideas</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/MTstateIntroStats/IntroStatTextbook/blob/master/09-foundations-hyp-testing.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/MTstateIntroStats/IntroStatTextbook/edit/master/09-foundations-hyp-testing.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Montana State Introductory Statistics with R</strong>" was written by Stacey Hancock, Nicole Carnegie, Elijah Meyer, Jade Schmidt, Melinda Yager. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
